<div xmlns="http://www.tei-c.org/ns/1.0">
    <head n="1.">Introduction</head>
    <p>
        <s>The web resources on the Internet (e.g.</s>
        <s>websites, user reviews, news, blogs, social media networks, etc.) are gigantic sources of
            textual data.</s>
        <s>Besides, there is a wealth of textual content on the various archives of news articles,
            novels, books, legal documents, biomedical documents, scientific papers, etc.</s>
        <s>The textual content on the Internet and other archives grow exponentially on a daily
            basis.</s>
        <s>As a result, users consume a lot of time to find the information they are looking for.</s>
        <s>They cannot even read and comprehend all the textual content of search results.</s>
        <s>There are many repeated or unimportant portions of the resulting texts.</s>
        <s>Therefore, summarizing and condensing the text resources becomes urgent and much more
            important.</s>
        <s>Manual summarization is an expensive task and consumes a lot of time and effort.</s>
        <s>Practically, it is very difficult for humans to manually summarize this huge amount of
            textual data <ref type="bibr" target="#b206">(Vilca &amp; Cabezudo, 2017)</ref>.</s>
        <s>The Automatic Text Summarization (ATS) is the key solution to this dilemma.</s>
    </p>
    <p>
        <s>The main objective of an ATS system is to produce a summary that includes the main ideas
            in the input document in less space <ref type="bibr" target="#b166">(Radev, Hovy, &amp;
            McKeown, 2002)</ref> and to keep repetition to a minimum <ref type="bibr" target="#b144">(Moratanch
            &amp; Chitrakala, 2017)</ref>.</s>
        <s>The ATS systems help the users to get the main points of the original document without
            the need to read the entire document <ref type="bibr" target="#b152">(Nazari &amp;
            Mahdavi, 2019)</ref>.</s>
        <s>The users will benefit from the automatically produced summaries and they will save a lot
            of time and effort.</s>
        <s>In <ref type="bibr" target="#b121">Maybury (1995)</ref>, Maybury defined the automated
            summary as follows: ''An effective summary distills the most important information from
            a source (or sources) to produce an abridged version of the original information for a
            particular user(s) and task(s)".</s>
        <s>In <ref type="bibr" target="#b166">Radev et al. (2002)</ref>, Radev et al. also defined
            the summary as follows: ''A summary can be loosely defined as a text that is produced
            from one or more texts, that conveys important information in the original text(s), and
            that is no longer than half of the original text(s) and usually significantly less than
            that.</s>
        <s>Text here is used rather loosely and can refer to speech, multimedia documents,
            hypertext, etc.".</s>
        <s>The produced summary should be shorter in length than the input text and include the most
            important information in the input text <ref type="bibr" target="#b46">(Gambhir &amp;
            Gupta, 2017)</ref>.</s>
    </p>
    <p>
        <s>ATS systems can be classified as single-document or multidocument summarization systems.</s>
        <s>The former produces the summary from a single document while the latter generates the
            summary from a cluster of documents.</s>
        <s>ATS systems are designed by applying one of the text summarization approaches:
            extractive, abstractive, or hybrid.</s>
        <s>The extractive approach selects the most important sentences from the input text and uses
            them to generate the summary.</s>
        <s>The abstractive approach represents the input text in an intermediate form then generates
            the summary with words and sentences that differ from the original text sentences.</s>
        <s>The hybrid approach combines both the extractive and abstractive approaches.</s>
        <s>The different classifications for ATS systems are defined in Section 2. The general
            architecture of an ATS system; as shown in Fig. <ref type="figure" target="#fig_0">1</ref>;
            consists of the following tasks:</s>
    </p>
    <p>
        <s>1. Pre-Processing: producing a structured representation of the original text <ref
                type="bibr" target="#b55">(Gupta &amp; Lehal, 2010</ref>) using many linguistic
            techniques like sentences segmentation, words tokenization, removal of stop-words,
            part-of-speech tagging, stemming, etc. 2. Processing: using one of the text
            summarization approaches by applying a technique or more to convert the input
            document(s) to the summary.</s>
        <s>Section 3 defines the different ATS approaches and Section 4 explores the different
            techniques and building blocks to implement an ATS system.</s>
        <s>3. Post-Processing: solving some problems in the generated summary sentences like
            anaphora resolution and reordering the selected sentences before generating the final
            summary.</s>
    </p>
    <p>
        <s>ATS is one of the most challenging tasks in Natural Language Processing (NLP) and
            Artificial Intelligence (AI) in general.</s>
        <s>ATS research began as early as 1958 with Luhn's work <ref type="bibr" target="#b108">(Luhn,
            1958)</ref> that automatically excerpts abstracts of magazine articles and technical
            papers.</s>
        <s>ATS poses many challenges to the research community like: 1) identification of the most
            informative segments in the input text to be included in the generated summary <ref
                type="bibr" target="#b166">(Radev et al., 2002)</ref>, 2) summarization of long
            single documents such as books, 3) summarization of multi-documents <ref type="bibr"
                target="#b57">(Hahn &amp; Mani, 2000)</ref>, 4) evaluation of the computer-generated
            summary without the need for the human-produced summary to be compared with, and 5)
            generation of an abstractive summary <ref type="bibr" target="#b57">(Hahn &amp; Mani,
            2000)</ref> similar to a human-produced summary.</s>
        <s>Researchers still dream of an accurate ATS system to produce a summary that 1) covers all
            the main topics in the input text, 2) does not include redundant or repeated data, and
            3) is readable and cohesive to the users.</s>
        <s>Since the beginning of ATS research in the late 1950s, they have been trying and are
            still working to improve techniques and methods for generating summaries so that the
            computer-generated summaries can match with the human-made summaries <ref type="bibr"
                target="#b46">(Gambhir &amp; Gupta, 2017)</ref>.</s>
    </p>
    <p>
        <s>Many surveys have been recently published about ATS systems and methodologies.</s>
        <s>Most surveys focus on techniques and methods of extractive summarization like <ref
                type="bibr" target="#b152">Nazari and Mahdavi (2019)</ref> because the abstractive
            summarization needs extensive NLP.</s>
        <s>In <ref type="bibr" target="#b86">Kirmani, Manzoor Hakak, Mohd, and Mohd (2019)</ref>, <ref
                type="bibr">Kirmani et al.</ref> define the common statistical features and some
            extractive methods.</s>
        <s>In <ref type="bibr" target="#b91">Kumar and Sharma (2019)</ref>, Kumar and Sharma provide
            a survey about the extractive ATS systems that apply fuzzy logic methods.</s>
        <s>In <ref type="bibr" target="#b145">Mosa, Anwar, and Hamouda (2019)</ref>, <ref
                type="bibr">Mosa et al.</ref> provide a survey on how the swarm intelligence
            optimization techniques are applied for ATS.</s>
        <s>They aim to motivate researchers to use swarm intelligence optimization for ATS
            especially for short text summarization.</s>
        <s><ref type="bibr" target="#b193">Suleiman and Awajan (2019)</ref> provide a survey about
            extractive deep-learning-based text summarization.</s>
        <s>Some surveys focus on abstractive summarization like <ref type="bibr">Gupta and Gupta
            (2019)</ref>, <ref type="bibr" target="#b98">Lin and Ng (2019)</ref> for different
            abstractive methods <ref type="bibr" target="#b197">and Tandel, Mistree, and Shah (2019)</ref>
            for abstractive neuralnetwork-based methods.</s>
        <s>Some surveys focus on a domainspecific summarization like <ref type="bibr" target="#b17">(Bhattacharya
            et al., 2019;</ref><ref type="bibr" target="#b79">Kanapala, Pal, &amp; Pamula, 2019)</ref>
            for legal documents summarization, <ref type="bibr">(Dutta et al., 2019)</ref> for
            comparing extractive algorithms used in the microblogs summarization, and <ref
                type="bibr" target="#b71">Jacquenet, Bernard, and Largeron (2019)</ref> for
            abstractive deep-learning-based methods and challenges of meeting summarization.</s>
        <s>Some surveys like <ref type="bibr" target="#b54">(Gupta, Bansal, &amp; Sharma, 2019;</ref><ref
                type="bibr" target="#b109">Mahajani, Pandya, Maria, &amp; Sharma, 2019)</ref>
            provide a review about some abstractive and extractive methods.</s>
        <s>A survey about the summarization evaluation methods is presented in <ref type="bibr"
                target="#b43">(Ermakova, Cossu, &amp; Mothe, 2019)</ref>.</s>
    </p>
    <p>
        <s>Most of the state-of-the-art surveys tackle a subset of the ATS aspects like focusing on
            one approach (e.g.</s>
        <s>extractive summarization), one method for a specific approach (e.g.</s>
        <s>extractive fuzzy logic method), one specific-domain ATS systems (e.g.</s>
        <s>legal documents summarization), etc. Besides, <ref type="bibr">Dutta et al. (2019)</ref>
            highlights that different ATS algorithms produce different summaries from the same input
            texts so it is very promising to combine outputs from multiple ATS algorithms to produce
            better summaries.</s>
        <s>Also, <ref type="bibr" target="#b109">Mahajani et al. (2019)</ref> conclude that it is
            recommended to benefit from the advantages of both extractive and abstractive approaches
            by proposing hybrid ATS systems.</s>
        <s>Therefore, the main motivation for this work is to provide a comprehensive survey about
            the various ATS aspects in order to help researchers enhance computergenerated summaries
            potentially by combining different approaches and/or methods.</s>
        <s>The main contributions of this research include:</s>
    </p>
    <p>
        <s>Illustrating the classifications of the ATS systems and explaining the different ATS
            applications provided with examples of ATS systems proposed in the literature for each
            application.</s>
        <s>Providing a systematic review about the ATS approaches: extractive, abstractive, and
            hybrid.</s>
        <s>Each approach is applied using several methods in the literature.</s>
        <s>This survey provides: 1) the general architecture, advantages, and disadvantages of each
            approach and 2) the methods of each approach along with the advantages, disadvantages,
            and examples of ATS systems for each method.</s>
        <s>A conclusion about the state-of-the-art research recommendations for each approach is
            provided at the end of the approach subsection in Section3.</s>
    </p>
    <p>
        <s>Providing an overview about the various components and techniques that are used to design
            and implement the ATS systems.</s>
        <s>The survey illustrates: 1) the text summarization operations inspired from the analysis
            of the human experts' operations, 2) the widely-used statistical and linguistic features
            that identify the important words and sentences, and 3) the text summarization building
            blocks.</s>
        <s>The building blocks include: 1) the common text representation models, 2) the linguistic
            analysis and processing techniques, and 3) the soft computing techniques (e.g. machine
            learning, optimization algorithms, and fuzzy logic).</s>
        <s>Providing an overview about the standard datasets besides the manual evaluation criteria
            and automatic evaluation tools for the computer-generated summaries.</s>
        <s>Providing a listing and categorization of the future research directions for the research
            community based on the existing ATS systems limitations and challenges.</s>
    </p>
    <p>
        <s>The structure of this paper mirrors its main contributions: Section 2 illustrates the
            various classifications of ATS systems and the ATS applications.</s>
        <s>Section 3 introduces ATS approaches and explores the different methods proposed in the
            literature for each approach.</s>
        <s>Section 4 highlights the techniques and building blocks that are used to implement ATS
            systems, while Section 5 explores the benchmarking datasets and ATS evaluation methods.</s>
        <s>Finally, Section 6 concludes the paper and provides future directions for ATS research.</s>
    </p>
</div>