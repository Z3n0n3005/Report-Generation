<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">TEMIS Integrates Ontology Management and Semantic Enrichment in Luxid® 7</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2014-07-01">July 1, 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Mike</forename><surname>Morrow</surname></persName>
							<email>mmorrow@businessobjects.com</email>
							<affiliation key="aff0">
								<address>
									<addrLine>295 Madison Avenue 45 th floor</addrLine>
									<postCode>10017</postCode>
									<settlement>New York</settlement>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Blumenstraße 15</orgName>
								<address>
									<postCode>D-69115</postCode>
									<settlement>Heidelberg</settlement>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">France Tour Mattei</orgName>
								<address>
									<addrLine>207 rue de Bercy</addrLine>
									<postCode>75012</postCode>
									<settlement>Paris</settlement>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="laboratory">Ancells Business Park</orgName>
								<address>
									<addrLine>Ancells Rd</addrLine>
									<postCode>GU51 2UN</postCode>
									<settlement>Fleet, Hampshire</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="department" key="dep1">Inxight Software</orgName>
								<orgName type="department" key="dep2">Inc</orgName>
								<address>
									<addrLine>500 Macara Avenue</addrLine>
									<postCode>94085</postCode>
									<settlement>Sunnyvale</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">TEMIS Integrates Ontology Management and Semantic Enrichment in Luxid® 7</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2014-07-01">July 1, 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-07T14:54+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>These crunchers can provide any linguistic function</term>
					<term>including ThingFinder (Entity</term>
					<term>relation</term>
					<term>event extraction)</term>
					<term>content filtering</term>
					<term>language identification</term>
					<term>summarization</term>
					<term>and Inxight&apos;s new and improved taxonomy and categorization system Entity Found Normalization May 12 $23 million CNA Systems</term>
					<term>Incorporated 05/12 23000000 USD CNA Systems</term>
					<term>Inc. Canonical Form Variant Forms No. of Appearances Joe Smith CNA Systems</term>
					<term>Incorporated Smith</term>
					<term>Mr. Smith</term>
					<term>J. Smith CNA</term>
					<term>CNA Systems</term>
					<term>CNAI 2 5 Company Date Person Person Position Currency Measurement Country Noun Group</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Practical applications of linguistic technology compiled by Dagobert Soergel</head><p>Reading 3 (required). Note: This TOC also provided as a separate file to view side-by-side Look over these pages to get a general idea and dig deeper if something piques your interest. This is a compilation of materials on the LUXID system (and its forerunner Insight [not to be confused with Inxight]) produced by TEMIS Corp., and on the SAP BusinessSystems ThingFinder system. ThingFinder originated at Inxight corporation, a spinoff from Xerox PARC (Palo Alto Research Center of mouse and the MAC and Windows interface fame); Inxight was bought by BusinessSystems, which was bought by SAP, a major business software vendor.</p><p>Both systems extract information from text. They process text to extract entities and statements that connect entities through relationships. They also assign metadata to documents, in other words, they assist in (or take over) cataloging. The marketing hype says that these systems convert unstructured data (text, better called data with complex structure) into structured data, entity-relationship statements often represented in tables and graphs, structures that are simpler and easier to search than text.</p><p>The compilation includes old documents from Inxight because they give better examples and a much better explanation of the process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Overall framework and broad applications</head><p>• Luxid 6 Content Enrichment Platform Brochure (Luxid 7 not available) 3 -8 • Luxid 7 press notice 9 -11 • OECD chooses TEMIS to semantically structure knowledge 13 -14 How it works. A first glimpse • Luxid. From text to meaning. One slide 15 • Inxight LinguistX platform 17 -18 • Inxight. Linguistics: Adding value to e-publishing and e-content P. 17 -20 is general hype, p. 21 -24 is useful technical information 19 -27 A little more detail on how it works • Inxight SmartDiscovery Extraction Server 29 -32 • Inxight ThingFinder Server 33 -34 • Fact sheet. TEMIS Skill Cartridge Biological Entity Relationships 35 -36 • Statistical Translation WashPost20110222Health&amp;ScienceP1 37 -40 • Google switches to its own [statistical] translation system</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Luxid ® Annotation Factory</head><p>Luxid ® Annotation Factory is the flagship natural language processing pipeline that extracts structured information from unstructured documents by recognizing the key topics, entities and relations mentioned in text. Built as a robust and scalable platform, it embeds syntactical, statistical, taxonomy-based and machine-learning driven information extraction engines and supports 20 languages, enabling it to power high-throughput information extraction applications across a wide range of use cases and geographies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Overview and key components</head><p>Luxid ® Content Enrichment Platform is subdivided into three key functional areas :</p><p>Luxid ® Skill Cartridge ® Library Skill Cartridges ® are the specialized modules that focus the information extraction mechanics provided by Luxid ® Annotation Factory on domain-or use-case specific entities or relations. Luxid ® Skill Cartridge ® Library is a range of off-the shelf Skill Cartridges ® that address areas of recurring interest such as people names, locations, corporate information and relationships, news categorization, biology, medicine, chemistry, homeland security, and others. Skill Cartridges ® can be easily customized and/or developed from scratch with Luxid ® Content Enrichment Studio. Luxid ® Content Enrichment Studio Luxid ® Content Enrichment Studio is a suite of four development tools that enable Luxid ® licensees to create new Skill Cartridges ® , to customize and extend existing ones, and to track and optimize quality and performance. The four tools are Knowledge Editor, Skill Cartridge ® Builder, Category Workbench and Annotation Workbench.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Reading 3a (optional) gives more detail. Only for those really interested in this topic Based on patented and award-winning natural language processing technology, Luxid ® Content Enrichment Platform is a powerful and scalable semantic content enrichment solution that recognizes and extracts relevant items of information hidden in plain text and enriches document metadata. By revealing the intimate nature of your informational assets, it helps optimize their management, distribution, access and analysis.</p><formula xml:id="formula_0">S T R U C T U R E T H E U N S T R U C T U R E D</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Applications in Professional Publishing</head><p>Boost the usage of your content by making it more compelling</p><p>• Attract new visitors with structured SEO tags • Make your content easier to navigate with smart facets based on semantic metadata • Provide context and perspective with personalized content recommendations and links to structured knowledge • Enable topic matter insights with metadata-driven analytic widgets</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Deliver innovative products &amp; formats</head><p>• Create Topic Pages by selecting content based on semantic metadata • Assemble Knowledge Bases with structured information extracted from your existing content • Embed your content in customer workflow applications with metadatarich Content APIs</p><p>Increase your editorial productivity</p><p>• Increase the flexibility, scalability and consistency of tagging, categorization and information extraction through automation • Repurpose archives faster by revealing their contents with analytics • Facilitate the maintenance of your taxonomy by automating the identification of candidate terms</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Applications in Enterprise Content Management</head><p>Add structure to your content</p><p>• Reduce the need for end-user metadata contribution by automating content tagging • Consistently align metadata to your taxonomy or controlled vocabulary</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Manage content hypergrowth</head><p>• Increase the efficiency of document auditing and migration tasks • Accelerate e-discovery tasks • Enable smart archival workflows with domain-specific metadata • Enrich your analytical reporting with indicators extracted from unstructured content</p><p>Exploit your content and the data it contains Structure, manage and exploit your unstructured content.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Overview</head><p>Based on UIMA, Luxid ® Annotation Factory's distributed architecture automatically balances the workload to all available processing units, and implements native fail-over capabilities sustaining the continuous processing required in mission-critical applications.</p><p>At the COre : SKill CArtridGeS ®</p><p>At the core of this distributed pipeline, specialized extraction modules called Skill Cartridges ® flexibly support information extraction needs across multiple domains and applications. Depending on the context, Skill Cartridges ® may focus on entities of general interest such as companies, people, locations, or dates, or on those that are more domain-specific-such as proteins or genes in biology. Beyond entities, Skill Cartridges ® are also able to extract more structured information in the form of the relations that link these entities (for example a merger between two companies or a chemical reaction between two compounds), including the roles played by each entity in the relation, as well as their attributes or other contextual information mentioned in the document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A brOAd rAnGe OF extrACtiOn teChniqUeS</head><p>To optimize its performance across use cases, Luxid ® Annotation Factory provides a marketleading part-of-speech tagging layer supporting 20 languages and embeds a wide range of information extraction techniques including morphosyntactic reasoning, statistics, thesaurus-and taxonomy-based extraction, machine learning and rules-based extraction. Luxid ® Annotation Factory is also capable of performing corpuslevel operations such as Categorization (the classification of documents in predefined categories) or Clustering (the grouping of similar documents into dynamically created clusters).</p><p>Adding even more flexibility to these native capabilities, Annotation Factory also supports the integration of third-party UIMA-compliant annotators in annotation plans.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>deplOyment And inteGrAtiOnS</head><p>A key component of Luxid ® Annotation Factory, its Workflow Engine is in charge of the end-toend management of complex workflows that can involve multiple cascaded Skill Cartridges ® as well as distributed multi-CPU and multi-node processing. To streamline platform deployment and support the robust operation of such workflows, the Workflow Engine also implements advanced fault-tolerance mechanisms and centralized log management. A web-based administration interface provides users control over all platform parameters and centralized access to its logs. The platform is furthermore JMX compliant, easily integrating into common monitoring consoles.</p><p>While the core of its pipeline is natively based on XML, Luxid ® Annotation Factory supports more than 200 file formats on the ingress side, and provides a flexible range of output options including XML and RDF. To ease its deployment within the major content management systems, a growing range of off-theshelf integrations is available, in particular for MarkLogic, Microsoft SharePoint 2010, EMC Documentum, Alfresco Enterprise, and Nuxeo. The Web Services offered by Luxid ® Content Enrichment Platform facilitate its integration within other content management systems, applications and information management workflows.</p><p>Here is an overview of some of the most representative of these Skill Cartridges ® .</p><p>relevAnt term Finder SKill CArtridGe ®</p><p>The RTF Skill Cartridge ® identifies the most characteristic terms of each document (its "fingerprint") by comparing its vocabulary to a statistical model based on a reference corpus. This model can be adjusted through training on any corpus that appropriately reflects your specific domain. RTF requires no pre-defined conceptual structure and can be applied to a wide variety of use cases such as Similar Documents Recommendation, Clustering, and domain-specific Terminology Extraction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SmArt tAxOnOmy FACilitAtOr SKill CArtridGe ®</head><p>STF acts as a vehicle for applying taxonomies and controlled vocabularies to documents. It embeds technologies that help overcome two key weaknesses associated to taxonomy-based indexing. The first, Fuzzy Term Matching, automatically produces variants of the forms present in the taxonomy, thereby helping to improve recall.</p><p>The second, Relevance Scoring, applies a range of heuristics to assign a relevance score to each extracted concept and discards the less relevant ones, therefore improving extraction precision. STF can also exploit part-of-speech tagging information to avoid false positives caused by ambiguous taxonomical terms. Knowledge Editor enables you to conveniently package your own taxonomy into STF and adjust its performance to your specific use case by controlling the parameters driving its heuristics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>mAChine leArninG extrACtiOn SKill CArtridGe ®</head><p>The MLX Skill Cartridge ® is a versatile extractor that can be trained to extract, subcategorize and/or score virtually any type of entity in text based on a previously annotated corpus where such entities of interest have been highlighted by domain experts. The corpus annotation and Skill Cartridge ® training processes requires no natural language processing expertise and can be performed easily with Annotation Workbench.</p><p>iptC CAteGOrizAtiOn SKill CArtridGe ®</p><p>This Skill Cartridge ® analyzes the vocabulary used in documents and classifies them into approximately 130 categories based on key headings of the top two levels of the IPTC (News) taxonomy. This Skill Cartridge ® is available for the English and French languages. Extensions to other languages and more complete coverage of the IPTC headings can be achieved on a project basis.</p><p>text mininG 360° SKill CArtridGe ® TM360 extracts more than 20 types of common entities among which the names of People, Companies, Organizations, Locations, as well as Measurements, Money and Time expressions, and Contact information. To achieve this task, TM360 embeds a variety of predictive natural language processing methods including morphological and syntactical heuristics. This Skill Cartridge ® is available in 8 languages (English, German, French, Spanish, Italian, Dutch, Portuguese and Arabic).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>COmpetitive intelliGenCe SKill CArtridGe ®</head><p>CI extracts the same entities as the TM360° Skill Cartridge ® , as well as 10 types of semantic relationships involving companies, their employees, assets or strategy, including Corporate Mergers and Acquisitions, Court Cases, Board and Management Changes, Financial Reporting, Business Development and Strategy. CI leverages syntactical reasoning to establish the role played by each entity in the relationship, enabling it to recognize for instance the acquiring company from the target or the licensee from the licensor. CI is available in English, French, Spanish and Dutch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>OpiniOn mininG SKill CArtridGe ®</head><p>The Opinion Mining Skill Cartridge ® recognizes the subjective expressions that reveal evaluative judgment or emotional states that are typically found in social media or customer feedback corpora. Leveraging a combination of specialized thesauri and syntactical reasoning, OM qualifies these opinions both in terms of polarity (negative/positive) and intensity, and links them to their target (for example products, service features, brands, organizations or people), helping professionals to quantify, track and analyze information that is otherwise entirely unstructured. This Skill Cartridge ® is available in English and French.</p><p>biOlOGiCAl entitieS And relAtiOnShip SKill CArtridGe ® Luxid ® Skill Cartridge ® Library also includes a range of Skill Units that are more specific to certain specialty areas such as military, political and strategic events, legal proceedings and scientific and technical domains beyond the life sciences.</p><p>An entirely new component of the Luxid® platform, Luxid® Webstudio is a natively multi-user, collaborative web application enabling users to create, edit and maintain an ontology while governing the way ontological objects are recognized by the Luxid® semantic enrichment pipeline. It also leverages the platform's Natural Language Processing layer to • Preview in real time the results of the semantic enrichment process when applied to users' corpus of documents. This enables users to rapidly see and correct gaps between ontology and real world semantic enrichment, directly within the Webstudio interface, for example by adding variants or adjusting extraction mechanisms.</p><p>• Suggest relevant objects mentioned in the user's corpus that are not yet included in the ontology. This feature can be extended with any Skill Cartridge® to suggest new objects and relationships based on linguistic patterns, statistics, or machine learning. In this spirit, Webstudio also embeds a Wikipedia-based Skill Cartridge® that suggests synonyms for any given concept. These suggestions can help non Subject Matter Experts to build their own ontologies too.</p><p>These powerful features make end-users more autonomous in creating or maintaining an ontology and the corresponding semantic enrichment pipeline. This translates into a considerably simplified and accelerated workflow, enabling improved time-to-market and lower total cost of ownership.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Streamlined, Big Data architecture offers improved scalability and robust integration options</head><p>Luxid® Annotation Server is TEMIS's flagship natural language processing pipeline. Supporting 20 languages and leveraging Skill Cartridges® -the specialized information extraction modules popularized by TEMIS -Luxid® Annotation Server lends itself to a broad range of usage scenarios thanks to its comprehensive range of information extraction engines based on syntactical, statistical, taxonomical, and machine-learning algorithms. In its 7</p><p>th generation, the pipeline has also been rethought from the ground up to offer</p><p>• A simplified internal architecture exploiting a single data model that reduces overhead, improves CPU utilization and efficiently lends itself to a variety of scale-in and scale-out configurations, for real-time, highavailability or batch content processing applications. Luxid® Annotation Server plays well in both cloud and Big Data (Hadoop) deployments, and flexibly processes ever-increasing volumes of unstructured content.</p><p>• Comprehensive REST Web Services enabling easy integration into any application or workflow. Beyond information extraction itself, virtually all Luxid® features are accessible through Web Services, enabling rich integrations that work hand-in-hand with other applications such as content management systems, portals, search engines, archival and case management platforms, editorial workflow tools, as well as analytics applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Follow Follow</head><p>Thanks to these evolutions, Luxid® 7 provides users with an unparalleled ability to add the value of semantic intelligence to their existing applications in complete coordination with their ontology or taxonomy management processes.</p><p>Luxid® 7 leverages TEMIS's updated Skill Cartridge® Library, a range of off-the shelf, application-specific information extractors, and includes its Content Enrichment Studio suite of tools, ensuring the industrial creation, maintenance and quality evaluation of Skill Cartridges®. Luxid® 7 is a powerful tool for the Luxid® Community, enabling users in a matter of minutes to import any thesaurus or taxonomy and consequently populate the website's Marketplace with new and innovative annotation resources.</p><p>OECD Chooses TEMIS to Semantically Structure its</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Knowledge and Information Management Processes</head><p>PARIS and NEW YORK, November 21, 2013 /PRNewswire/ --TEMIS (http://www.temis.com/), the leading provider of Semantic Content Enrichment solutions for the Enterprise, announced today that they have won a call for tender issued by the Organisation for Economic Co-operation and Development (OECD) with their award-winning Semantic Content Enrichment solution Luxid (http://www.temis.com/luxid-6)®.</p><p>The OECD provides its expertise, data and analysis to its 34 member governments and 100 other countries to help them support sustainable economic growth, boost employment and raise living standards. To fulfill its vision of increased relevance and global presence, the OECD has launched a Knowledge and Information Management (KIM) Program that establishes an integrated framework for managing and delivering information and improving its accessibility and presentation. The KIM framework is intended as the steward of the OECD's information lifecycle, with a universal knowledge referential at its core facilitating enhanced searching and findability, rationalized content reuse/repurposing processes, and supporting the organisation's Open Data and Linked Data initiatives.</p><p>In this context, the OECD has chosen TEMIS's flagship Luxid® Content Enrichment Platform to address all Semantic Enrichment stages of the KIM framework. Luxid® will help OECD to consistently enrich document metadata in alignment with its taxonomies and ontologies, providing a genuinely semantic integration layer across heterogeneous document storage and content management components. This semantic layer will both enable new search and browsing methods and improved relevance and accuracy of search results, as well as progressively build an integrated map of OECD knowledge.</p><p>Organizations continue to tackle the growing challenge of how to quickly and efficiently retrieve relevant information from the Internet and other electronic text data sources. Inxight's LinguistX ® Platform provides advanced text analysis technology that enables software developers to build multi-language text analysis features into their products, while reducing time-to-market and avoiding unnecessary development costs.</p><p>Using a single API for high-performance natural-language processing components, developers can quickly and cost-effectively create applications that enable intelligent, accurate and timely access to information.</p><p>Inxight LinguistX Platform provides advanced text analysis capabilities in more than 30 languages, making it the solution of choice for search engines, data mining applications, indexing applications, and text categorization and routing tools.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supporting global organizations and operations</head><p>Using a single API, Inxight LinguistX Platform intelligently analyzes text by providing language and character encoding identification, segmentation and stemming in these languages:</p><p>Many of these languages also support part-of-speech tagging and noun phrase extraction. Contact Inxight Sales for additional languages. The Most Advanced Natural-Language Proc e s s i n g</p><formula xml:id="formula_1">• Arabic • Catalan • Chinese (Simplified) • Chinese (Traditional) • Croatian • Czech • Danish • Dutch • English • Farsi (Persian) • Finnish • French • German • Greek • Hebrew • Hungarian • Italian • Japanese • Korean • Norwegian (Bokmål) • Norwegian (Nynorsk) • Polish • Portuguese • Romanian • Russian • Serbian • Slovak • Slovenian • Spanish • Swedish • Thai • Turkish</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>About Inxight</head><p>Inxight Software, Inc. is the leading provider of enterprise software solutions for information discovery. Using Inxight solutions, companies can better discover, retrieve and connect with unstructured, semi-structured or structured text. Inxight is the only company that provides a complete, scalable solution to enable information discovery in all major languages. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Word Segmentation (Tokenization)</head><p>Identifies meaningful units of text at a granular level, including:</p><p>• Individual words and word particles </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stemming</head><p>Identifies true stems (base forms) for each surface form token; normalizes words to most basic form for more efficient indexing and better recall in search.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>De-Compounding</head><p>Splits compound words into distinct elements -particularly important in languages such as German and Dutch where words are freely joined together.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Noun Phrase Extraction</head><p>Identifies sequences of tokens that have meaning as phrases based on patterns in part-of-speech tagging output. Examples include: "fourth quarter earnings," "adverse effects," "President Bush."</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Automatic Language and Character Encoding Identification</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Part-of-Speech</head><p>Plural noun Verb, present tense, third person Superlative adjective</p><formula xml:id="formula_2">Tag &lt;&lt; Nn-Pl &gt;&gt; &lt;&lt; V-Pres-3-Sg &gt;&gt; &lt;&lt; Adj-Sup &gt;&gt;</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Part-of-Speech Tagging</head><p>Identifies and labels the part-of-speech of each word in context, including grammatical category <ref type="bibr">(noun, verb, etc.)</ref>, and sub-class attributes (singular vs. plural nouns, present vs. past tense verbs, etc.).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Token cats sits biggest</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Competitors:</head><p>Temis XeLDA has the same basic functions Language identification. Automatically recognizes the language used by each document</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Segmentation. Divides a text into sentemces</head><p>Tokenization. Splits a text into basic lexical units Morphological analysis. Returns the normalized form (the lemma) and the potential grammatical categories [parts of speech] for all the words identified during the tokenization stage Morpho-syntactic disambiguation. Determines the exact grammatical category of a word according to its context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Extraction of noun phrases</head><p>Dictionary lookup. Identifies the context of a word to find the corresponding dictionary entry</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Recognition of idiomatic expressions</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Executive Summary</head><p>Linguistics: Adding Value to e-Publishing and e-Content Page 2</p><p>Constant change is the overriding factor shared by thousands of electronic publishing companies that provide information through Web sites. Traditional information distribution mechanisms (email, postal services, etc.) must now coexist with the chaos of the Web and its billions of pages. Smart, agile publishers and information aggregators -grouped under the headings e-Publishers and infomediaries -are learning that their success is dependent on monetizing content while protecting its inherent value from creeping "Napsterization" -all the while bucking the "everything for free" culture of the Internet.</p><p>So, the problem becomes how to charge a premium for information that the online world assumes should be free of charge. The answer lies in adding significant, obvious and relevant value by delivering specific, targeted information that saves users the time, effort and resources required to sift through the Web's massive data storehouses themselves.</p><p>Of the products and technologies targeting this market, only Inxight's e-Content Publishing Platform has the appropriate combination of functionality and underlying architecture to achieve the three key e-Publishing objectives: return on investment, improved productivity and increased value of information.</p><p>As the Web's overall content spirals upward into the realm of exabytes and beyond, the sheer volume of information that requires high-speed, intelligent search and retrieval software has presented an opportunity for editors to embrace new technology systems that replace former error-prone methods.</p><p>Inxight's e-Content Publishing Platform presents e-Publishers with the best available choice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>e-Publishing Industry Overview</head><p>Electronic publishing is growing at a staggering rate. Up from $146 billion in 1999 (Outsell, Inc.), industry insiders suggest that the number could now be as high as $300 billion, and the expansion of the Web and the Internet as information distribution engines can only spur further growth.</p><p>IDC estimates that 200 million pages are added each month, while an estimated 100 million become obsolete. The latter figure demonstrates clearly why information management on the Web is so difficult. Obsolete pages proliferate misinformation, although there's usually no way for users to gauge the validity of any given page.</p><p>Timeliness is a key element in certain e-Publishing areas, notably the distribution of news content. No one is going to pay a premium for yesterday's news. In other areas, though, time is less important.</p><p>Looking at the bigger picture, the Web has imposed a set of issues unknown in the publishing industry a decade ago, including the commoditization of information, the explosive growth of content and content aggregators, and the focus on profitability -to the chagrin of those who would contend that the Web must continue to operate at no cost to the user. While the Internet and Web are generally regarded as free sources of information, business realities have created new mandates to generate revenue and profits, driving the publishing industry to control intellectual property assets more closely. Market factors affecting publishing today include:</p><p>• Growth and expansion of e-Publishers/infomediaries • High expectations for quality and the need for specific content • User expectations and demand for real-time information • New players, roles and commoditization lead to slimmer margins • Information needs to be available anytime, anywhere • Content vendors need to adapt their content to support expanded media</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Players</head><p>These days, the e-Publishing distribution system is dominated by "infomediaries." These include many of the leading syndicators from the "old economy," such as Reuters and Dow Jones, along with the new breed of aggregation companies that serve as go-betweens, linking content providers with mass audiences. The latter group includes YellowBrix, iSyndicate, Factiva and Screaming Media. They don't produce their own content, nor do they have the kinds of direct relationships with information consumers that newspapers and magazines create. Rather, they serve as matchmakers for both ends of the distribution chain, linking content with knowledge consumers.</p><p>Infomediaries separate content from a specific interface or distribution channel, and make it available through an infinite number of channels. They aggregate content from many primary publishers -just as the traditional syndicators did -but instead of rolling the content into a single one-size-fits-all package, they offer slices of the content to a Web site or intranet that wants to add third-party content to its mix.</p><p>The e-Publishing cast looks like this:</p><p>• Infomediaries, including syndicators who collect information from selected sources and resell it to other buyers. Leading players include Factiva, The New York Times Syndicate, and iSyndicate. Aggregators are also part of the infomediary group. They don't own the content, but collect multiple information types from multiple sources and re-distribute it to buyers. Key players include Lexis Nexis, Dialog and Screaming Media. • Buyers, in this case an organization that buys content on behalf of end users and publishes it on an information portal. The buyer could be a private company or a commercial portal like msn.com or yahoo.com.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>•</head><p>End users, or information consumers. Players include individuals browsing Web sites for private use or business users collecting decision support information for commercial use.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Industry Dynamics</head><p>As the nature of the publishing business changes -and specifically the move to e-Content -so, too, do the drivers and inhibitors that dictate industry dynamics. As we've already seen, the sheer volume of information is growing exponentially. As a result, applications that categorize, tag and cull Webbased information today must encompass terabytes of data. In the not too distant future, applications must be capable of performing the same set of functions on to 'exabytes' of data (one million terabytes). The demand, therefore, is for information management architecture that scales to accommodate a virtually infinite set of information derived from multiple sources.</p><p>These sources include corporate ERP/CRM applications, document management systems, external research materials, news feeds, interpersonal email, and data housed on personal computers. Metadata -the "rules" by which information is categorized and culled, is scrambled and non-standardized. In addition, commoditization has impacted the value of e-Content and made it difficult to create enough perceived value to charge money for it.</p><p>The obvious needs are for highly refined filtration systems and tight, standardized organizational methodologies. In short, information delivery needs to "get personal," sorting through the maze of online content to zero-in on the requirements of specific users and organizations. Let's now examine the technologies that make that possible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Technologies</head><p>Just as HTML has led the pack in describing Web presentation, XML (eXtensible Markup Language) is growing as the industry standard used by application developers as the mechanism to define key information <ref type="bibr">[Type text]</ref> within documents. Used by a variety of enterprise applications, XML can be used as the common link between data from disparate sources. XML is essential in architecting a robust enterprise system, and allows for reuse of information across multiple, integrated applications.</p><p>As PC Week (now eWEEK) stated in 1999, "Like HTML, XML derives from the granddaddy of all markup languages: SGML (Standard Generalized Markup Language). SGML is a meta-language, or a system for defining markup languages such as HTML. XML is also a meta-language, a subset of SGML designed for use on the Web. As with SGML, you can use XML to define different markup languages for specific uses, particularly for data representation."</p><p>Adding to the confusion, different XML derivatives are constantly being promulgated as standards by various industry groups. Among the markup languages in publishing, whether NewsML, PRISM, NITP, each leverages XML, but modifies it for specific applications (e.g., NewsML for news publishers and ICE information and Content Exchange&gt; as a protocol to automate content syndication. Now, a look at how Inxight's underlying technology and application-level systems combine to deliver the most efficient e-Publishing content delivery solution available today.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Inxight Business Case</head><p>Strong technology and a rich feature set is one thing; mapping these capabilities to address real business needs is another. Fortunately, Inxight's e-Content Publishing Platform excels at delivering the benefits that define a successful e-Publishing solution: return on investment; productivity increases; and increased value of information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Increased ROI</head><p>Decrease Operation and Administrative Costs: Time is money -especially in the case of publishing content. The older the news, the less valuable it becomes. So, e-Publishers/infomediaries invest a significant amount of money on human capital to produce and maintain content. These days, much of that content is derived from the Web and, as discussed earlier in this paper, searching billions of Web pages for pertinent, related information is the single most difficult, timeconsuming activity in the e-Publishing industry. By automating the process, most publishers can decrease their operational and administrative costs, and realize significant savings with an investment payout in less than one year.</p><p>A small news agency, for example, that manages 300-plus news articles a day, will spend at least $1,000 a day on the time editors will take to categorize, summarize and tag an electronic article. Considering that it takes five minutes to manually categorize, tag and summarize a typical article, the cost added to the article is about $3.00 just to prepare it for electronic distribution. By automating this process, the savings would amount to at least $365,000 each year.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Increased productivity</head><p>Another advantage of e-content automation technologies is enhancing productivity and efficiency. For editors using the Inxight e-Content Publishing Platform, the benefit is the time they can save on tagging documents, enabling them to spend their time on more strategic editorial responsibilities.</p><p>Editors simply don't scale well -you can only get so much quality work out of a single human. With Inxight's e-Content Publishing Platform, scalability is built in; the engine is more than capable of sifting through billions of entries in minutes and extracting relevant, personalized information. Also, human editors often miss related content.</p><p>Take, for example, a business analyst looking to correlate internal sales data with external market research and consumer trend documents. In essence, she is looking for very closely related information that, on the surface, may seem to have little in common. A human editor may miss the connections entirely. Because editorial decisions are highly interpretive, it's predictable that even experienced editors will miss or inaccurately categorize and tag relevant information.</p><p>Inxight's e-Content Publishing Platform doesn't miss a thing. It uses the industry's most advanced linguistic algorithms, capable of making valid connections between seemingly disparate items. It's also transnational, capable of culling information in 12 western and four Asian languages.</p><p>But productivity savings don't stop at the publisher or aggregator. Rather, the chain accelerates in value as consumers interact with the information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Increased value of information</head><p>Buried under an ever-increasing volume of unfiltered data, readers don't have the time to search and read every piece of news in hopes of finding that rare, relevant kernel of useful information. Using Inxight's e-Content Publishing Platform, however, e-Publishers can boost revenues by increasing overall readership by offering a menu of time saving features such as auto-summarization.</p><p>In addition, publishers can add enormous value by personalizing information to meet the demographic profiles or preference lists of their subscribers. Studies show that, even though the Web is viewed as an essentially free medium, people are more than willing to pay subscriber fees to get precise, targeted information that saves them significant search time. E-Publishers wanting to stave off the effects of commoditization on their bottom lines can automatically increase the value of their information through personalization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Inxight Technology Focus</head><p>Inxight's architecture model focuses on the four key requirements involved in identifying, sorting and delivering targeted information from the mass of data residing on both public Web sites and private intranets -creation, collection/aggregation, normalization and distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>•</head><p>Organizing -The process of automatically classifying content into both topics/subjects and entities (companies, people's names, etc.)</p><p>• Enriching -The automation of enriching content by applying metatags into the document that embed the characterization of the document's topics, key entities, hyperlinks to related information, and summaries using XML technology.</p><p>• Collection/Aggregation -The process of integrating content from multiple, disparate sources, both internal and external, and organizing it into a body of useful information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>•</head><p>Normalization -The process of processing and refining aggregated information into cohesive search results. Different infomediary sources use different naming conventions and categorizations. For example, a search for auto racing may turn up articles on individual drivers, NASCAR safety regulations, and repaving the Indianapolis Speedway. Normalizing metadata from content means both an intelligent search that recognizes the relationships and contexts of seemingly unrelated articles, as well as rejecting articles that seem to fit search criteria but are only tangentially related.</p><p>• Data personalization -The process of sending the right information to the right people, in the right format, according to both search criteria and the format preferences of the user -abstracts and summaries for downloading to mobile devices such as PDAs and Internet appliances; full article with graphics for computer users.</p><p>Paying close attention to these core requirements yields a system for searching, categorizing and retrieving information that encompasses the 10 keys that allow users to take full advantage of dynamic content.</p><p>[Type text]</p><p>Linguistics: Adding Value to e-Publishing and e-Content Page 6</p><p>The Inxight e-Content Publishing Platform</p><p>Inxight delivers a best-of-breed content infrastructure known as the Inxight e-Content Publishing Platform that enables content businesses to fulfill delivery promises for quality over quality, faster access to pertinent information (horizontal and vertical information), and personalization. The Inxight e-Content Publishing Platform enables content businesses to:</p><p>• Automatically classify and index content, such as news feeds and web sites, into predefined subject categories. XML output Indexes and summaries are created using XML.</p><p>For IT administrators, developers and architects, they will benefit by using an standard XML encoding to integrate Inxight applications and output into their system infrastructure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Java and C/C++ API's</head><p>APIs coded in Java and C/C++ exposes key features in Inxight products.</p><p>APIs expose Inxight's best-ofbreed technologies and core functions. The APIs are designed to allow for ease of integration for all primary features of Inxight products, whether you are building and application or adding functionality into an existing system infrastructure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Feature _______ Description Benefit</head><p>Inxight is the leading provider of enterprise software applications for understanding and effectively using unstructured data. Open and flexible SOAP APIs allow for easy integration into any environment, as well as easy integration of third-party crawlers, search engines and metadata repositories.</p><p>Publishers can now process massive amounts of data for near real-time financial analysis or news aggregation/portal applications.</p><p>Government analysts looking for the needle in the haystack can process millions of classified messages, intelligence reports, blog information, and so forth for further analysis of relationships and events. ASP applications, including hosted CRM or business intelligence applications can process and classify massive amounts of data according to the products, companies, people, concepts and other entities mentioned in them for near realtime searching availability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Inxight SmartDiscovery Extraction Server (SDX) Modules</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ThingFinder ® Extraction Module</head><p>Inxight SmartDiscovery Extraction Server quickly and efficiently reads text to discover the "who," "what," "when" and "where" of each document --creating consistent, useful metadata.</p><p>SmartDiscovery Extraction Server's ThingFinder Entity Extraction Module (also available as an SDK) requires no training, tuning or customer-supplied lists. Leveraging Inxight's deep linguistic understanding, SmartDiscovery is able to discover entities based on patterns in text, automatically identifying more than 35 named entity types out-of-the-box, including people, places, companies, dates, measurements, currency figures and email addresses.</p><p>It can also be extended to recognize customer-specific list-based entity types, such as SKU numbers or project names.</p><p>With its deep understanding of natural language, the advanced entity extraction of ThingFinder Professional allows users to further extend their solution by defining custom patterns of tokens in regular expression syntax. It can be used to extract custom entities, relations and events such as chemical compound names or formulae, phrases for sentiment analysis and medication adverse effects. Out-of-the-box entity, relation and event extraction packs are also available for common business and intelligence applications. Contact Inxight for more details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Categorizer™ Module</head><p>Taxonomies can provide a powerful way to browse and retrieve documents based on a company-specific, meaningful, structured representation of information.</p><p>Inxight SmartDiscovery Extraction Server's Categorizer Module addresses every stage of taxonomy creation, management and content categorization to provide a consistent, accurate way to organize and navigate unstructured data, giving users access to the information they need to make informed decisions.</p><p>Inxight's Taxonomy and Categorization Module provides a hybrid approach to taxonomy management, combining learn-by-example with explicit rules creation, leveraging Inxight's deep understanding of language. An intuitive Taxonomy Workbench makes creation and testing of taxonomies easier. In addition, users can import home-grown and third-party taxonomies with relative ease. Only SmartDiscovery Extraction Server provides taxonomy management and categorization capabilities within a complete, integrated and powerful information discovery solution. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Summarizer™ Module</head><p>Inxight's Summarizer Module (also available as an SDK) generates accurate abstracts of any document in a fraction of a second, enabling users to scan large sets of information more than 10 times faster than reading the entire text. In a Web-based environment, it automatically summarizes the content of any Web page, so that you can preview a destination before leaving the page. For businesses of all kinds, Summarizer produces increased productivity and substantial cost savings by eliminating hours unnecessarily spent conducting online searches. Summaries can be output for use in alerting, search results display and routing applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Uses for Inxight SmartDiscovery Extraction Server</head><p>SmartDiscovery Extraction Server's capabilities enable users to:</p><p>• Automatically code documents in near real-time to appropriately route or alert users to relevant documents of interest.</p><p>• Create link analysis or business intelligence applications that identify and monitor trends and events mentioned in customer service logs, emails, blogs and other unstructured sources.</p><p>• Provide additional value to Documentum and Xerox DocuShare implementations by creating automated attributes for use at check-in time.</p><p>• Create applications that augment information search and retrieval operations.</p><p>• Add permanent, lasting metadata for future applications and uses. The Inxight ThingFinder SDK (software development kit) "reads" text and automatically identifies and extracts more than 25 key entity types out-of-the-box, such as people, dates, places, companies or other "things" from any text data source, in multiple languages -with no setup or manual creation of rules required. This ability to automatically identify and classify relevant entities makes Inxight ThingFinder one of the most powerful text analysis and categorization tools on the market.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Inxight uses the power of extraction and categorization to power its</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Providing structure to unstructured information</head><p>The Inxight ThingFinder SDK provides robust, open APIs (application programming interfaces) for easy integration into virtually any application that processes textual information, enabling users to:</p><p>• Find all references to products and people in customer service logs and emails -automatically.</p><p>• Create link analysis and business intelligence applications that monitor trends and movements associated with people, places, dates and companies.</p><p>• Add structure to unstructured text documents by identifying and categorizing the most important entities discussed inside the documents.</p><p>• Mine large volumes of text for relevant information and quickly identify trends in data sets.</p><p>In addition to the out-of-the-box entity types included with the system, Inxight </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Automatic Entity Extraction</head><p>Inxight ThingFinder -Requires no training sets or manually created rules</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Extraction and Categorization</head><p>ThingFinder leverages Inxight's true understanding of natural language -language-aware tokenization, part-of-speech tagging and noun phrase identification -to automatically extract and classify all entities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Variant Identification and Grouping</head><p>Variant identification and grouping allow Inxight ThingFinder to accurately classify all relevant entities in a document, even one-word entities, and to provide true counts reflecting the number and location of ALL appearances of a given entity. For example, Inxight ThingFinder recognizes that the appearance of the word "Smith" in the example refers to the earlier identified person "Joe Smith."</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Normalization</head><p>Normalization takes much of the guesswork out of metadata creation, search, data mining and link analysis processes by creating standard formats (e.g. ISO) for certain entity types such as dates or measurements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Relevance Ranking</head><p>The entities extracted by Inxight ThingFinder are given relevance scores reflecting their importance to the document as a whole, making ThingFinder an essential part of any data categorization solution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Customization</head><p>In addition to the out-of-the-box entity types included with the system, Inxight ThingFinder can be customized to extract other relevant items, such as WatchLists or project names. The optional Inxight ThingFinder Professional module further extends the power of ThingFinder by allowing developers to define custom entity and link types using regular expression patterns. For instance, developers can add chemical names or bank account numbers, and more. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Biological Entity Relationships</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Skill Cartridge™</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mining Biomedical Literature…</head><p>TEMIS Text Mining is a powerful technology to manage unstructured data with unparalleled accuracy. A search engine will return thousands of unworkable results from a query, but information extraction will focus on domain-specific and valueadded content.</p><p>The Biological Entity Relationships Skill Cartridge™ processes each biomedical article to identify and extract meaningful relationships <ref type="bibr">(expression, regulation, activation, etc…)</ref> between 10 types of biological entities (i.e. genes, proteins, cells, process, etc.). However, these entities may be referred to very differently and the complexity of the corresponding expressions may range from ambiguous acronyms like "NMBR" to complex combinations of terms like "Corticotropin releasing factor receptor 2". Conventional indexers will not be able to recognize many cases of such expressions in the text. The names of biomedical entities are often composed of several words, furthermore they are not unique and may include several synonyms.</p><p>A single protein may be referred to as: Interleukin 6, HGF, HSF, BSF2, IL-6, IFNB2, B-cell stimulatory factor 2, BSF-2, Interferon beta-2, Hybridoma growth factor, IL 6, BSF 2, interleukin6, IFNB 2 or IFNB-2.</p><p>The Biological Entity Relationships Skill Cartridge™ performs an identification and extraction of the names of biomedical entities (including genes and proteins) together with their relationships from documents with unequaled relevance. Each organism-specific gene or protein has a unique identifier as well as a root form facilitating an easy linkage into biomedical databases (i.e. Swiss-Prot, Entre-GENE, etc.) and providing a defined way to integrate to existing systems.</p><p>The </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Why choose the Biological Entity Relationships Skill Cartridge™?</head><p>The ability to identify and extract biomedical entities and their relations helps to: &lt; Access and organize all the much needed information about Biological Entities, Mechanisms or Targets, &lt; Compare one's findings to others,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Specifications</head><p>The Department of Bioinformatics at Fraunhofer SCAI focuses on two major aspects of modern life science informatics: data management as well as data analysis for biomedical research. The Fraunhofer Institute SCAI is working on applied mathematics, numerical simulation, high performance parallel computing, and bioinformatics. The Fraunhofer Institute is Germany´s largest organisation for applied research. It currently maintains 57 research institutes in Germany and other countries with about 13,000 employees.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt;&lt; Operating systems:</head><p>-Windows NT, 2000, XP workstation or server versions -Linux</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt;&lt; API:</head><p>-Java (RMI -Remote Method Invocation)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt;&lt; Source languages:</head><p>English.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt;&lt; Formats :</head><p>over 50 input formats (including MS Word, PDF and HTML).</p><p>Copyright © 2006 TEMIS S.A. All rights reserved. Product appearance and/or specifications may be modified without prior notice. BESC.052006 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Biological Entity Relationships Skill Cartridge™</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt;&lt; Grenoble</head><p>Tel. : +33 (0)4 56 38 24 00 info@temis-group.com</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TEMIS Germany</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt;&lt; Heidelberg</head><p>Tel. : +49 -6221 13753-12 info.de@temis-group.com</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TEMIS USA</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt;&lt; Philadelphia</head><p>Tel. : +1 571 235 83 95 info.us@temis-group.com</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TEMIS Italy</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt;&lt; Modena</head><p>Tel. : +39 -059 237 634 info.it@temis-group.com www.temis.com &lt; Build knowledge from heterogeneous sources and innovative inputs, &lt; Gain new insights into the molecular foundations of diseases by combining gene/protein interactions with other relevant entities like Disorders, Process, Cells and Tissues.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discover the TEMIS Product Range</head><p>The The guide was written in German, which Casey cannot read, so she typed bits of it into an Internet translation tool. "It occurs nobody endlschleudern, however, intercatapults" is one result she got. Stumped, she pressed some buttons and eventually managed to wash her clothes, in an elongated wash cycle that kept her pinned down for three hours.</p><p>Libby's quandary will come as no surprise to anyone who has tried to use a computer to translate things. For decades, machine t ranslation was mostly useful if you were trying to be funny. But in the last few years, as anyone using Google Translate, Babel Fish or many other translation Web sites can tell you, things have changed dramatically. And all because of an effort begun in the 1980s to remove humans from the equation.</p><p>As the late Frederick Jelinek, who pioneered work on speech recognition at IBM in the 1970s, is widely quoted as saying: "Every time I fire a linguist, my translation improves." (He later denied putting it so harshly.)</p><p>Up to that point, researchers working on machine translation used linguistic models. By getting a computer to understand how a sentence worked grammatically in one language, the thought was, it would be possible to create a sentence meaning the same thing in another language. But the differing rules in different languages made it difficult.</p><p>Jelinek and his group at IBM argued that by using statistics and probability theory, instead of language rules, a computer could do a better job of converting one language into another. Translation, they basically argued, was as much a mathematical problem as a linguistic one. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2011-02-22 Health&amp;Science P1</head><p>In print edition: Online translators go by the numbers meaning of what it was translating, but by creating a huge database of words and sentences in different languages, the computer could be programmed to find the most common sentence constructions and alignment of words, and how these were likely to correspond between languages. (Warren Weaver, a mathematician at the Rockefeller Foundation, had first raised the idea of a statistical model for translation in a 1947 letter in which he wrote: "When I look at an article in Russian, I say: 'This is really written in English, but it has been coded in some strange symbols.' ")</p><p>The IBM effort began with proceedings from the Canadian parliament, which were published in English and French. "A couple guys drove to Canada and left with two suitcases full of tapes that contained the proceedings," says Daniel Marcu, co-founder of Language Weaver, the first start-up to use the new statistical techniques in 2002.</p><p>Jelinek's group began by using a computer to automatically align sentences in the French and English versions of the parliamentary documents. It did this by pairing sentences from the same point in the proceedings that were of roughly equal lengths. If an opening sentence in English was 20 words long but the French opening was two sentences of about 10 words, the computer would pair the English sentence with the two French ones. The IBM researchers then used statistical methods and deductions to identify sentence structures and groups of words that were most common in the paired sentences.</p><p>As researchers got hold of more documents and translations of them in different languages, the database of common words and groups of words grew, providing increasing accuracy and nuance. This is the essence of the system today.</p><p>Although the IBM group's initiative began more than 20 years ago, it has taken time for computer scientists at IBM and elsewhere to refine those techniques, for computers to become powerful enough to manage the complexity of the many linguistic probabilities (such as multiword phrases and idioms) and for databases to grow large enough -billions of words in various languages -to provide translations nuanced enough to be usable. This is easier when </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Google, Yahoo! BabelFish use math principles to translate documents online</head><p>Page 2 of 4 Google, Yahoo! BabelFish use math principles to translate documents online 2/27/2011 http://www.washingtonpost.com/wp-dyn/content/article/2011/02/21/AR2011022102191_p... dealing with closely related languages, such as French and Spanish, and with languages that have lots of translated documents with which to build a database. European languages do well in computer translations in part because the workings of the European Union must be published in the 23 "official and working languages" of the EU; these documents can then be used as raw data for researchers.</p><p>A major step in computer translation occurred in 2007 -around the time that Libby Casey was struggling with those Reykjavik washer instructions -when Google introduced the first free, statistically based translation software. (Other Web-based translation programs were still using the older linguistic rule-based systems.) "Suddenly we see enormous progress in this technology because of Google's push," says Dimitris Sabatakakis, chief executive of Systran, one of the oldest computer translation companies. (Systran powered Google Translate until 2007 and is still the engine behind the widely known Yahoo! Babel Fish computer translation service, which now uses a hybrid system combining both statistical and linguistic models for translation.)</p><p>All this means that someone such as Michael Cavendish, a lawyer based Jacksonville, Fla., can do human-rights work related to China.</p><p>"Machine translation has been a godsend for someone like me who has trouble conversing in foreign languages, because I never got a chance to study them in depth," he said recently.</p><p>When Cavendish writes documents, e-mails or Twitter posts to communicate with dissidents and others in Chinese, he finds that a computer translation is pretty goodprovided he keeps his English simple. So he doesn't go on about "ex post facto laws," he said, but simply says: "China arrested this man today for something that was legal yesterday." After shunning linguistic system for many years, the statistical translation mainstream is now again embracing grammar and other language-specific rules to capture some nuances and improve accuracy. Experts say that improvements in translation systems are only going to continue as the databases they use grow larger and as computer scientists are better able to incorporate linguistic information. Soon, researchers say, there will be more and better "speech to speech" software, which will allow simultaneous translation in meetings, for instance. The Pentagon is particularly interested in giving deployed soldiers the ability to communicate with locals: One project is focusing on translations between English and Pashto, which is spoken in Afghanistan and Pakistan.</p><p>Even as the field rapidly evolves, though, the kind of odd translations that Libby Casey encountered doing her laundry in Reykjavik are unlikely to vanish entirely -as Sandra Alboum recently found out. Alboum, who runs a translation company in Arlington, was perusing a manual for a half-million-dollar steel-manipulation machine that a client of hers had translated, using a computer, from German into English. "Do not step under floating burdens," it said. She had to check the manual herself to figure out what was meant: "Do not stand under suspended loads."</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Kakaes is a writer living in Washington.</head><p>View all comments that have been posted about this article. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Google Switches to Its Own Translation System</head><p>Google switched the translation system from Systran to its own machine translation system for all the 25 language pairs available on the site. Until now, Google used its own system only for Arabic, Chinese, and Russian.</p><p>"Most state-of-the-art commercial machine translation systems in use today have been developed using a rules-based approach and require a lot of work by linguists to define vocabularies and grammars. Several research systems, including ours, take a different approach: we feed the computer with billions of words of text, both monolingual text in the target language, and aligned text consisting of examples of human translations between the languages. We then apply statistical learning techniques to build a translation model," explains Franz Och.</p><p>You can compare the new Google Translate with Babel Fish, a site that uses Systran to provide translations. The switch is a sign that Google's system has improved a lot and could soon be ready for expanding its coverage. This guide provides a conceptual framework for understanding ThingFinder, its functions, and its components.</p><p>This preface contains the following sections:</p><p>• Audience for this Guide </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Organization of This Guide</head><p>This guide contains the following chapters and appendices:</p><p>Chapter 2: Introducing ThingFinder-Surveys product features and provides a technical overview of ThingFinder.</p><p>Chapter 3: ThingFinder Processing-Describes the tasks ThingFinder performs to process documents.</p><p>Chapter 4: Glossary-A glossary of ThingFinder terminology.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Related Documentation</head><p>The following documentation contains information related and complementary to this guide:</p><note type="other">About This Guide Technical Support 1</note><p>Concepts Guide 3</p><p>• • ThingFinder Language Guide and Reference-Describes how to configure the ThingFinder language modules and provides reference information for each module.</p><p>• ThingFinder SDK Getting Started Guide-Describes ThingFinder SDK requirements, installation and guidelines to follow when developing applications based on your operation system platform.</p><p>• ThingFinder SDK Programmer's Guide and Reference-Describes how to use the ThingFinder C++ API within your programs and provides the API reference.</p><p>• ThingFinder SDK Java API Getting Started Guide-Describes the installation and configuration process for ThingFinder's Java API.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Technical Support</head><p>For all technical support issues, please visit our Customer Support Web site at http://technicalsupport.businessobject.com. • Various alphanumeric patterns such as ID numbers, contract dates, profits, and so on ThingFinder technology goes beyond conventional character matching tools for information retrieval, which can only seek exact matches for specific strings. Thanks to its strong linguistic foundation in Business Objects LinguistX Platform™, ThingFinder uses a deep understanding of the semantics of words. In addition to known entity matching, ThingFinder performs the complementary function of new entity discovery.</p><p>To customize entity extraction, ThingFinder enables you to specify your own list of entities in a name catalog. Name catalogs enable you to store entities and manage name variation. Known entity names can be standardized using the name catalog. ThingFinder also performs normalization of certain numeric expressions, such as dates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introducing ThingFinder</head><p>What is Entity Extraction? 2</p><p>Concepts Guide 7</p><p>In addition, ThingFinder Professional adds tools for building custom rules that enable the detection and extraction of activities, events, and relationships between entities. ThingFinder Professional extends the power of extraction offering by allowing users to:</p><p>• Define custom relationship and event types that are unique to your data sets and requirements</p><p>• Discover entities and concepts based on patterns rather than lists of known entities</p><p>• Disambiguate entities using contextual information. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>What is Entity Extraction?</head><p>Entity extraction is the process by which ThingFinder identifies entities in input documents, classifies them according to type, and where possible, normalizes them to a standard format. ThingFinder can extract entities using lists of specific named entities, and it can also discover new entities using linguistic models. Named entities are often proper names, such as the names of specific and unique people, companies, or places. Other specified entity types include currency amounts and dates, among others. ThingFinder classifies each extracted entity by type and presents this metadata in a standardized format along with the entity's character offset into the document, length, and other attributes.</p><p>For ThingFinder, an entity is defined as a pairing of a specific name and its type. For example, several entities are given here with their type: ThingFinder Professional custom extraction rules can use predefined and custom entity types to specify and extract more complex information based on the relationship between entities, along with the linguistic attributes of the entities (such as stem, part-of-speech, syntactic function, and so on).</p><p>The set of supported entity types differs by language; for more information, refer to the ThingFinder Language Guide and Reference. You can extend upon existing entity types by customizing a name catalog; refer to the ThingFinder Programmer's Guide and Reference for details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Challenges in Entity Extraction</head><p>Knowledge management and information retrieval applications must handle the problems of Name Variation and Ambiguity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Name Variation</head><p>A given entity can be referred to in more than one way. For example, John Doe in the sentence John Doe reported the incident can be replaced by all the variations shown in Figure <ref type="figure" target="#fig_1">2</ref>-1, and potentially others. Similarly, The United States of America, United States, America, and USA are various ways to refer to the same country.</p><formula xml:id="formula_3">• ADDRESS • CURRENCY • ORGANIZATION • PUBLICATION • ADDRESS_ INTERNET • DATE • PERCENT • SSN • CITY • HOLIDAY • PERSON • STATE • ORGANIZATION • LANGUAGE • PHONE • VEHICLE • COUNTRY • MONTH • PRODUCT • YEAR Introducing ThingFinder</formula><p>What is Entity Extraction? 2</p><p>Concepts Guide 9 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ambiguity</head><p>A particular name may refer to more than one entity. For example, in the sentence, Georgia's budget is balanced, the identity of Georgia is ambiguous. Depending on interpretation, the sentence is talking about very different things, as shown in Figure <ref type="figure" target="#fig_1">2</ref>-2. Knowledge management applications must know which of the possible interpretations is the correct one for the current document.</p><p>To summarize, the relationship between real-world entities and their names as found in text documents is many to many. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The ThingFinder Solution</head><p>ThingFinder combines the following tools for recognizing entities, events, and relationships from text documents:</p><p>• A set of sophisticated language modules to discover entities based on ThingFinder's inherent knowledge of the semantics of words and the linguistic context in which these words occur.</p><p>The language modules perform more sophisticated linguistic processing than string matching because they combine knowledge about sequences of word tags with intelligence about word semantics.</p><p>• Reference to a name catalog-a compiled database of named entities, their canonical forms and their common variations.</p><p>• Custom extraction rules created with ThingFinder Professional-the ability to create custom patterns to extract entities and facts that are specific to your needs.</p><p>ThingFinder can use these techniques individually or in combination.</p><p>In addition, there are several supplementary operations that ThingFinder uses to enhance its results. For instance, ThingFinder can determine that certain names are aliases of each other and refer to the same entity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Linguistic Processing</head><p>ThingFinder performs linguistic processing by using tools that include semantic and syntactic knowledge of words. In general, linguistic processing identifies paragraphs, sentences, and clauses, and then identifies semantic and syntactical information within the text. Presently, there are two modes for linguistic processing: standard and advanced.</p><p>• Standard linguistic processing-is available for all supported languages, and is the default behavior for all supported languages.</p><p>• Advanced parsing-is available for English custom rule-based extraction.</p><p>Advanced parsing offers richer noun phrase structure, noun phrase coordination, syntactic function attributes, and pronominal resolution. Advanced parsing is used only when custom extraction rules are used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introducing ThingFinder</head><p>The ThingFinder Solution 2</p><p>Concepts Guide 11</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Name Catalog</head><p>A ThingFinder name catalog is an easy to use customization tool that specifies a list of entities that ThingFinder should always extract while processing text. You can use a name catalog to store name variations in a structured way that is accessible through the ThingFinder API. The name catalog structure can help standardize references to an entity.</p><p>Name catalogs distinguish between canonical and variant names. The canonical name is the most standard, complete or precise form for a given entity. For example, United Parcel Service of America is the canonical name for that company. A canonical name may have one or more variant names embedded under it. A variant name is less standard or complete than a canonical name. For example, United Parcel Service and UPS are both variant names for the same company. While each canonical must have a type, variants can optionally have their own type; for example, you might define a variant type ABBREV to include abbreviations. Figure <ref type="figure" target="#fig_1">2</ref>-3 shows the structure of a name catalog entry: For more information, refer to the ThingFinder Programmer's Guide and Reference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Custom Extraction Rules</head><p>ThingFinder Professional extraction rules are patterns written using regular expressions and linguistic attributes that define patterns for the entities, events, and relations you need to find. These rules are written using the • Entities-A pairing of a specific name and its type. For example, Canada/ COUNTRY.</p><p>• Events-Two or more entities whose relationship indicates an occurrence or a change of state. For example, John Smith landed in Plymouth in 1675.</p><p>• Relations-Two or more entities that have a specific relationship. For example, John Smith met Pocahontas in 1675.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ThingFinder Architecture</head><p>This section surveys some essential technical aspects of ThingFinder. 2. Using the language modules, ThingFinder performs extraction on the text, normalizes the format of entities where possible, compares these results with the name catalog, applies custom extraction rules, and finally generates a list of the entities to be returned. Optionally, ThingFinder refines its results by performing further ambiguity resolution and grouping aliases together.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.</head><p>ThingFinder results are returned to the application as lists of metadata.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ThingFinder Operations</head><p>The standard ThingFinder processing algorithm includes the operations summarized below. You can perform some of the operations independently, or you can skip some.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Known Entity Matching</head><p>Known entity matching is accomplished by using the following methods:</p><p>• Language modules-ThingFinder language modules contain known entities, their syntactic and semantic information, and the entity type to which they can belong. You can use a language module alone to perform known entity matching and extraction, or you can use it in conjunction with a name catalog or custom extraction rules, or both.</p><p>• Name catalogs-Name catalogs contain a given form of an entity, including its canonical name, and its variants and their types. You can use a name catalog alone or you can use it in conjunction with a language module or custom extraction rules, or both.</p><p>• Custom Extraction rules-ThingFinder Professional custom extraction rules contain patterns that include regular expressions and syntactic information to match specific entities. You must use custom extraction rules in conjunction with a language module. You can also use it in conjunction with a name catalog, which, in addition, can be used within extraction rules.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>New Entity Discovery</head><p>ThingFinder uses specialized language modules to recognize entities in running text. For example, a noun phrase following Mr. is often a PERSON, and a noun phrase preceding Inc. is often a COMPANY.</p><p>ThingFinder Professional enables you to define your own extraction rules to recognize entities, events, and relations that are specific to your needs.</p><formula xml:id="formula_4">2 14 Concepts Guide</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Entity Construction</head><p>ThingFinder compares the results of entity extraction from various language modules, with the records found in the name catalog to determine the entities and assign types to them. In its results, ThingFinder returns information about how it determined the entity and its type, for example, whether the entity was found in the name catalog or some other way. Entity names are standardized where possible.</p><p>When ThingFinder cannot determine the type of an entity, it might return more than one type so that the calling application can perform entity disambiguation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Normalization</head><p>Numeric expressions in the categories DATE, CURRENCY, PERCENT, and YEAR are normalized according to the norms of the International Standards Organization, or ISO.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Post-processing</head><p>Following the standard processing, there are several optional operations that can refine your results. Conjecture determines the type of an ambiguous entity by comparing it with identified entities from the same document.</p><p>Aliasing groups together references to the same entity. Relevance ranking provides a score of how relevant an entity is to the overall themes in its containing document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Precision and Recall</head><p>Here we'll briefly review the accuracy measures most often used to describe the correctness and completeness of information retrieval systems, including entity extraction systems-precision and recall.</p><p>Precision and recall statistics assume that, for any question, a system will produce a variable number of answers, some correct and some not. The question posed to an entity extraction system is: What entities are contained in a given document, and what is the type of each? We can define precision and recall in these terms as follows:</p><p>Precision The number of correct answers as a percentage of all answers a system produces.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Recall</head><p>The number of correct answers actually produced as a percentage of the total number of correct answers that can be produced.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introducing ThingFinder</head><p>ThingFinder Architecture 2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Concepts Guide 15</head><p>ThingFinder combines processes aimed at increasing both recall and precision. Recall is increased during the generation of candidate entities, while precision is the focus during entity selection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Output</head><p>ThingFinder produces a collection of entities, packaged as an ordered list.</p><p>The information associated with each extracted entity includes its name, entity type, and its offset, or position, in the text, so that its original text form can easily be fetched. These structures are in memory and are accessible through the API, for use by the calling application. The character encoding of output structures is identical to that of the input. Applications are responsible for processing this metadata and presenting it to users.</p><note type="other">chapter ThingFinder Processing ThingFinder Processing Candidate Generation 3 18 Concepts Guide</note><p>This chapter describes, in greater detail, the process of entity extraction.</p><p>When performing entity extraction, certain steps are required while others are optional.</p><p>Figure <ref type="figure">3</ref>-5 illustrates the ThingFinder workflow: This chapter contains the following topics:</p><p>• Candidate Generation • Entity Selection</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Candidate Generation</head><p>ThingFinder's first task is to generate candidate entities. As part of this process, ThingFinder processes all input with its language modules. Candidate generation involves the following phases: pre-processing, grouping, and name catalog lookup. If you use ThingFinder Professional, candidate generation also includes custom extraction lookup.</p><p>ThingFinder discovers entities using a process called Grouping. This process maximizes recall by finding all candidate entities. The ThingFinder language modules take many factors into consideration during grouping, including the linguistic distribution of word tags, semantic knowledge about words, capitalization, punctuation, and the presence of designator words, such as a title preceding a proper noun. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pre-processing</head><p>The first phase in the ThingFinder process is to segment the input text into linguistic chunks that can be analyzed and manipulated. The operations described in this section are part of ThingFinder pre-processing, and this information is intended to help you understand how ThingFinder works. Your application won't do anything specifically related to these operations. Nor can a ThingFinder application directly access these operations or their objects. The output of these operations is available only for internal use by ThingFinder.</p><p>Pre-processing consists of the following operations:</p><p>• Segment Generation-The input text is broken into segments, which are chunks of text, normally containing one or more paragraphs, that are used for further processing. Their size is controlled by the &lt;maximum- segment-size&gt; parameter, as described in the configuration chapter of the ThingFinder Language Guide.</p><p>• Language and Encoding Identification-To process text, ThingFinder must know the language, format, and character encoding of the input text. ThingFinder can automatically identify these properties, or you can supply the values, depending on your application.</p><p>For example, when using the ThingFinder SDK, you can specify the values in the parameters of the TF_Finder constructor, or you can specify "auto" to instruct ThingFinder to identify the properties automatically.</p><p>• Word Segmentation-ThingFinder identifies words in the input buffer, including words numbers, abbreviations, multi-word tokens, and punctuation. At the same time, a determination is made for whether punctuation marks should be considered part of a word or separate. For example, the period in Ms. is a part of the word, while a period ending a sentence is a separate unit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Grouping</head><p>During grouping, ThingFinder processes the input text using a series of language modules that specialize in the recognition of various tag sequences. These tags are assigned to each token in the text based on contextual co- ThingFinder assigns one or more entity type labels to each discovered phrase. Some labels are very specific, such as PERSON, DATE and VEHICLE_LIC (license plate), while others are generic, labeling an entity as a miscellaneous proper noun (PROP_MISC). Entities with generic types can be identified during a post-processing operation or through the use of custom extraction rules.</p><p>If you are using ThingFinder Professional, you can also define custom rules to help you identify extraction patterns that are specific to your requirements. In a second pass after grouping, ThingFinder uses your compiled custom rules, looking for matches. These are output in parallel with the results from the standard processing.</p><p>The grouping operation is optional. You can also choose to extract entities using only a name catalog.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Note:</head><p>The output of custom rules matching can overlap with the output from standard processing and with name catalog only extraction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Name Catalog Lookup</head><p>In this operation, ThingFinder searches the name catalog for matching entries. In addition to the entity candidates generated by the language modules, the name catalog lookup generates entity candidates, and the lookups contribute to the precision of the entity generation. You can use a name catalog to identify lists of known entities, and to match variant names in a standard output format. Because name catalogs are language-independent, this lookup is also independent of the document language. The name catalog lookup is optional.</p><p>The name catalog lookup is divided into two types, determined by the presence of wildcards in the name catalog entries. For more information, refer to the ThingFinder Customization Guide.</p><p>• Entries with Wildcards-The name catalog looks up sentences to match entries with wildcards. Sentences form the candidate set for matching with wildcard name catalog entries. Matching entries are returned with the name catalog entity type.</p><p>• Entries without Wildcards-The name catalog looks up the entire text segment used for processing, without regard to sentence and paragraph boundaries. Matching entries are extracted from the text and returned with the name catalog entity type.</p><note type="other">ThingFinder Processing Entity Selection 3</note><p>Concepts Guide 21</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Entity Selection</head><p>Entity selection is the process of narrowing down the possible entity candidates to one entity if possible. This process combines the discovery and the lookup results. First, the output of the grouping operation is compared with that of the name catalog lookup; then, these are combined to form nonoverlapping entities. A selection is made according to several principles that maximize precision, and entities are returned with their entity types and the method by which the type was assigned.</p><p>Note: Entity selection diminishes overlapping entities if possible. However, there are items that return overlapping entities, including custom extraction rules (these do not participate in the selection process at all), some name catalog entities (once name catalog entity can overlap another), and common mentions.</p><p>This section also describes three optional post-processing steps that help precision: aliasing, conjecture and relevance ranking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Selection Principles</head><p>This section discusses the principles used in selecting an entity and its type, and how they interact in some possible scenarios. ThingFinder selects entity types according to the following principles:</p><p>• Length The longest matching group takes precedence.</p><p>• Occurrence in the Name Catalog Occurrence in the name catalog ensures that the entity will be found.</p><p>• Linguistic Confidence Some entity types are more likely than other types, and miscellaneous proper nouns are least likely.</p><p>• Entity Type Weighting You can assign more weight to specific entity types.</p><p>• Filters If you specify filters, then only requested entity types are returned.</p><p>The following sections also describe the related topics of Conjecturing and Ambiguity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Length</head><p>As a general rule, ThingFinder gives precedence to the group with the largest scope, i.e. the longest matching group is selected. As an example, consider the scenario where a group is identified along with enclosed sub-groups, as in the sentence He lives at 1600 Pennsylvania Avenue, which contains the following groups: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Occurrence in the Name Catalog</head><p>After length, the next principle of entity selection in a name catalog is occurrence. As a general rule, if you list an entity in your name catalog, it is found during entity extraction. An entity that is found by the language modules but is also found in the name catalog is evaluated as follows:</p><p>• If the entity type is PROP_MISC and the entity is the same length as the name catalog entry, then the name catalog entry takes precedence.</p><p>• If the entity contains smaller entities listed in the name catalog, the entity found by the language modules take precedence over the name catalog entities.</p><p>For example, in the He lives at 1600 Pennsylvania Avenue discussed above, [Pennsylvania]STATE is not returned even if it's in your name catalog. To avoid this, you can use the name catalog alone for extraction, or you can use the category filters to exclude the larger entity type.</p><p>• If the entity is ambiguous, then both types are returned.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Linguistic Confidence</head><p>For each entity, ThingFinder determines the most likely type. Linguistic confidence comes into play when the language modules detect more than one possible type for an entity with the same length. For example, Houston may be a PERSON_GIV, but it is most commonly a CITY.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ThingFinder Processing</head><p>Entity Selection 3</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Concepts Guide 23</head><p>During entity selection, ThingFinder assigns a confidence score between 1 and 30 to each found entity. This score indicates ThingFinder's degree of confidence in its identification of the current entity. A score of 30 indicates a custom rule match, 1 indicates that the entity is ambiguous, and 2-29 indicate a combination of factors, including language modules, category, proximity of similar entities in the text, and so on.</p><p>The following describes the linguistic confidence values and their meanings:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Entity Type Weighting</head><p>ThingFinder lets you assign relative weights to different entity types. When an entity is ambiguous between two different types, the entity type weighting is used to select the final interpretation. For instance, if you know that the current set of documents consists largely of market reports, you weigh towards the COMPANY interpretation.</p><p>Note: Entity type weighting only affects the output of the language modules and does not resolve ambiguities involving multiple entries in the name catalog.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Filters</head><p>You can use a filter while extracting entities to specify the entity types that you wish to extract. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method and Confidence</head><p>ThingFinder indicates the method used in entity selection, as one of the following:</p><p>During entity selection, ThingFinder assigns a confidence score between 1 and 30 to each found entity. This score indicates ThingFinder's degree of confidence in its identification of the current entity. A score of 30 indicates a custom rule match, 25 indicates unique identification, and 1 indicates that the entity is ambiguous, and 2-29 indicate a combination of factors, including category, proximity of similar entities in the text, and so on.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ambiguity</head><p>An entity is ambiguous when its type cannot be identified uniquely. This happens when there is either too little or too much information about the entity.</p><p>• There is too little information when an entity is identified only as a proper noun and no type can be assigned. For example, in The XYZ is funny, XYZ is a noun according to the context, but it can't be further identified. In such cases, ThingFinder classifies the entity in question as PROP_MISC, indicating a miscellaneous proper noun.</p><p>• There is more than one possible entity type:</p><p>• If an entity matches more than one entity in the name catalog. The matching entities may or may not belong to the same type. For example, in analyzing United announced Q3 results, if the name catalog lists United as a variant of more than one entity, e.g. of</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method Description</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Unique</head><p>The entity name and category are unique according to the language modules.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conjectured</head><p>The entity name or category were ambiguous, and ThingFinder resolved the ambiguities by comparing several entities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Name Catalog</head><p>The entity name and category were found in the specified name catalog.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ambiguous</head><p>The entity name or category were ambiguous, and ThingFinder was unable to resolve the ambiguity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Custom Grouper Entity</head><p>The entity name and category derived from custom extraction rules.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Custom Grouper Fact</head><p>The fact name and category derived from a custom extraction rules.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ThingFinder Processing</head><p>Entity Selection 3</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Concepts Guide 25</head><p>United Airlines and United Steel, then it will find several entities sharing the name variant United. In this case, multiple entities are returned.</p><p>• When different entities have the same confidence, then they are returned with an ambiguous reading. The ambiguity can be resolved later via conjecture or by category weighting in the &lt;language&gt;- tf.config file. An example of this is the sentence Georgia's budget is balanced, in which Georgia is ambiguous between a PERSON, STATE, and COUNTRY.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Post-Processing</head><p>There are three optional post-processing steps that ThingFinder performs:</p><p>• Conjecturing • Aliasing • Relevance Ranking Note: These steps can improve precision or recall. However they are resource-intensive, and therefore they should be turned off, if they are not already.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conjecturing</head><p>ThingFinder conjecturing is informed guesswork to resolve the type of an unknown or ambiguous entity, based on comparison with similar entities in the input buffer. Conjecture also searches the name catalog to match unknown or ambiguous entities with the canonical forms of entities stored there. An entity is ambiguous either because it has been labeled PROP_MISC or because more than one entity type has been assigned to it with the same confidence.</p><p>During conjecturing, ThingFinder searches the entire input buffer or document, both forward and backward, for similar, co-occurring entities, starting with the longest entities. Word properties such as case, punctuation, titles, etc. are ignored during conjecturing. If the document contains more than one candidate for conjecture, then ThingFinder uses distance to select an entity type. That is, an unknown entity is conjectured to the closest, matching, known entity. When conjecturing an ambiguous entity, ThingFinder only seeks to resolve the ambiguity within one of the types already assigned.</p><p>The distinction between strong and weak conjecture reflects the expected accuracy of the applied conjecturing. The more similar two entities are, the more likely it is that they have the same referent.</p><p>Consider the PROP_MISC example below and the ThingFinder output for it: Example Washington is buzzing with excitement. For the first time, the northwestern state is sending a president to the nation's capital.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Aliasing</head><p>An alias is an alternative name for an entity, and aliasing is the process of grouping together text references to the same entity, regardless of their variation in form. For instance, if William Jefferson Clinton and Mr. Clinton are found in the same input buffer, and they're listed as variant names in the name catalog, then they'll be grouped as aliases of the same entity.</p><p>The ThingFinder aliasing capability handles the following variations:</p><note type="other">ThingFinder Processing Entity Selection 3</note><p>Concepts Guide 27</p><p>When enabled, ThingFinder collects aliases into an alias group. Some alias groups contain only a single reference, indicating that the relevant entity was referred to only once. The reference is nevertheless considered an "alias", so that each entity is available without the duplication inherent in a full list of entity references.</p><p>You can configure how aliasing is performed with respect to titles and abbreviations by modifying the tf.aliasing-config file. In that file, you can specify titles and abbreviations that should be ignored for aliasing. For more information about configuring aliasing, refer to the configuration chapter in the ThingFinder Language Guide and Reference.</p><p>Note: Aliasing doesn't cover cases such as William==Bill and Robert==Bob. Aliasing groups entities found by the language modules with those in a (user-defined) name catalog. However, the entity type name is case-sensitive.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Feature</head><p>Big Blue == I.B.M.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multi-word tokens</head><p>An entity containing one or more multi-word tokens is aliased to the same string of characters segmented differently.</p><p>Mike Tyson (single multi-word token) == Mike Tyson (two tokens)</p><formula xml:id="formula_5">3 28 Concepts Guide</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Relevance Ranking</head><p>Relevance ranking measures the relevance of a given entity to the core themes of its document, providing a way to quickly identify those entities that reflect the subject of the document. Relevance ranking requires that entity aliasing has been performed.</p><p>The relevance score for a given entity is based on the following factors:</p><p>• Count of coreferential entities Co-referential entities are counted, and aliased and conjectured entities are assigned the same relevance score.</p><p>• Entity type weight The entity type weight, if set in the tf.relevance-config file.</p><p>• Sentence weight This takes into account that some sentences are more important than others, such as titles and headings.</p><p>You can configure relevance ranking by modifying the tf.relevance- config file. Among other things, this file lets you control the weight of different entity types and the weight given to entities occurring in titles and headings. For more information about configuring relevance ranking, refer to the configuration chapter in the ThingFinder Language Guide and Reference.</p><p>Relevance scores are in the range of -1 and 100. A value of -1 indicates that relevance ranking wasn't performed because it wasn't requested or because aliasing wasn't performed. A value of -1 is also returned for sub-entities, which are not ranked for relevance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Note:</head><p>The relevance score and confidence score calculations are independent of each other. When several text references refer to the same entity, they are aliases of each other and can be collected into an alias group.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>alias list</head><p>An alias list contains zero or more alias groups. aliasing</p><p>The process of determining which entities refer to the same objects and are therefore aliases of each other. ThingFinder uses co-occurrence analysis and a name catalog to determine that entities in an input buffer are aliases of one other. When enabled, ThingFinder collects aliases into an alias group. Some alias groups contain only a single reference, indicating that the relevant entity was referred to only once. ambiguity Ambiguity occurs when a reference to an entity can be identified with more than one entity type or when there's not enough information to uniquely identify the entity type. For example, a name like Houston can be either a CITY or a PERSON_FAM. canonical name A canonical name is the standard form for an entity; generally it is the longest, most precise or official name of the object. The canonical name is listed in a name catalog. CGUL Custom Grouper User Language. CGUL is a token-based language that enables you to perform pattern matching using character or token-based regular expressions combined with linguistic attributes to define custom rules. conjecture</p><p>The process of determining the type of an ambiguous entity. An entity may be ambiguous either when its type can't be identified or when it is assigned more than one type. ThingFinder performs conjecture, if possible, by comparing the ambiguous entity with known entities that occur in the same document. For example, if a text contains [Mr. Dixon]PERSON and later contains [Dixon]PROP_MISC, ThingFinder conjectures the second reference as a PERSON. co-reference Mention of a given entity in an input buffer, by any of its possible names.</p><p>Esther Dyson, Dyson, Ms. Dyson, and Esther are all possible references to an entity [Esther Dyson]PERSON. A reference may be the canonical name or variant name from a name catalog. All references to the same entity can be collected in an alias group.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>custom entity type</head><p>Entity types you create by writing rules that define each entity type. Custom entity types enable you to perform specialized extraction, customized to your specific needs.</p><p>Glossary 4</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Concepts Guide 31 disambiguati on</head><p>The process of resolving ambiguity. Ambiguity arises when there is more than one possible type for an entity or the entity's type is not known. entity An entity denotes the names of people, places, and things that can be extracted from text. Each ThingFinder entity is defined as a pairing of a name and its type. For example, [Winston Churchill]PERSON is an entity in which Winston Churchill is the entity name and PERSON is the entity type.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>entity type</head><p>The category an entity falls into. For example, [Janet Reno]PERSON is an entity in which Janet Reno is the entity name and PERSON is the entity type. You can define your own entity types by using the name catalog and by writing CGUL rules.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>entity subtype</head><p>A hierarchical specification of an entity type that enables the distinction between different varieties of the same entity type. For example, to distinguish Land Vehicles from Air Vehicles. enumeration The ThingFinder feature that automatically generates predictable variant names for entities listed in a name catalog. An enumeration tag must be listed in the name catalog entry for the given entity. event An event denotes an activity, event, or action that can be extracted from text. language module A set of files containing knowledge about a given natural language.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>method</head><p>The method ThingFinder used to identify the entity and its type. name catalog A user-defined repository of information about entities-their canonical name and variant names, their entity types, etc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>name catalog compiler</head><p>A tool for compiling files into the name catalog format that lets you add and remove entities, override entity types, add name variants, add and remove entity types, etc. normalization The process of normalizing the form of a name to a predefined standard. For instance, ThingFinder normalizes numeric entities in the entity types DATE, CURRENCY, PERCENT, and YEAR only into standard formats defined by the International Standards Organization. noun group A NOUN_GROUP is any common noun sequence consisting of two or more related nouns and not identified as a name, measure, or identifier. The entity type NOUN_GROUP is supported in all the ThingFinder language modules. relationship A relationship denotes two or more entities that have a specific connection, or a connection between events and their participants, that can be extracted from text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>relevance ranking</head><p>Measures the relevance of a given entity to the central themes of the document in which it occurs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Term Definition</head><p>Glossary 4 32 Concepts Guide segment An unprocessed piece of text from the input document. A segment holds text and metadata for one or more complete paragraphs of the text being processed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>sub-entity</head><p>An embedded entity of the same semantic type as the containing entity. The sub-entity has a prefix that matches that of the larger, containing entity. For example, [1600]ADDRESS_NUM is a sub-entity of [1600 Pennsylvania Ave.]ADDRESS, but [1600]YEAR is not, because it doesn't have a matching ADDRESS prefix. variant name An alternative name for the same entity. An entity can have zero or more variant names associated with its canonical name, all of which are variants. For instance, United Parcel Service of America, Inc., United Parcel Service, and UPS are all variant names of the same entity. variant type A variant name in a name catalog can optionally be typed. A variant type indicates what sort of name the variant is. For example, to identify a given variant as an abbreviation, you might define a type ABBREV in your name catalog.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>word segmentation</head><p>The process of breaking input text into its component parts-words, multiword tokens, numbers, and punctuation marks. This is also known as tokenization. XeLDA ® is a multilingual linguistic engine. It models and standardizes unstructured documents in order to automatically exploit their content. Based on a technology developed through 20 years of research and development, XeLDA ® supplies advanced solutions to the issues of processing written information, providing expertise, command of natural language and multilingualism.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Term Definition</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Concepts</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Who is XeLDA ® designed for?</head><p>Are you a solutions developer, software publisher or systems integrator? XeLDA ® enables you to embed the most advanced natural language processing services in your applications. With XeLDA ® , you bring true added value to your customers by offering them new products and services, based on accurate understanding of language.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Text Intelligence™</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>How XeLDA ® works</head><p>XeLDA ® offers a scalable range of services based on natural language processing components that you can integrate in your business applications:</p><p>&lt;&lt; Language identification: automatically recognizes the language used by each document &lt;&lt; Segmentation: divides a text into sentences &lt;&lt; Tokenization: splits a text into basic lexical units &lt;&lt; Morphological analysis: returns the normalized form (the lemma) and the potential grammatical categories for all the words identified during the tokenization stage &lt;&lt; Morpho-syntactic disambiguation: determines the exact grammatical category of a word according to its context &lt;&lt; Extraction of noun phrases: extracts sequences of words that form noun phrases &lt;&lt; Dictionary lookup: identifies the context of a word to find the corresponding dictionary entry &lt;&lt; Recognition of idiomatic expressions: recognizes the expressions found in a text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Specifications</head><p>Copyright © 2003 TEMIS Holding. All rights reserved. Product appearance and/or specifications may be modified without prior notice. XEL.2.5.032005</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Contact</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Contact</head><p>XeLDA ®</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt;&lt; Operating systems and compilers supported:</head><p>-Windows NT, 2000, XP with Microsoft Visual C++ 6 -Solaris 9 with Sun Compiler Forte 7 -Linux RedHat 8 with gcc 3.2 -Java Runtime Environment 1.3 and higher</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt;&lt; API :</head><p>-C++, Java, -documentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt;&lt; Source languages:</head><p>Czech, Dutch, English, French, German, Greek, Hungarian, Italian, Polish, Portuguese, Russian, Spanish.</p><p>New ̈Nordic Language Pack: Danish, Finnish, Swedish, Norwegian (Bokmal).</p><p>Other languages are being developed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt;&lt; Bilingual dictionaries:</head><p>Dutch, English, French, German, Italian, Spanish.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discover the TEMIS product range</head><p>XeLDA ® is the technology used at the core of Insight Discoverer™ Extractor, the information extraction engine, and XTS, the corporate terminology suite. Insight Discoverer™ Extractor offers solutions tailored to your company's different business areas using Skill Cartridges™. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt;&lt; Grenoble</head><p>Tel. : +33 (0)4 56 38 24 00 Fax : +33 (0)4 56 38 24 01 info@temis-group.com</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TEMIS Germany</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt;&lt; Heidelberg</head><p>Tel. : +49 -6221 13753-12 Fax : +49 -6221 13753-14 info.de@temis-group.com</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TEMIS Italy</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt;&lt; Modena</head><p>Tel. : +39 -059 237 634 Fax : +39 -059 220 093 info.it@temis-group.com</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TEMIS United Kingdom</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt;&lt; Bristol</head><p>Tel. : + 44 (0)117 949 8646 info.uk@temis-group.com</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TEMIS USA</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt;&lt; Washington</head><p>Tel. : +1 703 823 57 45 info.us@temis-group.com</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>www.temis-group.com</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>About This Overview</head><p>The Xerox Linguistic Development Architecture (XeLDA) is a toolkit for developing custom linguistic applications. The XeLDA engine can be used to transform, normalize, and extract information from text. This overview introduces the XeLDA linguistic services and the modes in which XeLDA applications can operate. This overview is designed for researchers and developers in the fields of computing and linguistics who understand linguistic terminology. This overview uses the following style conventions:</p><p>υ Monospaced font: this typeface is used for any text that appears on the computer screen or text that you should type. It is also used for file names, functions, and examples.</p><p>υ Monospaced italic font: this typeface is used for any text that serves as a placeholder for a variable. For example, dataType indicates that the word dataType is a placeholder for an actual data type, such as CString. υ Internal cross references: this format is used to indicate crossreferences within the manual. If you are working on an electronic copy of the manual, click the cross-reference to go directly to the section it references.</p><p>This overview contains the following sections: In addition to this overview, the documentation set for XeLDA includes the following manuals:</p><p>υ XeLDA Installation Guide: provides procedures for installing XeLDA. υ XeLDA C++ API Programmer's Guide: provides information about creating custom natural language processing applications using the XeLDA C++ API. υ XeLDA Java API Programmer's Guide: provides information about creating custom Java applications using the XeLDA Java API. υ XeLDA C++API Reference Manual: provides a complete reference to all of XeLDA's public C++ classes. υ XeLDA Java API Reference Manual: provides a complete reference to all of XeLDA's public Java classes. υ XeLDA Tagsets: for each language supported by XeLDA, a file describing the Part-Of-Speech tags is available in the directory docs of the xelda installation directory. υ XeLDA Customization Guide: provides detailed information about building custom XeLDA services. υ XeLDA Server User's Guide: describes the server shipped with XeLDA. υ XeLDA Command-Line Client User's Guide: describes the client shipped with XeLDA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction to XeLDA</head><p>XeLDA is an engine for transforming, normalizing, and extracting information from text.</p><p>It is a comprehensive set of tools, which can be incorporated into applications written in Java or C++ to provide text processing in a number of different natural languages by applying linguistics theory and science.</p><p>The Following the acquisition by the TEMIS group of the entire business activity of XeLDA (product development, marketing and sales), the whole product is now fully supported by TEMIS, starting from July 2 nd , 2003.</p><p>The facilities provided by XeLDA, called linguistic services, include:</p><p>υ Language identification: recognizes the language used by a selected text. υ Tokenization: divides the selected text into words.</p><p>υ Morphological analysis: provides the normalized form and all potential part of speech categories for each word identified during tokenization. υ Part of speech disambiguation: finds the correct grammatical category of a word according to its context within a text. υ Noun phrase extraction: identifies a sequence of words that behaves together as a noun. υ Dictionary lookup: retrieves a word's context and uses this context to find the correct entry in the dictionary. υ Idiom recognition: recognizes idiomatic expressions in a text.</p><p>υ Relational morphology: groups words according to their derivational family.</p><p>Each linguistic service is described in detail later in this document.</p><p>The XeLDA architecture can handle most written languages.</p><p>Most XeLDA services support West-European languages and several East-European languages.</p><p>Middle East and more East-European languages are in active development.</p><p>XeLDA runs in the Intel/Linux, Sparc/Solaris and Windows environments and can be tailored for others.</p><p>XeLDA is written in C++ but can also connect to applications written in Java.</p><p>To develop a Windows application that uses the XeLDA SDK, you must work on Windows 2000 and compile using the Microsoft Visual C++ Compiler version 6.0.</p><p>For Solaris applications, use Sun Solaris 8 and compile using the Sun WorkShop 6 update 2 C++ Compiler.</p><p>For Linux applications, use RedHat 8 and compile using the GNU gcc 3.2 C++ Compiler.</p><p>XeLDA acts as a server to a client application and is based on an open architecture that lends itself to the integration of future Xerox proprietary Finite State research results as well as third party linguistics components.</p><p>XeLDA has two operating modes: client-server and stand-alone (or monoprocess) mode. In client-server mode, all linguistic processing takes place on the server machine. In stand-alone mode, the client and server are merged into a single executable.</p><p>XeLDA embraces the open architecture of a package running in a UNIX or Windows environment. As such, it is designed to provide a framework into which developers and researchers can seamlessly integrate further linguistics services and resources.</p><p>Potential applications of the XeLDA engine include comprehension aids and translation or syntax checking, terminology extraction, and other general authoring tools.</p><p>XeLDA is a toolkit that provides linguistic processing to client applications.</p><p>A sample Windows application, wxeldac, is bundled with the XeLDA toolkit and demonstrates XeLDA's linguistic services.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 1 -The wxeldac application main screen, which demonstrates XeLDA functions</head><p>Some features are available only through programming. See the XeLDA C++ Programmer's Guide for more information.</p><p>υ For C++ or Java examples, go to the samples folder in the XeLDA install tree. A description, a brief explanation of the technique used, the available languages, an example, and reference data are given for each service. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Language Identification _____________________________</head><p>The language identification service recognizes the language used to write a text, even if the text is written without accented characters.</p><p>It is called either explicitly or transparently when the user does not specify the language for a particular service.</p><p>The language identification service is extremely fast and reliable, working optimally with five words or more.</p><p>The language identification service uses the Trigram and Short Words method, also known as TRISHORT.</p><p>The language identifier service has been trained on many texts in various languages so it has a statistical background. Using this statistical information, it determines the following:</p><p>υ The frequency of the three-character sequences in every language.</p><p>υ The frequency of common short words (five characters or less) such as "the", "of", and "is".</p><p>38 languages are supported. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Tokenization ______________________________________</head><p>The tokenization service performs the basic function of cutting a text into words.</p><p>It is generally harder that it sounds. Punctuation, abbreviations, units of measure, clitics, multiword expressions, and special cases must be considered. Some examples follow:</p><p>υ In French, "parce que" and "aujourd' hui" are single words, while "l' ami" and "j' ai" are composed of two words. υ In English, "e.g." and "i.e." are single words, and "don' t" is composed of two words. The possessive "' s" as in "St Paul' s Cathedral" must be kept with the previous word. υ The dash may represent the hyphenation of a single word that did not fit on the line. υ A character may belong to two words. For example, in French, "donne-le" should be tokenized as "donne-" + "-le". υ In German and agglutinative languages, a single word may be composed of several parts. For example, "Bundesfinanzminister" is made of three nouns. The tokenization service keeps the word together, and it is the morphological analyser' s job to extract the individual parts.</p><p>For all supported languages, XeLDA tokenizes texts with a finite-state transducer (FST).</p><p>For unsupported languages, there is a simple algorithm that uses spaces and punctuation for basic tokenization.</p><p>Czech, Dutch, English, French, German, Greek, Hungarian, Italian, Polish, Portuguese, Russian, and Spanish. Other languages are in development. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Morphological Analysis _____________________________</head><p>The morphological analysis service finds all the possible combinations of base form and part of speech corresponding to a given inflected word.</p><p>For example, the word "levels" will be analyzed as either "level", a plural noun, or as "to level", a verb in third person singular present tense.</p><p>The base form of a word is the form used as headword in a dictionary. This is language-dependent. For example, in French and English the base form for a verb is the infinitive, while in Latin the base form is the first person of the present tense.</p><p>Various morphological phenomena (such as gender, number, case, contraction and elisions, and vowel harmony) are taken into account, depending on the language being analyzed.</p><p>The part of speech is coded as one or a series of tags. Each tag represents a grammatical category. However, the tags do not adhere to all of the usual grammatical categories, sometimes being combined to optimise processing and improve efficiency. Examples of tags are "+Noun", "+Coord" (coordinating pronoun), "+SubjP" (Present subjunctive).</p><p>There is a different set of tags for each language. The tag set is optimized for the next step, disambiguation. The disambiguation service decides which one of the different possibilities is the right one in the given context.</p><p>The tags list for each supported language is found in the docs directory of the xelda installation directory.</p><p>The morphological analysis service uses finite state transducers (FST). A FST transforms one string into another in an extremely speed-and spaceefficient manner. FSTs are combined in strategies, a series of transducers, the output of each being the input of the next. If a strategy fails to find a match, then the next one is used.</p><p>Using a series of transducers is necessary for several reasons. A word may not be properly accentuated or capitalized, in which case one of the transducers will normalize it to the "standard" form before passing it to the next. Also, a specialized transducer may be created with domain-specific terms.</p><p>Finally, neologisms and unknown words are taken into account by a "guesser", which will try to find the part of speech of an unknown word.</p><p>For English this is based on rules like:</p><p>υ -----y = adverb υ ---ed = verb/adj </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Part of Speech Disambiguation ______________________</head><p>The part of speech disambiguation service follows the morphological analysis. It removes the ambiguity by choosing one base form plus tag for each word from the list proposed by the morphological analysis service.</p><p>To make the choice, the part of speech disambiguation service chooses the most probable tag in the word context. Many other modules depend on the results produced by the disambiguation service, making its accuracy important. Depending on the language, the part of speech disambiguation service finds the grammatical category of a word with an accuracy of more than 95%.</p><p>The disambiguation service is a basic component for many more sophisticated services.</p><p>The disambiguation service relies on a Hidden Markov Model engine. This engine has been trained on carefully chosen, manually tagged corpus for each language and the result of this training is used by XeLDA to disambiguate new texts.</p><p>The disambiguation service takes the results from the morphological analysis service and retains, for each word, the most probable tag in the word context.</p><p>The output of the disambiguation service is usually a single base form + tag for each input word. However, some semantic ambiguities may remain after part of speech disambiguation. For example, in French the word "MODELE" is disambiguated to either modèle+NOUN_SG or modelé+NOUN_SG. The part of speech ambiguity has been removed, but not the semantic ambiguity.</p><p>As a convenience of language, the phrase "Part of Speech Tagging" is often used to describe the sequence of tokenization, morphological analysis, and disambiguation.</p><p>Czech, Dutch, English, French, German, Greek, Hungarian, Italian, Polish, Portuguese, Russian and Spanish. Other languages are in development.</p><p>υ For programming details, see the XeLDA C++ API Programmer's Guide and the XeLDA Java Programmer's Guide. υ For the C++ example, see the "Disambiguation" folder. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Text Extraction ____________________________________</head><p>A noun phrase is a sequence of terms that behave together as a noun.</p><p>"Noun phrase" and "sequence of terms" are themselves noun phrases, as are "red power cord" and "geostationary communications satellite".</p><p>The noun phrase extraction service is a powerful tool to get candidate terms for a glossary, or as a front-end for other linguistic processing.</p><p>The noun phrase extraction service uses the XeLDA tokenization, morphological analysis, and disambiguation services.</p><p>It extracts noun phrases according to language-dependent patterns, resulting from Xerox linguistic research.</p><p>The individual components of the noun phrases are also returned, with their disambiguated base form and part of speech.</p><p>Czech, Dutch, English, French, German, Greek, Hungarian, Italian, Polish, Portuguese, Russian and Spanish. Other languages are in development.</p><p>υ For programming details, see the XeLDA C++ API Programmer's Guide and the XeLDA Java Programmer's Guide. υ For the C++ example, see the "TextExtraction" folder.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>! ! "</head><p># About XeLDA's Linguistic Services XeLDA white paper 20</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dictionary Lookup _________________________________</head><p>A word can have several meanings, depending on the context in which it is used. The dictionary lookup service retrieves the word context and can use this context to find the correct entry, the target, in a dictionary.</p><p>Several types of dictionaries are supported, including monolingual, synonym, and bilingual.</p><p>The dictionary lookup service may be contextual or not, can look for idiomatic expressions, and can return examples from the dictionary.</p><p>The dictionaries used are encoded in XML or SGML and compiled into a XeLDA dictionary.</p><p>XeLDA first does a disambiguation on the word, in context, to get the proper base form and part of speech.</p><p>Idiomatic expression recognition is attempted. If there is a match, this expression is shown.</p><p>The dictionary is then searched and the result (translation for a bilingual dictionary) is shown.</p><p>For example, a text would be analysed as follows:</p><p>Examples or idiomatic expressions or both can be shown, depending on the options set by the user.</p><p>English, French, German, Italian and Spanish as source languages, any language as the target language.</p><p>υ For programming details, see the XeLDA C++ API Programmer's Guide and the XeLDA Java Programmer's Guide. υ For the C++ example, see the "DictionaryLookup" folder.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>! ! "</head><p>A spark plug does not work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>bougie brancher</head><p>The contextual dictionary lookup of the word "Rights" using an English-French bilingual dictionary occurs as follows in the wxeldac sample application:</p><p># About XeLDA's Linguistic Services XeLDA white paper 22</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Idiom Recognition _________________________________</head><p>DescriptionAn idiom is a group of words that have a meaning not deducible from the meaning of the individual words.</p><p>Idioms may have some variability, for example verbs may be conjugated, nouns may be inflected, and adverbs or adjectives may be inserted. Some words have a particular meaning when they disambiguate in a certain way.</p><p>Some idiomatic expressions may be used for domain-specific expressions or may point to particular entities. For example, a name followed by "Inc." or its variants points to a particular kind of company.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Some examples of idiomatic expressions follow:</head><p>υ "To take the bull by the horns", which may be interpreted as "he took quickly and firmly the bull by the horns." υ "&lt;noun&gt;", followed by variants or abbreviations of "Chief Executive Officer", pointing both to a proper name and rank in a company. υ "spark plug", "operating system", "gasket joint", and "reverse" can be disambiguated as nouns depending upon the context.</p><p>XeLDA provides an idiomatic regular expression language (IDAREX) to describe idiomatic expressions. With IDAREX, you can define:</p><p>υ Invariants (exact spelling).</p><p>υ Words that can appear optionally. For example, an adjective can appear in a phrase but is not required. υ Repetition.</p><p>υ Specific words when they disambiguate in a specific category, such as adjective, determiner, noun, verb. For example, you could specify that the word "level" be counted only when used as an adjective. υ Any word of a specific category: adjectives, adverbs, negatives, and clitic pronouns. υ Macros helping to define particular constructs, such as VPRON(verb): Verb + variable clitic. In Spanish, this macro is interpreted as follows: VPRON(dar) = darle, le he dado, me das, nos daba, les dará, and so on.</p><p>XeLDA provides an idiomatic expression compiler. The user may define custom expressions, using the categories and macros provided with the language library, and incorporate the compilation result in the XeLDA configuration files.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>! ! "</head><p>The idiom recognition service is available through the dictionary lookup service.</p><p>υ For programming details, see the XeLDA C++ API Programmer's Guide and the XeLDA Java Programmer's Guide. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Relational Morphology _____________________________</head><p>Often, you need to know the family to which a word belongs. For example, the word "Presidential" is related to the word "President".</p><p>The relational morphology service allows the grouping of words that belong to the same derivational family. Each family is characterized by a representative word. There are two relational morphology services integrated into XeLDA:</p><p>υ Relational morphology service: this service returns a single word representative of the derivational family. υ Reverse relational morphology service: this service returns all the words belonging to the derivational family.</p><p>These services are used for the following:</p><p>υ Categorizing words and documents.</p><p>υ Expanding queries by finding all related words and expressions.</p><p>The relational morphology service is a special type of morphological analyser that defines the relational family based on the prefix of a word.</p><p>The relational morphology service first requests the disambiguation service on the whole text. Then, for each word in the text, it:</p><p>υ Gets the base form of a word.</p><p>υ Performs a relational morphological analysis on the base form.</p><p>English, French, German, Italian and Spanish.</p><p>υ For programming details, see the XeLDA C++ API Programmer's Guide and the XeLDA Java Programmer's Guide. υ For the C++ example, see the "MorphoAnalysis" folder.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>! ! "</head><p>This request is sent to the server via the communication link (which can be a direct connection in the case of a stand-alone application). This request is executed on the server by the XeLDA kernel, which calls the appropriate linguistic service.</p><p>The result is generated either in raw format or formatted according to what the client specifies. Raw format is easier to manipulate by the client whereas a formatted result is easier to display or print. After the result is generated, it is sent back to the client. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Client Server</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Developing Applications With XeLDA</head><p>The XeLDA services are available in the XeLDA toolkit for creating custom language processors, either using XeLDA services "out of the box" or combining them to get the results you need.</p><p>XeLDA can be customized, meaning customer lexicons and expressions can be integrated into the XeLDA toolkit.</p><p>XeLDA is an evolving product. It constantly incorporates new modules and languages from Xerox or third-party linguistic researchers. One of XeLDA's design goals is the ability to quickly integrate cutting-edge results into mainstream processing.</p><p>For more information, refer to the following documents:</p><p>υ The XeLDA C++ API Programmer's Guide for information about using the XeLDA C++ SDK to create custom language processing applications. υ The XeLDA Java API Programmer's Guide for information about creating custom Java applications using the XeLDA Java API. υ The XeLDA Reference Manuals for information about all of XeLDA's public classes.</p><p>For more information on XeLDA, please contact: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Glossary of Terms</head><p>ANSI: American National Standards Institute. For more information, go to http://www.ansi.org/.</p><p>Character: the smallest component of written language with semantic value.</p><p>Character Set: a complete group of characters for one or more writing systems.</p><p>Clix: A C++ library that provides a collection of general functionalities, grouped by packages.</p><p>Coded Character Set: a mapping from a set of abstract characters to a set of integers.</p><p>Dictionary Lookup: a linguistic service that retrieves a word's context and uses this context to find the correct entry in the dictionary.</p><p>Finite State Technology: see FST.</p><p>FST: Finite State Technology. An FST is a network of states and transitions that work as an abstract machine to perform dedicated linguistic tasks. For example, the XeLDA morphological analyzer tokenization resources are encoded as FSTs.</p><p>IANA: Internet Assigned Numbers Authority, the central coordinator for the assignment of unique parameter values for Internet protocols. For more information, go to http://www.iana.org/.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IDAREX: Idiomatic Regular Expression language.</head><p>Idiom: a group of words having a meaning not deducible from each of the individual words.</p><p>Idiom Recognition: a linguistic service that recognizes idiomatic expressions in a text.</p><p>IETF: Internet Engineering Task Force, an internal community of network service providers concerned with Internet architecture and operation. For more information go to http://www.ietf.org/.</p><p>ISO: International Organization for Standardization, a worldwide federation of national standards bodies. For more information, go to http://www.iso.ch/.</p><p>Language Guesser: see Language Identification.</p><p>Language Identification: a linguistic service that recognizes the language and character set used to write a document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Objectives:</head><p> To study the nature of language (Linguistics) </p><formula xml:id="formula_6"></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Word Sense</head><p>The man went to the bank to get some cash. and jumped in.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Case</head><p>He ran the mile in four minutes. the Olympics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Referential</head><p>I took the cake from the table and washed it. ate it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Indirect Speech Acts</head><p>Can you open the window? I need some air.  Disadvantages:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Parsing in NLP</head><formula xml:id="formula_7">(agrees * V) (SETR SUBJ*) (agrees SUBJ *) (SETR V *) (AND (GETF PPRT) (= V "BE")) (SETR OBJ SUBJ) (SETR V*) (SETR AGFLAG T) (SETR SUBJ "SOMEONE") (TRANSV) (SETR OBJ *) AGFLAG (SETR AGFLAG FALSE) T (SETR SUBJ *)</formula><p> Different grammar required for each new domain  Lack of overall syntax can lead to "spotty" grammar coverage (e.g. fronting possessive in "&lt;attribute&gt; of &lt;ship&gt;") doesn't imply fronting in "&lt;rank&gt; of &lt;officer&gt;")  Difficult to develop grammars  Suffers from same fragility as ATNs</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Case Frames</head><p>Case frames were introduced by Fillmore (a linguist) to account for essential equivalence of sentences like:  "John broke the window with a hammer"  "The window was broken by John with a hammer"  "Using a hammer, John broke the window" [head: BREAK agent: JOHN object: WINDOW instrument: HAMMER ]</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Case Frames</head><p>Fillmore postulated finite set of cases applicable to all actions:</p><p>[head: &lt;the action&gt; agent: &lt;the active causal agent agent instigating the action&gt; object: &lt;the object upon which the action is done&gt; instrument: &lt;an instrument used to assist in the action&gt; recipient: &lt;the receiver of an action-often the I-OBJ&gt; directive:&lt;the target of an (usually physical) action&gt; locative: &lt;the location where the action takes place&gt; benefactive: &lt;the entity for whom the action is taken&gt; source: &lt;where the object acted upon comes from&gt; temporal &lt;when the action takes place&gt; co-agent: &lt;a secondary or assistant active agent&gt;]</p><p>Case Frame Examples "John broke the window with a hammer on Elm Street for Billy on Tuesday" "John broke the window with Sally" "Sally threw the ball at Billy" "Billy gave Sally the baseball bat" "Billy took the bat from his house to the playground"</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Robust Parsing</head><p>Spontaneously generated input will contain errors and items outside an interface's grammar  </p><formula xml:id="formula_8">L 1 L L 2 L L 3 L L 4 L Interlingua Paradigm for MT (2N) L 1 L 1 L 2 L L 3 L L 4 L Semantic Representation aka "interlingua"</formula><p>For N = 72, T/G  5112 grammars, Interlingua  144</p><p>Beyond Parsing, Generation and MT</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Anaphora and Ellipsis Resolution</head><p> "Mary got a nice present from Cindy. It was her birthday."</p><p> "John likes oranges and Mary apples."</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dialog Processing</head><p> "Speech Acts" (literal  intended message)  Social Role context s peech act selection  "General" context sometimes needed Example 10-year old: "I want a juicy Hamburger!" Mother: "Not today, perhaps tomorrow…" General: "I want a juicy Hamburger." Aide: "Yes, sir!!" Prisoner 1: "I want a juicy Hamburger." Prisoner 2: "Wouldn't that be nice for once."</p><p>Social Role Determines Interpretation 10-year old: "I want a juicy Hamburger!" Mother: "Not today, perhaps tomorrow…" General: "I want a juicy Hamburger!" Aide:</p><p>"Yes, sir!!" Prisoner 1: "I want a juicy Hamburger!" Prisoner 2: "Wouldn't that be nice for once!"</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INTRODUCTION</head><p>Natural Language Processing (NLP) is the computerized approach to analyzing text that is based on both a set of theories and a set of technologies. And, being a very active area of research and development, there is not a single agreed-upon definition that would satisfy everyone, but there are some aspects, which would be part of any knowledgeable person's definition. The definition I offer is:</p><p>Definition: Natural Language Processing is a theoretically motivated range of computational techniques for analyzing and representing naturally occurring texts at one or more levels of linguistic analysis for the purpose of achieving human-like language processing for a range of tasks or applications.</p><p>Several elements of this definition can be further detailed. Firstly the imprecise notion of 'range of computational techniques' is necessary because there are multiple methods or techniques from which to choose to accomplish a particular type of language analysis.</p><p>'Naturally occurring texts' can be of any language, mode, genre, etc. The texts can be oral or written. The only requirement is that they be in a language used by humans to communicate to one another. Also, the text being analyzed should not be specifically constructed for the purpose of the analysis, but rather that the text be gathered from actual usage.</p><p>The notion of 'levels of linguistic analysis' (to be further explained in Section 2) refers to the fact that there are multiple types of language processing known to be at work when humans produce or comprehend language. It is thought that humans normally utilize all of these levels since each level conveys different types of meaning. But various NLP systems utilize different levels, or combinations of levels of linguistic analysis, and this is seen in the differences amongst various NLP applications. This also leads to much confusion on the part of non-specialists as to what NLP really is, because a system that uses any subset of these levels of analysis can be said to be an NLP-based system. The difference between them, therefore, may actually be whether the system uses 'weak' NLP or 'strong' NLP.</p><p>'Human-like language processing' reveals that NLP is considered a discipline within Artificial Intelligence (AI). And while the full lineage of NLP does depend on a number of other disciplines, since NLP strives for human-like performance, it is appropriate to consider it an AI discipline.</p><p>'For a range of tasks or applications' points out that NLP is not usually considered a goal in and of itself, except perhaps for AI researchers. For others, NLP is the means for 1 Liddy, E. D. In Encyclopedia of Library and Information Science, 2 nd Ed. Marcel Decker, Inc.</p><p>UBLIS 571 Soergel. A supplemental reading for Lecture 6.2b, Applications on p. 13. This is more about how NLP is done, the Feldman Jabberwocky reading more about applications in searching . Elizabeth Liddy accomplishing a particular task. Therefore, you have Information Retrieval (IR) systems that utilize NLP, as well as Machine Translation (MT), Question-Answering, etc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Goal</head><p>The goal of NLP as stated above is "to accomplish human-like language processing".</p><p>The choice of the word 'processing' is very deliberate, and should not be replaced with 'understanding'. For although the field of NLP was originally referred to as Natural Language Understanding (NLU) in the early days of AI, it is well agreed today that while the goal of NLP is true NLU, that goal has not yet been accomplished. A full NLU System would be able to:</p><p>1. Paraphrase an input text 2. Translate the text into another language 3. Answer questions about the contents of the text 4. Draw inferences from the text While NLP has made serious inroads into accomplishing goals 1 to 3, the fact that NLP systems cannot, of themselves, draw inferences from text, NLU still remains the goal of NLP.</p><p>There are more practical goals for NLP, many related to the particular application for which it is being utilized. For example, an NLP-based IR system has the goal of providing more precise, complete information in response to a user's real information need. The goal of the NLP system here is to represent the true meaning and intent of the user's query, which can be expressed as naturally in everyday language as if they were speaking to a reference librarian. Also, the contents of the documents that are being searched will be represented at all their levels of meaning so that a true match between need and response can be found, no matter how either are expressed in their surface form.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Origins</head><p>As most modern disciplines, the lineage of NLP is indeed mixed, and still today has strong emphases by different groups whose backgrounds are more influenced by one or another of the disciplines. Key among the contributors to the discipline and practice of NLP are: Linguistics -focuses on formal, structural models of language and the discovery of language universals -in fact the field of NLP was originally referred to as Computational Linguistics; Computer Science -is concerned with developing internal representations of data and efficient processing of these structures, and; Cognitive Psychology -looks at language usage as a window into human cognitive processes, and has the goal of modeling the use of language in a psychologically plausible way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Divisions</head><p>While the entire field is referred to as Natural Language Processing, there are in fact two distinct focuses -language processing and language generation. The first of these refers to the analysis of language for the purpose of producing a meaningful representation, while the latter refers to the production of language from a representation. The task of Natural Language Processing is equivalent to the role of reader/listener, while the task of Natural Language Generation is that of the writer/speaker. While much of the theory and technology are shared by these two divisions, Natural Language Generation also requires a planning capability. That is, the generation system requires a plan or model of the goal of the interaction in order to decide what the system should generate at each point in an interaction. We will focus on the task of natural language analysis, as this is most relevant to Library and Information Science.</p><p>Another distinction is traditionally made between language understanding and speech understanding. Speech understanding starts with, and speech generation ends with, oral language and therefore rely on the additional fields of acoustics and phonology. Speech understanding focuses on how the 'sounds' of language as picked up by the system in the form of acoustical waves are transcribed into recognizable morphemes and words. Once in this form, the same levels of processing which are utilized on written text are utilized. All of these levels, including the phonology level, will be covered in Section 2; however, the emphasis throughout will be on language in the written form.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>BRIEF HISTORY OF NATURAL LANGUAGE PROCESSING</head><p>Research in natural language processing has been going on for several decades dating back to the late 1940s. Machine translation (MT) was the first computer-based application related to natural language. While Weaver and Booth (1);</p><p>(2) started one of the earliest MT projects in 1946 on computer translation based on expertise in breaking enemy codes during World War II, it was generally agreed that it was Weaver's memorandum of 1949 that brought the idea of MT to general notice and inspired many projects (3). He suggested using ideas from cryptography and information theory for language translation. Research began at various research institutions in the United States within a few years.</p><p>Early work in MT took the simplistic view that the only differences between languages resided in their vocabularies and the permitted word orders. Systems developed from this perspective simply used dictionary-lookup for appropriate words for translation and reordered the words after translation to fit the word-order rules of the target language, without taking into account the lexical ambiguity inherent in natural language. This produced poor results. The apparent failure made researchers realize that the task was a lot harder than anticipated, and they needed a more adequate theory of language. However, it was not until 1957 when Chomsky (4) published Syntactic Structures introducing the idea of generative grammar, did the field gain better insight into whether or how mainstream linguistics could help MT.</p><p>During this period, other NLP application areas began to emerge, such as speech recognition. The language processing community and the speech community then was split into two camps with the language processing community dominated by the theoretical perspective of generative grammar and hostile to statistical methods, and the speech community dominated by statistical information theory (5) and hostile to theoretical linguistics (6).</p><p>Due to the developments of the syntactic theory of language and parsing algorithms, there was over-enthusiasm in the 1950s that people believed that fully automatic high quality translation systems (2) would be able to produce results indistinguishable from those of human translators, and such systems should be in operation within a few years. It was not only unrealistic given the then-available linguistic knowledge and computer systems, but also impossible in principle (3).</p><p>The inadequacies of then-existing systems, and perhaps accompanied by the overenthusiasm, led to the ALPAC (Automatic Language Processing Advisory Committee of the National Academy of Science -National Research Council) report of 1966. ( <ref type="formula">7</ref>) The report concluded that MT was not immediately achievable and recommended it not be funded. This had the effect of halting MT and most work in other applications of NLP at least within the United States.</p><p>Although there was a substantial decrease in NLP work during the years after the ALPAC report, there were some significant developments, both in theoretical issues and in construction of prototype systems. Theoretical work in the late 1960's and early 1970's focused on the issue of how to represent meaning and developing computationally tractable solutions that the then-existing theories of grammar were not able to produce. In 1965, Chomsky (8) introduced the transformational model of linguistic competence. However, the transformational generative grammars were too syntactically oriented to allow for semantic concerns. They also did not lend themselves easily to computational implementation. As a reaction to Chomsky's theories and the work of other transformational generativists, case grammar of Fillmore, (9), semantic networks of Quillian, (10), and conceptual dependency theory of Schank, (11) were developed to explain syntactic anomalies, and provide semantic representations. Augmented transition networks of Woods, (12) extended the power of phrase-structure grammar by incorporating mechanisms from programming languages such as LISP. Other representation formalisms included Wilks' preference semantics (13), and Kay's functional grammar ( <ref type="formula">14</ref>).</p><p>Alongside theoretical development, many prototype systems were developed to demonstrate the effectiveness of particular principles. Weizenbaum's ELIZA (15) was built to replicate the conversation between a psychologist and a patient, simply by permuting or echoing the user input. Winograd's SHRDLU (16) simulated a robot that manipulated blocks on a tabletop. Despite its limitations, it showed that natural language understanding was indeed possible for the computer (17). PARRY (18) attempted to embody a theory of paranoia in a system. Instead of single keywords, it used groups of keywords, and used synonyms if keywords were not found. LUNAR was developed by Woods ( <ref type="formula">19</ref>) as an interface system to a database that consisted of information about lunar rock samples using augmented transition network and procedural semantics (20).</p><p>In the late 1970's, attention shifted to semantic issues, discourse phenomena, and communicative goals and plans (21). Grosz ( <ref type="formula">22</ref>) analyzed task-oriented dialogues and proposed a theory to partition the discourse into units based on her findings about the relation between the structure of a task and the structure of the task-oriented dialogue. Mann and Thompson ( <ref type="formula">23</ref>) developed Rhetorical Structure Theory, attributing hierarchical structure to discourse. Other researchers have also made significant contributions, including Hobbs and Rosenschein (24), Polanyi and Scha (25), and Reichman (26).</p><p>This period also saw considerable work on natural language generation. McKeown's discourse planner TEXT ( <ref type="formula">27</ref>) and McDonald's response generator MUMMBLE (28) used rhetorical predicates to produce declarative descriptions in the form of short texts, usually paragraphs. TEXT's ability to generate coherent responses online was considered a major achievement.</p><p>In the early 1980s, motivated by the availability of critical computational resources, the growing awareness within each community of the limitations of isolated solutions to NLP problems ( <ref type="formula">21</ref>), and a general push toward applications that worked with language in a broad, real-world context (6), researchers started re-examining non-symbolic approaches that had lost popularity in early days. By the end of 1980s, symbolic approaches had been used to address many significant problems in NLP and statistical approaches were shown to be complementary in many respects to symbolic approaches (21).</p><p>In the last ten years of the millennium, the field was growing rapidly. This can be attributed to: a) increased availability of large amounts of electronic text; b) availability of computers with increased speed and memory; and c) the advent of the Internet. Statistical approaches succeeded in dealing with many generic problems in computational linguistics such as part-of-speech identification, word sense disambiguation, etc., and have become standard throughout NLP (29). NLP researchers are now developing next generation NLP systems that deal reasonably well with general text and account for a good portion of the variability and ambiguity of language.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>LEVELS OF NATURAL LANGUAGE PROCESSING</head><p>The most explanatory method for presenting what actually happens within a Natural Language Processing system is by means of the 'levels of language' approach. This is also referred to as the synchronic model of language and is distinguished from the earlier sequential model, which hypothesizes that the levels of human language processing follow one another in a strictly sequential manner. Psycholinguistic research suggests that language processing is much more dynamic, as the levels can interact in a variety of orders. Introspection reveals that we frequently use information we gain from what is typically thought of as a higher level of processing to assist in a lower level of analysis. For example, the pragmatic knowledge that the document you are reading is about biology will be used when a particular word that has several possible senses (or meanings) is encountered, and the word will be interpreted as having the biology sense.</p><p>Of necessity, the following description of levels will be presented sequentially. The key point here is that meaning is conveyed by each and every level of language and that since humans have been shown to use all levels of language to gain understanding, the more capable an NLP system is, the more levels of language it will utilize.</p><p>(Figure <ref type="figure">1</ref>: Synchronized Model of Language Processing)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Phonology</head><p>This level deals with the interpretation of speech sounds within and across words. There are, in fact, three types of rules used in phonological analysis: 1) phonetic rules -for sounds within words; 2) phonemic rules -for variations of pronunciation when words are spoken together, and; 3) prosodic rules -for fluctuation in stress and intonation across a sentence. In an NLP system that accepts spoken input, the sound waves are analyzed and encoded into a digitized signal for interpretation by various rules or by comparison to the particular language model being utilized.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Morphology</head><p>This level deals with the componential nature of words, which are composed of morphemes -the smallest units of meaning. For example, the word preregistration can be morphologically analyzed into three separate morphemes: the prefix pre, the root registra, and the suffix tion. Since the meaning of each morpheme remains the same across words, humans can break down an unknown word into its constituent morphemes in order to understand its meaning. Similarly, an NLP system can recognize the meaning conveyed by each morpheme in order to gain and represent meaning. For example, adding the suffix -ed to a verb, conveys that the action of the verb took place in the past. This is a key piece of meaning, and in fact, is frequently only evidenced in a text by the use of the -ed morpheme.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lexical</head><p>At this level, humans, as well as NLP systems, interpret the meaning of individual words.</p><p>Several types of processing contribute to word-level understanding -the first of these being assignment of a single part-of-speech tag to each word. In this processing, words that can function as more than one part-of-speech are assigned the most probable part-ofspeech tag based on the context in which they occur.</p><p>Additionally at the lexical level, those words that have only one possible sense or meaning can be replaced by a semantic representation of that meaning. The nature of the representation varies according to the semantic theory utilized in the NLP system. The following representation of the meaning of the word launch is in the form of logical predicates. As can be observed, a single lexical unit is decomposed into its more basic properties. Given that there is a set of semantic primitives used across all words, these simplified lexical representations make it possible to unify meaning across words and to produce complex interpretations, much the same as humans do.</p><p>launch (a large boat used for carrying people on rivers, lakes harbors, etc.) ((CLASS BOAT) (PROPERTIES (LARGE) (PURPOSE (PREDICATION (CLASS CARRY) (OBJECT PEOPLE))</p><p>))</p><p>The lexical level may require a lexicon, and the particular approach taken by an NLP system will determine whether a lexicon will be utilized, as well as the nature and extent of information that is encoded in the lexicon. Lexicons may be quite simple, with only the words and their part(s)-of-speech, or may be increasingly complex and contain information on the semantic class of the word, what arguments it takes, and the semantic limitations on these arguments, definitions of the sense(s) in the semantic representation utilized in the particular system, and even the semantic field in which each sense of a polysemous word is used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Syntactic</head><p>This level focuses on analyzing the words in a sentence so as to uncover the grammatical structure of the sentence. This requires both a grammar and a parser. The output of this level of processing is a (possibly delinearized) representation of the sentence that reveals the structural dependency relationships between the words. There are various grammars that can be utilized, and which will, in turn, impact the choice of a parser. Not all NLP applications require a full parse of sentences, therefore the remaining challenges in parsing of prepositional phrase attachment and conjunction scoping no longer stymie those applications for which phrasal and clausal dependencies are sufficient. Syntax conveys meaning in most languages because order and dependency contribute to meaning. For example the two sentences: 'The dog chased the cat.' and 'The cat chased the dog.' differ only in terms of syntax, yet convey quite different meanings.</p><p>Semantic This is the level at which most people think meaning is determined, however, as we can see in the above defining of the levels, it is all the levels that contribute to meaning. Semantic processing determines the possible meanings of a sentence by focusing on the interactions among word-level meanings in the sentence. This level of processing can include the semantic disambiguation of words with multiple senses; in an analogous way to how syntactic disambiguation of words that can function as multiple parts-of-speech is accomplished at the syntactic level. Semantic disambiguation permits one and only one sense of polysemous words to be selected and included in the semantic representation of the sentence. For example, amongst other meanings, 'file' as a noun can mean either a folder for storing papers, or a tool to shape one's fingernails, or a line of individuals in a queue. If information from the rest of the sentence were required for the disambiguation, the semantic, not the lexical level, would do the disambiguation. A wide range of methods can be implemented to accomplish the disambiguation, some which require information as to the frequency with which each sense occurs in a particular corpus of interest, or in general usage, some which require consideration of the local context, and others which utilize pragmatic knowledge of the domain of the document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discourse</head><p>While syntax and semantics work with sentence-length units, the discourse level of NLP works with units of text longer than a sentence. That is, it does not interpret multisentence texts as just concatenated sentences, each of which can be interpreted singly. Rather, discourse focuses on the properties of the text as a whole that convey meaning by making connections between component sentences. Several types of discourse processing can occur at this level, two of the most common being anaphora resolution and discourse/text structure recognition. Anaphora resolution is the replacing of words such as pronouns, which are semantically vacant, with the appropriate entity to which they refer (30). Discourse/text structure recognition determines the functions of sentences in the text, which, in turn, adds to the meaningful representation of the text. For example, newspaper articles can be deconstructed into discourse components such as: Lead, Main Story, Previous Events, Evaluation, Attributed Quotes, and Expectation ( <ref type="formula">31</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pragmatic</head><p>This level is concerned with the purposeful use of language in situations and utilizes context over and above the contents of the text for understanding The goal is to explain how extra meaning is read into texts without actually being encoded in them. This requires much world knowledge, including the understanding of intentions, plans, and goals. Some NLP applications may utilize knowledge bases and inferencing modules. For example, the following two sentences require resolution of the anaphoric term 'they', but this resolution requires pragmatic or world knowledge.</p><p>The city councilors refused the demonstrators a permit because they feared violence.</p><p>The city councilors refused the demonstrators a permit because they advocated revolution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Summary of Levels</head><p>Current NLP systems tend to implement modules to accomplish mainly the lower levels of processing. This is for several reasons. First, the application may not require interpretation at the higher levels. Secondly, the lower levels have been more thoroughly researched and implemented. Thirdly, the lower levels deal with smaller units of analysis, e.g. morphemes, words, and sentences, which are rule-governed, versus the higher levels of language processing which deal with texts and world knowledge, and which are only regularity-governed. As will be seen in the following section on Approaches, the statistical approaches have, to date, been validated on the lower levels of analysis, while the symbolic approaches have dealt with all levels, although there are still few working systems which incorporate the higher levels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPROACHES TO NATURAL LANGUAGE PROCESSING</head><p>Natural language processing approaches fall roughly into four categories: symbolic, statistical, connectionist, and hybrid. Symbolic and statistical approaches have coexisted since the early days of this field. Connectionist NLP work first appeared in the 1960's.</p><p>For a long time, symbolic approaches dominated the field. In the 1980's, statistical approaches regained popularity as a result of the availability of critical computational resources and the need to deal with broad, real-world contexts. Connectionist approaches also recovered from earlier criticism by demonstrating the utility of neural networks in NLP. This section examines each of these approaches in terms of their foundations, typical techniques, differences in processing and system aspects, and their robustness, flexibility, and suitability for various tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Symbolic Approach</head><p>Symbolic approaches perform deep analysis of linguistic phenomena and are based on explicit representation of facts about language through well-understood knowledge representation schemes and associated algorithms (21). In fact, the description of the levels of language analysis in the preceding section is given from a symbolic perspective. The primary source of evidence in symbolic systems comes from human-developed rules and lexicons.</p><p>A good example of symbolic approaches is seen in logic or rule-based systems. In logicbased systems, the symbolic structure is usually in the form of logic propositions. Manipulations of such structures are defined by inference procedures that are generally truth preserving. Rule-based systems usually consist of a set of rules, an inference engine, and a workspace or working memory. Knowledge is represented as facts or rules in the rule-base. The inference engine repeatedly selects a rule whose condition is satisfied and executes the rule.</p><p>Another example of symbolic approaches is semantic networks. First proposed by Quillian (10) to model associative memory in psychology, semantic networks represent knowledge through a set of nodes that represent objects or concepts and the labeled links that represent relations between nodes. The pattern of connectivity reflects semantic organization, that is; highly associated concepts are directly linked whereas moderately or weakly related concepts are linked through intervening concepts. Semantic networks are widely used to represent structured knowledge and have the most connectionist flavor of the symbolic models (32). A frequently used statistical model is the Hidden Markov Model (HMM) inherited from the speech community. HMM is a finite state automaton that has a set of states with probabilities attached to transitions between states (34). Although outputs are visible, states themselves are not directly observable, thus "hidden" from external observations. Each state produces one of the observable outputs with a certain probability.</p><p>Statistical approaches have typically been used in tasks such as speech recognition, lexical acquisition, parsing, part-of-speech tagging, collocations, statistical machine translation, statistical grammar learning, and so on.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Connectionist Approach</head><p>Similar to the statistical approaches, connectionist approaches also develop generalized models from examples of linguistic phenomena. What separates connectionism from other statistical methods is that connectionist models combine statistical learning with various theories of representation -thus the connectionist representations allow transformation, inference, and manipulation of logic formulae (33). In addition, in connectionist systems, linguistic models are harder to observe due to the fact that connectionist architectures are less constrained than statistical ones (35); (21).</p><p>Generally speaking, a connectionist model is a network of interconnected simple processing units with knowledge stored in the weights of the connections between units (32). Local interactions among units can result in dynamic global behavior, which, in turn, leads to computation.</p><p>Some connectionist models are called localist models, assuming that each unit represents a particular concept. For example, one unit might represent the concept "mammal" while another unit might represent the concept "whale". Relations between concepts are encoded by the weights of connections between those concepts. Knowledge in such models is spread across the network, and the connectivity between units reflects their structural relationship. Localist models are quite similar to semantic networks, but the links between units are not usually labeled as they are in semantic nets. They perform well at tasks such as word-sense disambiguation, language generation, and limited inference (36).</p><p>Other connectionist models are called distributed models. Unlike that in localist models, a concept in distributed models is represented as a function of simultaneous activation of multiple units. An individual unit only participates in a concept representation. These models are well suited for natural language processing tasks such as syntactic parsing, limited domain translation tasks, and associative retrieval.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Comparison Among Approaches</head><p>From the above section, we have seen that similarities and differences exist between approaches in terms of their assumptions, philosophical foundations, and source of evidence. In addition to that, the similarities and differences can also be reflected in the processes each approach follows, as well as in system aspects, robustness, flexibility, and suitable tasks.</p><p>Process: Research using these different approaches follows a general set of steps, namely, data collection, data analysis/model building, rule/data construction, and application of rules/data in system. The data collection stage is critical to all three approaches although statistical and connectionist approaches typically require much more data than symbolic approaches. In the data analysis/model building stage, symbolic approaches rely on human analysis of the data in order to form a theory while statistical approaches manually define a statistical model that is an approximate generalization of the collected data. Connectionist approaches build a connectionist model from the data.</p><p>In the rule / data construction stage, manual efforts are typical for symbolic approaches and the theory formed in the previous step may evolve when new cases are encountered.</p><p>In contrast, statistical and connectionist approaches use the statistical or connectionist model as guidance and build rules or data items automatically, usually in relatively large quantity. After building rules or data items, all approaches then automatically apply them to specific tasks in the system. For instance, connectionist approaches may apply the rules to train the weights of links between units.</p><p>System aspects: By system aspects, we mean source of data, theory or model formed from data analysis, rules, and basis for evaluation.</p><p>-Data: As mentioned earlier, symbolic approaches use human introspective data, which are usually not directly observable. Statistical and connectionist approaches are built on the basis of machine observable facets of data, usually from text corpora.</p><p>-Theory or model based on data analysis: As the outcome of data analysis, a theory is formed for symbolic approaches whereas a parametric model is formed for statistical approaches and a connectionist model is formed for connectionist approaches.</p><p>-Rules: For symbolic approaches, the rule construction stage usually results in rules with detailed criteria of rule application. For statistical approaches, the criteria of rule application are usually at the surface level or under-specified. For connectionist approaches, individual rules typically cannot be recognized.</p><p>-Basis for Evaluation: Evaluation of symbolic systems is typically based on intuitive judgments of unaffiliated subjects and may use system-internal measures of growth such as the number of new rules. In contrast, the basis for evaluation of statistical and connectionist systems are usually in the form of scores computed from some evaluation function. However, if all approaches are utilized for the same task, then the results of the task can be evaluated both quantitatively and qualitatively and compared.</p><p>Robustness: Symbolic systems may be fragile when presented with unusual, or noisy input. To deal with anomalies, they can anticipate them by making the grammar more general to accommodate them. Compared to symbolic systems, statistical systems may be more robust in the face of unexpected input provided that training data is sufficient, which may be difficult to be assured of. Connectionist systems may also be robust and fault tolerant because knowledge in such systems is stored across the network. When presented with noisy input, they degrade gradually.</p><p>Flexibility: Since symbolic models are built by human analysis of well-formulated examples, symbolic systems may lack the flexibility to adapt dynamically to experience. In contrast, statistical systems allow broad coverage, and may be better able to deal with unrestricted text (21) for more effective handling of the task at hand. Connectionist systems exhibit flexibility by dynamically acquiring appropriate behavior based on the given input. For example, the weights of a connectionist network can be adapted in realtime to improve performance. However, such systems may have difficulty with the representation of structures needed to handle complex conceptual relationships, thus limiting their abilities to handle high-level NLP (36).</p><p>Suitable tasks: Symbolic approaches seem to be suited for phenomena that exhibit identifiable linguistic behavior. They can be used to model phenomena at all the various linguistic levels described in earlier sections. Statistical approaches have proven to be effective in modeling language phenomena based on frequent use of language as reflected in text corpora. Linguistic phenomena that are not well understood or do not exhibit clear regularity are candidates for statistical approaches. Similar to statistical approaches, connectionist approaches can also deal with linguistic phenomena that are not well understood. They are useful for low-level NLP tasks that are usually subtasks in a larger problem.</p><p>To summarize, symbolic, statistical, and connectionist approaches have exhibited different characteristics, thus some problems may be better tackled with one approach while other problems by another. In some cases, for some specific tasks, one approach may prove adequate, while in other cases, the tasks can get so complex that it might not be possible to choose a single best approach. In addition, as Klavans and Resnik (6) pointed out, there is no such thing as a "purely statistical" method. Every use of statistics is based upon a symbolic model and statistics alone is not adequate for NLP. Toward this end, statistical approaches are not at odds with symbolic approaches. In fact, they are rather complementary. As a result, researchers have begun developing hybrid techniques that utilize the strengths of each approach in an attempt to address NLP problems more effectively and in a more flexible manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>NATURAL LANGUAGE PROCESSING APPLICATIONS</head><p>Natural language processing provides both theory and implementations for a range of applications. In fact, any application that utilizes text is a candidate for NLP. The most frequent applications utilizing NLP include the following:</p><p>• Information Retrieval -given the significant presence of text in this application, it is surprising that so few implementations utilize NLP. Recently, statistical approaches for accomplishing NLP have seen more utilization, but few systems other than those by Liddy (37) and Strzalkowski (38) have developed significant systems based on NLP .</p><p>• Information Extraction (IE) -a more recent application area, IE focuses on the recognition, tagging, and extraction into a structured representation, certain key elements of information, e.g. persons, companies, locations, organizations, from large collections of text. These extractions can then be utilized for a range of applications including question-answering, visualization, and data mining.</p><p>• Question-Answering -in contrast to Information Retrieval, which provides a list of potentially relevant documents in response to a user's query, question-answering provides the user with either just the text of the answer itself or answer-providing passages.</p><p>• Summarization -the higher levels of NLP, particularly the discourse level, can empower an implementation that reduces a larger text into a shorter, yet richlyconstituted abbreviated narrative representation of the original document.</p><p>• Machine Translation -perhaps the oldest of all NLP applications, various levels of NLP have been utilized in MT systems, ranging from the 'word-based' approach to applications that include higher levels of analysis.</p><p>• Dialogue Systems -perhaps the omnipresent application of the future, in the systems envisioned by large providers of end-user applications. Dialogue systems, which usually focus on a narrowly defined application (e.g. your refrigerator or home sound system), currently utilize the phonetic and lexical levels of language. It is believed that utilization of all the levels of language processing explained above offer the potential for truly habitable dialogue systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CONCLUSIONS</head><p>While NLP is a relatively recent area of research and application, as compared to other information technology approaches, there have been sufficient successes to date that suggest that NLP-based information access technologies will continue to be a major area of research and development in information systems now and far into the future. In short, SmartDiscovery Awareness Server automates the process of information discovery. This means that instead of spending two to four hours a day looking for information, you can spend those hours using the information you find.</p><p>Using Awareness Server, you can:</p><p>• Automatically pull together analyst reports, news articles and SEC filings for complete competitive analysis.</p><p>• Monitor your brand globally.</p><p>• Access information on a given topic, regardless of source, for compliance.</p><p>• Monitor chatter from a variety of classified sources, blogs and other open sources.</p><p>• Be alerted when competitors' Websites change.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Filtering and Preview Options</head><p>Numerous filtering and preview options allow users to quickly understand and locate relevant information from billions of potential hits spread around the world in hundreds of internal and external systems.</p><p>For example, relevance ranking across documents from multiple content sources enables users to see the most relevant documents first, regardless of source.</p><p>SmartDiscovery Awareness Server quickly categorizes each matching result record and provides a View by Concept display that organizes search results into a visual tree structure of matching categories, enabling rapid navigation by subject.</p><p>Dynamic summarization enables users to browse quickly though volumes of information and quickly find the most relevant documents, reducing unnecessary click-throughs and saving precious time and effort.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Inxight SmartDiscovery Awareness Server</head><p>Search the public Web, Deep Web, news, subscription content and internal information -all from one screen.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Search alerts keep you on top of the latest developments related to your search queries.</head><p>Lotus Domino, Google Search Appliance indexes, intranets and Documentum, and classified sources. Results are displayed as a relevance-ranked list, or search queries can be saved as alerts, and results can be emailed to you.</p><p>In seconds, you can cluster and filter your federated search results by the most relevant people, companies, places, concepts, weapons, vehicles and other entities mentioned in them. More than 35 entities are available out-of-the-box, and you can customize the system to track new list-based or pattern-based topics such as products, competitors, terrorist names, part numbers, gene sequences, etc. You can also cluster and filter results by pre-defined taxonomies or by source.</p><p>These capabilities are powered by Inxight's deep understanding of language.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Language Understanding</head><p>Inxight's language understanding offers intelligent analysis of more than 30 languages. This analysis includes:</p><p>• Identification of paragraphs, sentences, clauses, and phrases within text.</p><p>• Accurate identification and management of capitalization and case normalization.</p><p>• Word Segmentation (Tokenization) -Identifies meaningful units of text at a granular level, including: o Individual words and word particles o Abbreviations and contractions (i.e. "don't") o Punctuation (periods, commas, exclamation marks, etc.)</p><p>• Stemming -Identifies true stems (base forms) for each surface form token; normalizes words to the most basic form for more efficient indexing and better recall in search.</p><p>• De-Compounding -Splits compound words into distinct elements --particularly important in languages such as German and Dutch where words are freely joined together.</p><p>• Part-of-Speech Tagging -Identifies and labels the part-of-speech of each word in context, including grammatical category (noun, verb, etc.) and sub-class attributes (singular vs. plural nouns, present vs. past tense verbs, etc.). •</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Entity and Concept Extraction</head><p>Inxight then builds on these underlying language components to out-of-the-box extract 35 different key entities (people, places, organizations, weapons, vehicles, dates, etc.) and concepts from electronic text. The Inxight system can also be easily extended to identify and extract custom entities, such as project names, lists of "persons of interest," date/timestamps, chemical compound names or formulae, serial or part numbers, and patent numbers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Relation and Event Extraction</head><p>Again, Inxight builds on the underlying language components to allow the system to detect relations and events, such as personal associations, merger and acquisition activities, or travel events. It can be extended to find custom relations and events such as company contact information, brand co-occurrence or medication adverse effects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Variant Identification and Normalization</head><p>Variant identification and grouping allow Inxight to accurately classify all relevant entities in a document, even one-word entities, and to provide true counts reflecting the number and location of ALL appearances of a given entity. For example, Inxight recognizes that the appearance of the word "Smith" in the example refers to the earlier identified person "Joe Smith." Normalization takes much of the guesswork out of metadata creation, search, data mining and link analysis processes by creating standard formats (e.g., ISO) for certain entity categories such as dates or measurements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Enriched Applications</head><p>In addition to powering more effective information retrieval through Inxight SmartDiscovery Awareness Server, this deep understanding of language also allows documents indexed by Google to be enriched with information, powering applications in routing, data mining, and relationship and trend visualization.</p><p>For example, in the custom application below, the user first queries their Google Search Appliance for information on "Tony Blair." Relevant entities are extracted from the result set and this information is saved to a MySQL metadata repository.</p><p>The user can then see which entities co-occurred within a sentence in the document result set. They can also explore different events, such as seeing what people sent emails to each other, or what people had meetings with each other. This capability is powered by an Inxight StarTree® visualization:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Capitalize on Your Google Investment with Inxight SmartDiscovery</head><p>Google is one of the world's best search indexers. It puts the Web's information at your fingertips, while the Google Search Appliance does the same thing for your website or corporate intranet.</p><p>Inxight, a Google Enterprise Partner, takes this information and helps you harness it in more meaningful ways. Inxight SmartDiscovery Awareness Server augments it with sources that cannot (because of accessibility or copyright regulations) be indexed by the public Web or by internal systems.</p><p>Inxight SmartDiscovery Analysis Server electronically "reads" that information and structures itpulling out key entities (people, places, companies…), concepts, relations, and events trapped in unstructured text. Inxight visualizations such as Inxight StarTree then provide the ability to visualize that information in meaningful ways.</p><p>For more information or a demonstration, contact Inxight Software at www.inxight.com or email sales@inxight.com.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>About Inxight</head><p>Inxight Software, Inc. is the leading provider of enterprise software solutions for information discovery. Using Inxight solutions, organizations can access and analyze unstructured, semistructured and structured text to extract key information to enable business intelligence. Inxight is the only company that provides a complete, scalable solution enabling information discovery in more than 30 languages. ! "  </p><formula xml:id="formula_9"># $ % &amp; " ' " ! ( ' ! ! % &amp; % &amp; ) ) * + &amp; , ! " # $ % &amp; " ' " ! ( ' ! ! % &amp; % &amp; ) ) * + &amp; - ( . / 0 ! % 0 1 ! " # ! " # $ ! # % % &amp; $! '( % ( % ) ! % # * + *) (% (<label>(</label></formula><formula xml:id="formula_10">! : @ ! ! ! ! ! ! ' ! ! 4 " $ ) + -3 / + -% ! # . + - ! " # $ % &amp; " ' " ! ( ' ! ! % &amp; % &amp; ) ) * + &amp; + % ! + &lt; ! " # $%&amp; ' # ( ) A B ( . / ! B ' ' : : $ ' ! + ! ' : ! ) ' B ! : ' ! ! C ! ) ' B ! ! ! ! ! ! C ' ! ! C D ; ; E + ! " # $ % &amp; " ' " ! ( ' ! ! % &amp; % &amp; ) ) * + &amp; &lt; $ F &gt; F &lt; G ;;;4 4 ! !" # $ % &amp; ' ( ) &amp; % ( * + , - + .&amp;( ! " # + , - + / % , ) &amp; % ( * + , - + .&amp;( ! " # + , - + / % + -* . / $ * &amp; $ % &amp; &amp; 0 &amp; ,$ 1 &amp; +$ Luxid® Repository " -* . Luxid® Repository 2 -* . Luxid® Repository -* . Luxid® Repository ! ! ! " # ) &amp; % ( * + , - + .&amp;( ! " # + , - + / % % 1 &amp; # 2 ' ! ! ( " ! ! ! ( # ' &amp; B ! ! . ( * 5 5 6 2 7 . # / C &lt; &amp; ! , 3 8 ! ! ! ! # " ! ( ! ! ! ( # C &lt; ! ! . -! ( ! # D : ! ; " ! ( &lt; : ' ! ! " # $ ! ! , ! . # 2 &lt; &amp; ! ! ! " ! ( ; ! ! &lt; " . , , # % &amp; &amp; : ! ! 4 ! , ! ! 2 E = ! ( ! / ! # ' D ! 9 " , ! . ! # 1 ! ! ! , " ! # ,/ &amp; A , 0 0 1 , &amp; F &amp; G ! " . = + ! ' ! ! ! ;$ . &lt; &amp; % ! ! ( ! ! " ( ! ! # $ * 3 '? ! . # ," -H * &lt; 17 % 9&gt; ! ! ! ;3 ! + . &lt; ! ! " 0 ;$ * 3 '?&lt; ,2 % * &amp; ! + . ! ( ! . + # J 6 B K ; K<label>6</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Insight Discoverer™ Extractor, the information extraction solution</head><p>Insight Discoverer™ Extractor is an information extraction server dedicated to analysis of text documents. It detects pieces of information that are the most relevant to users: a merger announcement in an article for an analyst, a sales opportunity in an e-mail for a customer relationship manager, a specific skill in a resumé for a recruiter, for example.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Key applications of extraction</head><p>Used with specialized Skill Cartridges™, Insight Discoverer™ Extractor answers the needs for documentary analysis for departments as different as customer services, market watch units or human resources. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Specifications</head><p>&lt;&lt; Operating systems:</p><p>-Windows NT, 2000, XP workstation or server versions -Linux</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt;&lt; API:</head><p>-Java (RMI -Remote Method Invocation)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt;&lt; Source languages:</head><p>English, French, German, Italian, Dutch, Spanish, Portuguese, Czech, Greek, Hungarian, Polish, Russian.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt;&lt; Formats :</head><p>over 50 input formats (including MS Word, PDF and HTML).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Text Intelligence™</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>How Insight Discoverer™ Extractor works</head><p>Insight Discoverer™ Extractor performs a sequence of three linguistic analysis steps:</p><p>&lt;&lt; Corpus recognition: automatic language identification &lt;&lt; Morpho-syntactic analysis:</p><p>• Assigns a grammatical category to each word in a document (noun, adjective, verb, etc.) as well as its morpho-syntactic characteristics (gender, number) </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt;&lt; Grenoble</head><p>Tel. : +33 (0)4 56 38 24 00 info@temis-group.com</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TEMIS Germany</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt;&lt; Heidelberg</head><p>Tel. : +49 -6221 13753-12 info.de@temis-group.com</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TEMIS USA</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt;&lt; Philadelphia</head><p>Tel. : +1 571 235 83 95 info.us@temis-group.com</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TEMIS Italy</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt;&lt; Modena</head><p>Tel. : +39 -059 237 634 info.it@temis-group.com </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Overview</head><p>With the steady growth of business and scientific activities and the recent advances in Information Technology, huge amounts of electronically available but unstructured data have to be dealt with. New tools able to analyse and structure textual data need to be developed so that non-expert users can understand and evaluate the contents of their documents. In this context, a successful information extraction technology has a central role to play. Information Extraction is the process of identifying relevant information where the criteria for relevance are predefined in the form of a template that is to be filled. The template pertains to actions between different actors related to events or situations and contains slots that denote who did what to whom, when and where, and possibly why. The template builder has to predict what information will be of interest to the customer according to his field of activity.</p><p>In an industrial context, the aim of Information Extraction is to build an extraction model adapted to the customer's application (its information assets: databases, documents and all the data issued by or received in a company). It requires the creation and validation of terminology resources specific to the described field as well as the definition of selection criteria using extraction rules.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Methodology</head><p>Our approach is based on discovering knowledge from a corpus in an iterative way. We use various text analysis processing: morpho-syntactic analysis, named entities recognition, pattern recognition using linguistics and/or semantic labels. The main idea is to build patterns 1 . If, for instance, the aim of the application is to detect company mergers or acquisitions in press releases, it will seek expressions like 'company A acquired company B' or 'company A merged with company C'. As company may be a company name and all the common words which refer to a company (firm, manufacturer, corporation, …). They are gathered under the semantic descriptor 'company.' In the case of an application dedicated to the field of Competitive Intelligence, verbs like buy, sell, and acquire, which refer to a transfer of possessions, are coded together under the same descriptor.</p><p>In press releases, the economic actors are mentioned within their context. It is therefore necessary to associate specific terms under a common descriptor. This task is achieved through the use of extraction rules. An extraction rule is expressed by a regular expression which may refer to a lemma (canonical form), syntactic, or semantic label.</p><p>Example: "the first private label pasta maker" will be caught by the rule:</p><p>(company_Adj|Loc_Adj|#ORD)*/ (brand_product) / (Company) Company_Adj refers to adjectives such as "leading", "industrial" or "public" LocAdj refers to adjectives describing places such as "European" or "Italian" #ORD refers to ordinals (first, second, …) brand_product private label, branded + #NOUN / symbol separates two words # symbol denotes a syntactic tag (differentiates the syntactic labels from the semantic ones).</p><p>An expression like 'company A acquired company B' will be extracted by the following rule:</p><p>1 A pattern is a regular expression whose purpose is to identify relevant phrases within a context. Combining an action to a pattern, a rule will add information to a word sequence, assigning a name concept which can be used by other rules.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INSIGHT DISCOVERER™ EXTRACTOR</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>white paper</head><p>Text Intelligence™ company / possession_transfer / company At this stage, it is possible to identify actors such as "who and which_company," which refer to the subject actor and the object actor respectively, taking the syntactic information into account (active vs. passive voice, modals, auxiliaries, and negation). The following rule helps extract the roles filled by "who and which_company" (who buys whom). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Processing</head><p>The extraction server proceeds in two stages: 1. the morpho-syntactic analysis -each entry is assigned a part of speech and a morphologic feature 2. the application of extraction rules.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Morpho-syntactic analysis</head><p>It gives the lemma and the morpho-syntactic label for each entry. It is coupled with a statistic model (Hidden Markov Model) , which helps in dealing with ambiguities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Semantic analysis</head><p>Semantic tagging is performed with the following resources: a) dictionaries, using existing resources (such as WordNet <ref type="bibr">[FELDBAUM 1997</ref><ref type="bibr">[FELDBAUM , 1999] ]</ref> for English) and tailor-made dictionaries created by TEMIS' team of linguists </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Text Intelligence™</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Transducers Technology</head><p>The extraction component, which performs semantic labeling from morpho-syntactically tagged texts, has been implemented using a dynamic composition of transducers. According to the specific processing, three levels of transducer components have been distinguished.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">World level</head><p>At this stage, the transducer reads a word in the sentence and suggests an alternative for each character in the word. The word level processing is used to deal with accentuation, uppercase vs. lowercase, and hyphen phenomena. It acts as a pre-processor of information extraction and can recognize a word and assign it a semantic label, independent of how it is written in the source text.</p><p>Firstname Valerie refers to Valerie, Valérie, VALERIE, and VALÉRIE Adjective anglo-swiss recognizes anglo-swiss and anglo -swiss</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Lexical level</head><p>At the lexical level, the transducer deals with the semantic dictionaries. In input, the tagged sentence with suggestions. In output, it gives the semantic label associated to each lexical entry, independent of how it is expressed in the term databases (word vs. multiword): Badoit Blue / Quellen (Source)? / Perrier ...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Rules level</head><p>At the rules level, the transducers takes the semantically labeled sentence and applies the rule dictionaries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Contact us</head><p>-By e-mail: info@temis-group.com -Or visit our Web site : www.temis-group.com TEMIS France    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Drive your document flows with Insight Discoverer™ Categorizer</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Insight Discoverer™ Categorizer, the information classification solution</head><p>Insight Discoverer™ Categorizer is a document categorization server. It automatically classifies unstructured documents into pre-defined categories, combining statistical and linguistic analysis rules.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Key applications of categorization</head><p>Insight Discoverer™ Categorizer is used in three types of applications: &lt; Categorization: assignment of a document to one or more categories within a taxonomy &lt; Indexing: identification of topics in a document according to similarity with documents already indexed &lt; Routing: distribution of documents to certain people or departments according to their criteria of interest TEMIS' document categorization server is a tool particularly suited to the needs of your Quality, R&amp;D, Marketing, Methods and Documentation departments. It is used in three main fields in particular: ➜ Quality gains: manual classification generates significant fluctuations in the quality of document assignment. Automatic classification, on the contrary, produces consistently high quality, whatever the form and syntax of the documents.</p><p>➜ Increased motivation: automation of categorization frees your teams from the tedious tasks of manual classification and enables them to dedicate their time to analysis tasks. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Text Mining Solutions</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Text Intelligence™</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Information Extraction tasks</head><p>Naturally, identifying names in free text is not a classification task. On the contrary, it requires a specific kind of parsing. People's names (and to a lesser extent, names of organizations) bear a specific structure that can be recognized by pattern matching with sufficient accuracy.</p><p>Insight Discoverer™ Extractor uses a restricted form of a regular grammar to perform this recognition process. Some 15 rules specify the way in which titles, first names, family names and job titles are typically combined to form people's names in texts. Large collections of first names, job titles etc. are used as knowledge sources for the recognition component.</p><p>After having recognized proper names in a document, Insight Discoverer™ Extractor also tries to find canonical forms for the identified names (i.e. if someone is mentioned with a title once, with the first name a second time and with neither in a third position, Insight Discoverer™ Extractor recognizes that the person which the three forms refer to, has been mentioned three times in this document). Insight Discoverer™ Extractor even performs a rudimentary kind of anaphora resolution in order to count the number of occurrences of a name. That means that in (the corresponding German translation of) a sentence like (1)</p><p>(1)</p><p>Madonna was not only one of the most controversial artists of the nineties, she was also one of the most successful.</p><p>Madonna will be treated as if she had been mentioned twice. Counting the number of occurrences in the document is used as the prime criterion to assign a relevance measure to a name.</p><p>Apart from their importance as index terms for a document, people's names also have a considerable effect on the classification process. Failing to recognize them and treat them as one token in the text (rather than treating first and family names as separate tokens) would mean that important information is ignored and would therefore lead to poorer classification results. The following hypothetical example might illustrate this point.</p><p>(2) Helmut Schmidt (former German chancelor): politics Martin Scorsese (US film director): film Martin Schmidt (German ski athlete): sports</p><p>Assuming that we had no name recognition component and assuming that the classifier has learnt that the tokens Helmut and Schmidt have some significance for the topic politics and Martin and Scorsese have some relevance for film, then the tokens Martin and Schmidt will falsely signal some influence towards politics and film even if they occur as parts of another name, here that of an athlete. The name recognition component on the other hand will treat these names as tokens, exploiting the fact that in most domains, most names tend to be mentioned with a limited set of topics and thus often serve as good features for a classification component.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Results</head><p>DocCat currently runs in a specific setting where documents that are assigned to one or several broad topics (TOP = {sports, theatre, economics, ...}) have to be annotated with finer labels from a fixed vocabulary of thesaurus terms <ref type="bibr">(SUBTOP = {..., aids, demonstration, university, theft, cancer, ... })</ref>. Of these, DocCat has learnt to assign some 600 terms<ref type="foot" target="#foot_11">1</ref> . The results on the different broad topics reflect the internal homogeneity of the respective sub corpora: On a well-defined topic such as sports (recall 60%, precision 70%), DocCat performed much better than in other areas like society/celebrities (recall 51%, precision 40%) in assigning the correct specific topic terms. The first line for instance in table 2, reflects the fact that on the sub-corpus annotated with sports DocCat performed the task of selecting the correct assignments with 60% recall and 70% precision from a set of some 600 SUBTOP labels. It has to be noted that these results reflect the number of cases where the DocCat result differs from the initial manual annotation found in the test set, no matter how this difference should be judged. Besides the cases, however, where we have to admit a clear DocCat error, there are also many cases where one has to conclude that both results (the manual and the automatic) are equally valid and even a considerable fraction, where the results of DocCat can or have to be considered superior. While we have yet to evaluate this question quantitatively, we are confident that such a study will prove that the quality of DocCat is even better than that reflected in the tables above.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">System specifications</head><p>The DocCat system is implemented using C++ for the number crunching part of the calculations and Perl for the text processing parts and as a glue language. It currently runs on AIX and Windows (95 and NT). A minimum of 128MB of RAM is necessary for the training of moderately large corpora (&gt; 50,000 documents). The resulting classifier then is able to process a document in less than a second and annotate it in the way described above.</p><p>DocCat runs as a separate process that is called over a simple interface (file or TCP/IP) from the respective text documentation environment and delivers its results back over the same interface. Thus DocCat has minimal requirements concerning the target environment and can be employed in any documentation system where external functionalities can be integrated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion and Outlook</head><p>The DocCat automatic indexing system can be applied in a real world setting, yielding results that enhance the efficiency of manual indexing. For the setting up of a classifier for a new domain or a new classification system, nothing but the annotated training corpus is neededno hand coding of grammar or correlation rules is required. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Text Intelligence™</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Insight Discoverer™ Clusterer</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Insight Discoverer™ Clusterer, the information organization solution</head><p>Insight Discoverer™ Clusterer is an automated classification server that dynamically groups documents according to their semantic similarity. It proposes the most relevant classification for a given document collection. Users can then browse through their documents organized according to theme and sub-theme. They have both an overview of the information and different avenues to explore. It is therefore easier to find and appropriate relevant information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Key applications of clustering</head><p>Insight Discoverer™ Clusterer provides companies with advanced solutions for Competitive Intelligence and optimization of Customer Relationship Management. In the field of Competitive Intelligence, Insight Discoverer™ Clusterer offers a high-performance solution for organizing information related to competitors and the market. It dynamically organizes collections of documents captured by a search engine according to topics. Users can then browse through their document collections and find the The quest for information... Structure your information with Insight Discoverer™ Clusterer most interesting competitive behaviors. In the field of Customer Relationship Management, Insight Discoverer™ Clusterer enables marketing departments to get to know the behavior of their consumers and to orient their strategies accordingly. The software segments your customer database according to e-mail messages, customer correspondence or opinion surveys, for example. This segmentation is innovative because it is based on customers' writing and what they express, rather than models based on descriptive statistics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>➜ Researchers:</head><p>You obtain state-of-the art research information by organizing scientific publications and patents in a given field.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>➜ Product managers:</head><p>You identify customer segments and isolate characteristic behavior or representative comments for a given range or product, by analyzing e-mail messages or customer satisfaction surveys, for example.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>➜ Financial analysts:</head><p>You isolate the major themes and trends in your sector and detect high value added information by analyzing your flows from the economic, financial and trade press. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>http://www.washingtonpost.com/wp-dyn/content/article/2011/02/21/AR2011022102191_pf.html Advertisement Print Powered By Google, Yahoo! BabelFish use math principles to translate documents online Page 3 of 4 Google, Yahoo! BabelFish use math principles to translate documents online 2/27/2011 http://www.washingtonpost.com/wp-dyn/content/article/2011/02/21/AR2011022102191_p...</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2</head><label>2</label><figDesc>Figure 2-1 :Name variation: more than one way to refer to the same entity</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2</head><label>2</label><figDesc>Figure 2-2 :Ambiguity: one name can refer to more than one entity</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2</head><label>2</label><figDesc>Figure 2-3 :Name Catalog hierarchy</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 2</head><label>2</label><figDesc>Figure 2-4 :ThingFinder architecture</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure</head><label></label><figDesc>Figure 3-5 :ThingFinder workflow</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>, or another name for the same entity. alias group</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>As a window into cognition (Psychology)  As a human-interface technology (HCI)  As a technology for text translation (MT)  As a technology for information management (IR) Parsing: text  internal representation such as parse trees, frames, FOL,…  Generation: representation  text  Inference: representation  fuller representation  Filter: huge volumes text  relevant-only text  Summarize: clustering, extraction, presentation Speech NLP  Speech recognition: acoustics  text  Speech synthesis: text  acoustics  Language modeling: text  p(text | context)  …and all the text-NLP componentsOutline of an NLP SystemNatural language processing involves translation of input into an unambiguous internal representation before any further inferences can be made or any response given. In applied natural language processing:  Little additional inference is necessary after initial translation  Canned text templates can often provide adequate natural language output  So translation into internal representation is central problem DB query language (for DB access)  Parse trees with word sense terminal nodes (for machine translation)  Case frame instantiations (for a variety of applications)  Conceptual dependency (for story understanding) Grand Canyon flying to New York.Time flies like an arrow.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>access to DB of US Navy ships S  &lt;present&gt; the &lt;attribute&gt; of &lt;ship&gt; &lt;present&gt;  what is | [can you] tell me &lt;attribute&gt;  length | beam | class &lt;ship&gt;  the &lt;shipname&gt; &lt;shipname&gt;  kennedy | enterprise &lt;ship&gt;  &lt;classname&gt; class ship &lt;classname&gt; kitty hawk | lafayette Example inputs recognized by above grammar: what is the length of the Kennedy can you tell me the class of the Enterprise what is the length of Kitty Hawk class ships  Not all categories are "true" syntactic categories  Words are recognized by their context rather than category (e.g. class)  Recognition is strongly directed  Strong direction useful for spelling correction Semantic Grammars Summary Advantages: Efficient recognition of limited domain input  Absence of overall grammar allows pattern-matching possibilities for idioms, etc.  No separate interpretation phase  Strength of top-down constraints allow powerful ellipsis mechanisms What is the length of the Kennedy? The Kittyhawk?</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>Specificity "Reach" (up)  "atteindre" [French] "Reach" (down)  "baisser" [French] 14 words for "snow" in Inupiac Lexical holes "Shadenfreuder" [German]  happiness in the misery of others, no such English word Syntactic Ambiguity (as discussed earlier)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>Customers include enterprise companies such as Air Products, Novartis, Procter &amp; Gamble and Thomson, multiple U.S. and foreign government agencies, including the Department of Defense, Defense Intelligence Agency, Department of Homeland Security and Commonwealth Secretariat, and software OEMs such as SAP, SAS, Oracle and IBM. The company has offices throughout the United States and Europe. For more information, visit www.inxight.com or call 1-408-738-6200 or +44 (0) 1252 761314. Copyright ©2006 Inxight Software, Inc. All rights reserved. Inxight and SmartDiscovery are trademarks or registered trademarks of Inxight Software, Inc. All other corporate names or trademarks stated herein are the property of their respective companies.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>J</head><label></label><figDesc>Hunting for relevant information... Companies today have to handle a growing volume of documents resulting from the increase in electronic communication. Because only those companies who know how to use this information will remain the leaders of tomorrow, TEMIS offers a new generation of text information processing tools.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>&lt;</head><label></label><figDesc>Linux version available &lt; Extraction processing time cut by up to 50% &lt; New Skill Cartridge™ Compiler: 6 times faster than previous version and lightweight Skill Cartridges™ (size reduced by more than 90%) &lt; Easy conversion of existing Skill Cartridges™ to Insight Discoverer™ Extractor V2 compatible Skill Cartridges™ with SCtranslate &lt; More flexibility thanks to improved Skill Cartridge™ syntax &lt; Built-in linguistic engine XeLDA® upgraded to V2.5 (enhanced English and German processing) &lt; P3 architecture enables the integration of Pre and Post Processing in Skill Cartridges™. Pre Processing can be used to normalize input documents and Post Processing can be used to filter and rename concepts after an extraction process, for example.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head></head><label></label><figDesc>catch Company A would acquire Company B, Company A acquired Company B, Company A has bought Company B but Company B has not been acquired by Company A.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>For</head><label></label><figDesc>to process an increasing volume of documents every day. And only information found in documents that have been classified can be exploited. Your company needs to organize its information system according to your organization and processes (sector-based, functional, theme-based).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>➜</head><label></label><figDesc>Competitive Intelligence, to categorize financial, scientific or technical documents, press articles, patents or scientific publications ➜ Knowledge Management, to automatically load classification trees and knowledge databases or for routing the documents that are relevant to your teams ➜ Customer Relationship Management, for classification or routing of e-mail from customers and automating repliesWhy choose Insight Discoverer™ Categorizer?Insight Discoverer™ Categorizer has a number of advantages:➜ Productivity gains: once their classification model has been validated, your users or departments have easier access to organized information, and can quickly access missioncritical information requiring immediate action.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head></head><label></label><figDesc>Your employees may spend up to 80% of their time looking for the information they need to do their jobs. Information science provides reliable content storage solutions (databases, document management) and retrieval solutions (search engines), but appropriating information is a different challenge.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="3,27.34,41.92,243.14,352.55" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TEMIS products (from the Luxid or the earlier Insight suites) for illustration of applications</head><label></label><figDesc></figDesc><table><row><cell>• Open source NLP software can help.</cell><cell>45 -</cell></row><row><cell>A representative sampling of open source software in a nice NLP</cell><cell></cell></row><row><cell>flowchart</cell><cell></cell></row><row><cell>• Transforming Unstructured Text into Actionable Data -slides, esp. p.</cell><cell>51 -</cell></row><row><cell>56 -59</cell><cell></cell></row><row><cell>• ThingFinder Concepts Guide.</cell><cell>69 -</cell></row><row><cell>A detailed description how ThingFinder works and a good introduction</cell><cell></cell></row><row><cell>to natural language processing (NLP) in general. Start at p. 47</cell><cell></cell></row><row><cell>The XeLDA paper (next)may be even better.</cell><cell></cell></row><row><cell>• XeLDA: integrate a linguistic engine in your applications</cell><cell>107 -</cell></row><row><cell>Another good introduction to natural language processing (NLP) with</cell><cell></cell></row><row><cell>many illustrations. Perhaps even better than the ThingFinde paper</cell><cell></cell></row><row><cell>• Jaime Carbonell. Natural Language Processing</cell><cell>143 -</cell></row><row><cell>33 slides with very nice examples. Good overview</cell><cell></cell></row><row><cell>• Libby, Elizabeth. Natural Language Processing.</cell><cell>177 -</cell></row><row><cell>Article in the Encyclopedia of Library and Information Science</cell><cell></cell></row><row><cell>• Inxight SmartDiscovery Awareness Server</cell><cell>191 -</cell></row><row><cell>Interesting product that uses linguistic technology to post-process</cell><cell></cell></row><row><cell>Google search results; for examples, extracts information from text into</cell><cell></cell></row><row><cell>a relational database. Not sure this product still exists</cell><cell></cell></row><row><cell>• Going beyond Google. Another document on the same system</cell><cell>195 -</cell></row><row><cell>• Several • Luxid in the medical domain. 18 slides</cell><cell>201 -</cell></row><row><cell>• Analyzing patent literature to gain competitive insight with Luxid</cell><cell>219 -</cell></row><row><cell>(medical domain) 42 slides</cell><cell></cell></row><row><cell>• Insight Discoverer Extractor short</cell><cell>261 -</cell></row><row><cell>• Insight Discoverer Extractor long</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Content Enrichment Studio is a suite of four development tools that enables you to customize and extend existing Skill Cartridges ® , to develop new ones from scratch, and to track and optimize quality and performance. CER extracts chemical entities such as chemical compounds, chemical classes and molecular formulae and performs name-to-structure conversion. It includes support for International Union of Pure and Applied Chemistry (IUPAC) as well as Chemical Abstracts Service (CAS) registry numbers. CER can be successfully used in conjunction with BER or MER to reveal the chemical compounds at play in biological and medical contexts. It can also be customized with custom lexicons.</figDesc><table><row><cell>ChemiCAl entitieS Luxid ® Skill Cartridge ® reCOGnitiOn SKill CArtridGe ®</cell><cell></cell></row><row><cell>Library</cell><cell></cell></row><row><cell>Luxid ® Skill Cartridge ® Library is a range</cell><cell></cell></row><row><cell>of off-the shelf extractors developed by TEMIS</cell><cell>OM</cell></row><row><cell>to address recurring use cases and domains. RTF sTF ipTc ci Content Enrichment Studio lUxid ® KnOwledGe editOr enables the development and optimization of TM Luxid ® Luxid ® Taxonomy-based Skill Cartridges ® . It provides a user-friendly interface that streamlines the process of importing and editing taxonomies, thesauri, and/or controlled vocabularies, and of packaging them into a Skill Cartridge ® that can be used within Luxid ® Annotation Factory. Luxid ® Knowledge Editor also provides access to a wide variety of parameters and training processes that help fine-tune the behavior of Taxonomy-based Skill Cartridges ® . Luxid ® Knowledge Editor can also be used to access lexical resources present in all types of Skill Cartridges ® . lUxid ® SKill CArtridGe ® bUilder supports the development of semantic rules-CAteGOry wOrKbenCh supports both the development and optimization of Categorization Skill Cartridges ® . Such Skill Cartridges ® leverage statistics to categorize documents according to predefined document classification plans. Luxid ® Category Workbench also includes a clustering feature that is able to suggest possible classification plans when no such plan is available for reference. lUxid ® AnnOtAtiOn wOrKbenCh provides a window into the quality and perfor-based Skill Cartridges lUxid ® mance of Skill Cartridges ® developed with either</cell><cell>Available in the English language, BER ex-tracts both 15 key types of biological entities and 17 relationships binding them, as well as rich contextual information. Extracted entities include Anatomical terms, Cells and Tissues, Proteins and Genes, Disorders, Treatments, Species, Genomic and Mutational informa-tion. Relationships include Activation, Inhibi-tion, Regulation, Gene expression, Mutation, Diagnosis, and Therapy. BER is powered by a deep syntactical analysis layer that provides an intimate and highly structured understan-ding of complex biological mechanisms and pathways. mediCAl entitieS And relAtiOnShip SKill CArtridGe ® MER extracts 15 key types of medical entities and 10 types of semantic relationships binding them. Extracted entities include Clinical Trial terms, Diagnostics, Disorders, Transmission information, Genomic information, Species information, Ethnic information, Symptoms, BER MER Luxid ® Knowledge Editor or Luxid ® Skill Car-tridge ® Builder. It supports the manual curation (validation, correction, removal and insertion of annotations by the human operator) as well as the automated evaluation and generation of re-ports regarding Skill Cartridge ® extraction qua-lity by comparison to a pre-annotated reference corpus. The reports produced by Luxid ® Annota-tion Workbench can be used to evaluate a Skill Cartridge ® 's extraction quality on an absolute basis, to compare it with another Skill Cartridge ® (for example subsequent versions of the same, to evaluate progress) or to compare its performance across different corpora. Luxid ® Annotation Work-bench also enables domain experts to create ma-chine-learning based Skill Cartridges ® by simply training them to identify and extract information based on a manually-annotated corpus.</cell></row><row><cell></cell><cell>Targets, Treatments, and Administration Routes.</cell></row><row><cell>MLX</cell><cell></cell></row></table><note><p><p>Examples of relationships include Adverse</p>Effects (binding a treatment with a negative effect), Therapies (binding a treatment with a disease), and Molecular Targets (binding a process with certain specific entity types). ® . Such rules, written and optimized by developers, constitute models that leverage the part-of-speech tags and morphosyntactic properties of text to recognize entities of interest when they appear in documents, as well as their relationships and respective roles in these relationships. Thanks to Luxid ® Skill Cartridge ® Builder developers can apply the full power of semantics to virtually any type of domain or use case.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>• Abbreviations and contractions (e.g. "don't") • Punctuation(periods, commas, exclamation marks, etc.)    </figDesc><table><row><cell></cell><cell>Inxight LinguistX</cell></row><row><cell>Ranging &gt;&gt;&gt; Rang Rang &gt;&gt;&gt; Rang</cell><cell>Ring Rang Ringing } Ring Ranging &gt;&gt;&gt; Range</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>• Automatically create executive summaries from the context of each article. • Automatically create and embed hyperlinks of key concepts. • Provide dynamic annotation on hyperlinks, allowing users to actively see key 'live' information (such as a company's current stock price or company overview), or jump to related Web sites such as the company home page, SEC (Edgar) database, a financial news page, or a list of related news articles. • Actively find similar news content to support the "find more like this" function.</figDesc><table><row><cell>Linguistics-based</cell><cell cols="2">Uses natural language processing that includes language</cell><cell>When systems know "what</cell></row><row><cell cols="3">Inxight's Linguistic Technology drivers identification, word stemming, compound word analysis, word</cell><cell>you mean", it enhances the</cell></row><row><cell></cell><cell cols="2">and phrase tokenization, noun-phrase concept identification,</cell><cell>quality of categorization,</cell></row><row><cell>Feature</cell><cell>Description and part-of-speech tagging.</cell><cell></cell><cell>Benefit hyperlinking,</cell></row><row><cell>Auto categorization Auto-index tagging</cell><cell cols="2">Automatically categorizes and organizes documents, such as news feeds, word processing files and email, into pre-defined subject categories. Examples: Language ID "Ich bin ein Berliner" = German (Deutsch) "I am a citizen of Berlin" = English Word Stemming Automatically embeds category indexes as metadata into "selling" = sell; "bought" = buy each article or file, or into an index repository. Compound Word Analysis</cell><cell>summarization and finding Speeds search by similar/ related documents. organizing information into logical directories and Moreover, the linguistics folders. aspects helps process text in a Creates lasting, reusable way that helps a computer value to documents. better manage information by</cell></row><row><cell></cell><cell>"homeowner" = home owner</cell><cell></cell><cell>knowing more than words -but</cell></row><row><cell>Intelligent</cell><cell cols="2">Automatically creates intelligent summaries based on the Tokenization</cell><cell>Users save time by extracting concepts and</cell></row><row><cell>summaries</cell><cell cols="2">context of an article or file. Configurable -summaries can "Mr. Kim, an investor's representative, said, 'The stock is</cell><cell>'previewing' documents content.</cell></row><row><cell></cell><cell cols="2">be defined to have a specific length or genre preference. undervalued'."</cell><cell>while searching.</cell></row><row><cell></cell><cell cols="2">[mr kim an investor representative said the stock is</cell></row><row><cell>Hyperlinks Hyperlink annotation/ menus</cell><cell cols="2">Automatically create and embed hyperlinks that identifies and highlights 27 key entities including people, company names and ticker symbols, product names and places. undervalued] Noun-Phrase "The financial analyst reports are listed on the finance Internet website." [financial analyst report] and [financial Internet website] Extends the hyperlink function to include dynamic 'annotative" menus, allowing users to "roll-over" a hyperlink and view information or menus related to the hyperlink. Part-of-Speech Tagging "The merger initiative folded." [merger: adjective][initiative: noun][folded: verb]</cell><cell>Users save time by previewing key information (e.g. stock price) or by jumping to a related URL via a hyperlink. Creates a user-friendly dimension to hyperlinks where the user can decide,</cell></row><row><cell></cell><cell></cell><cell></cell><cell>using a menu, which place</cell></row><row><cell></cell><cell cols="2">Applied to hyperlinks, this can also be used to present</cell><cell>he/she wants to jump to, as</cell></row><row><cell></cell><cell cols="2">executive style "summaries" of Web pages behind each</cell><cell>well as previewing "live"</cell></row><row><cell></cell><cell>link.</cell><cell></cell><cell>dynamic data, like a stock</cell></row><row><cell></cell><cell cols="2">Example: The name Oracle Corporation is hyperlinked. The</cell><cell>price, without having to "jump" around.</cell></row><row><cell></cell><cell cols="2">dynamic menu would give the following information:</cell></row><row><cell></cell><cell>ORCL 30.25 up 0.50</cell><cell>(jump to cnnfn.com)</cell></row><row><cell></cell><cell>CEO: Larry Ellison</cell><cell>(jumps to eWEEK)</cell></row><row><cell></cell><cell>www.oracle.com</cell><cell>(jumps to Web site)</cell></row><row><cell></cell><cell>Look up on Yahoo! News</cell><cell>(jumps to Yahoo!)</cell></row><row><cell>Article similarity</cell><cell cols="2">Compares document with others in the knowledge base to</cell><cell>Makes discovery of related</cell></row><row><cell></cell><cell cols="2">discover related or "similar" documents.</cell><cell>articles fast and easy.</cell></row><row><cell>Customizable</cell><cell cols="2">Translates acronyms, abbreviations, name aliases and ticker</cell><cell>Enhances search and</cell></row><row><cell>Thesaurus</cell><cell>symbols into normalized concepts.</cell><cell></cell><cell>hyperlinking functionalities</cell></row><row><cell>module</cell><cell>Examples:</cell><cell></cell><cell>by taking abstract concepts</cell></row><row><cell></cell><cell cols="2">SEC=Securities Exchange Commission, CTO=Chief</cell><cell>and normalizing them to a</cell></row><row><cell></cell><cell>Technology</cell><cell></cell><cell>common term for easier</cell></row><row><cell></cell><cell cols="2">Officer, President Bill Clinton = William J. Clinton,</cell><cell>navigation and search.</cell></row><row><cell></cell><cell>ORCL=Oracle Corp</cell><cell></cell></row></table><note><p><p><p><p><p>• Create a user-definable thesaurus that translates acronyms, industry terms, company names, name aliases, abbreviations and stock ticker symbols into full titles and names.</p>•</p>Increase accuracy using patented, linguistic pre-processing engines.</p>•</p>Store category indexes, summaries and key entities via XML output to an industry standard format, allowing for ease of integration with other enterprise applications.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>About InxightInxight Software, Inc. is the leading provider of enterprise software solutions for information discovery. Using Inxight solutions, organizations can access and analyze unstructured, semi-structured and structured text to extract key information to enable business intelligence. Inxight is the only company that provides a complete, scalable solution enabling information discovery in more than 30 languages. Customers include enterprise companies such as Novartis, Procter &amp; Gamble and Thomson, multiple U.S. and foreign government agencies, including the Department of Defense, Defense Intelligence Agency, Department of Homeland Security and Commonwealth Secretariat, and software OEMs such as SAP, SAS, Oracle and IBM. The company has offices throughout the United States and Europe. For more information, visit www.inxight.com or call 1-408-738-6299 or 703.251.4429.</figDesc><table><row><cell>Inxight SmartDiscovery Extraction Server (SDX)</cell></row><row><cell>Technical Specifications</cell></row><row><cell>• Industry Standard SOAP APIs for</cell></row><row><cell>easy integration into any system</cell></row><row><cell>• Supports more than 220 file formats,</cell></row><row><cell>including Microsoft Office documents, Leveraging Inxight's deep PDF, XML, HTML, text and email.</cell></row><row><cell>linguistic understanding, • Browser-based administration</cell></row><row><cell>SmartDiscovery • Reference integrations with several</cell></row><row><cell>common enterprise systems and is able to discover entities repositories, including:</cell></row><row><cell>based on patterns in text, -Web, file systems, Microsoft</cell></row><row><cell>Exchange (Content sources)</cell></row><row><cell>automatically identifying -Oracle, SQL Server, Mark Logic,</cell></row><row><cell>and IBM DB2 Viper (metadata more than 35 named entity storage)</cell></row><row><cell>types out-of-the-box. Operating Systems</cell></row><row><cell>• Windows 2003</cell></row><row><cell>• Solaris 9.0 and 10.0</cell></row><row><cell>• Red Hat Linux ES 3.0 and 4.0</cell></row><row><cell>• Red Hat Linux AS 3.0</cell></row><row><cell>Browsers</cell></row><row><cell>• Microsoft Internet Explorer 5.5 and 6.0</cell></row><row><cell>Languages</cell></row><row><cell>Arabic, Chinese (Simplified), English,</cell></row><row><cell>Farsi (Persian), French, German, Italian,</cell></row><row><cell>Japanese, Korean, and Spanish.</cell></row><row><cell>Contact Inxight about the availability of</cell></row><row><cell>other languages.</cell></row><row><cell>SmartDiscovery</cell></row><row><cell>Awareness Server federated search and alert offering.</cell></row><row><cell>www.inxi g h t . c o m</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Biological Entity Relationships Skill Cartridge™ &lt; A Skill Cartridge™ is</head><label></label><figDesc></figDesc><table><row><cell></cell><cell cols="2">Inxight ThingFinder</cell></row><row><cell></cell><cell cols="2">Technical Specifications</cell></row><row><cell></cell><cell cols="2">Operating Systems</cell></row><row><cell></cell><cell cols="2">• Microsoft Windows 2000, XP and 2003</cell></row><row><cell></cell><cell cols="2">Server with MSVC 6, and 2003 Server</cell></row><row><cell></cell><cell>with MSVC 7.0</cell></row><row><cell></cell><cell cols="2">• Sun Solaris 8.0 and 9.0 with GCC 3.2.3</cell></row><row><cell></cell><cell cols="2">and Solaris 9.0 with Forte 32 bit</cell></row><row><cell></cell><cell cols="2">• Red Hat Linux ES 2.1 with GCC 2.9.6,</cell></row><row><cell></cell><cell cols="2">AS 3.0 with GCC 3.2.3, and AS 4.0 with</cell></row><row><cell></cell><cell>GCC 3.4.3</cell></row><row><cell></cell><cell cols="2">• AIX 5.2 with Visual Age 5.0</cell></row><row><cell></cell><cell cols="2">• HPUX 11.11 with aCC A 03.37</cell></row><row><cell></cell><cell cols="2">Available Language Modules</cell></row><row><cell></cell><cell cols="2">Arabic, Chinese (Simplified), Chinese</cell></row><row><cell></cell><cell cols="2">(Traditional), Dutch, English, Farsi (Persian),</cell></row><row><cell></cell><cell cols="2">French, German, Italian, Japanese, Korean,</cell></row><row><cell></cell><cell cols="2">Portuguese, Russian, Spanish, Swedish,</cell></row><row><cell></cell><cell cols="2">Danish, Bokmål, Nynorsk, Finnish</cell></row><row><cell></cell><cell cols="2">Contact Inxight about the availability of</cell></row><row><cell></cell><cell>other languages.</cell></row><row><cell></cell><cell cols="2">Pre-Defined Entity Categories</cell></row><row><cell></cell><cell cols="2">Entity categories can be customized and</cell></row><row><cell></cell><cell cols="2">new categories may be added. Not all entity</cell></row><row><cell></cell><cell cols="2">types are supported in all languages.</cell></row><row><cell></cell><cell>• Address</cell><cell>• Place</cell></row><row><cell></cell><cell>• City</cell><cell>-Regions</cell></row><row><cell></cell><cell>• Company</cell><cell>-Political</cell></row><row><cell></cell><cell>• Country</cell><cell>-Geographical</cell></row><row><cell></cell><cell>• Currency</cell><cell>Areas</cell></row><row><cell></cell><cell>• Date</cell><cell>• Product</cell></row><row><cell></cell><cell>• Day</cell><cell>• Social Security</cell></row><row><cell></cell><cell>• Holiday</cell><cell>Number</cell></row><row><cell></cell><cell>• Internet Address</cell><cell>• State</cell></row><row><cell></cell><cell>• Measure</cell><cell>• Ticker Symbol</cell></row><row><cell></cell><cell>• Month</cell><cell>• Time</cell></row><row><cell></cell><cell>• Noun Group • Organization</cell><cell>• Time Period</cell></row><row><cell></cell><cell>• Percent</cell><cell>• Vehicle</cell></row><row><cell></cell><cell>• Person</cell><cell>-Make</cell></row><row><cell></cell><cell cols="2">-Position -Given Name -Family Name -Suffix a set of customizable -Model knowledge components describing the -Color information relevant for extraction. -VIN &lt; A knowledge component can be a lexicon</cell></row><row><cell></cell><cell>-Affiliation and/or an extraction rule.</cell><cell>-License Plate</cell></row><row><cell></cell><cell cols="2">• Phone Number &lt; An extraction rule describes a sentence structure • Year</cell></row><row><cell></cell><cell>that characterizes a concept.</cell></row><row><cell></cell><cell cols="2">For the specific needs of Life Science Research,</cell></row><row><cell>Text</cell><cell cols="2">TEMIS offers the Biological Entity Relationships</cell></row><row><cell>Intelligence™</cell><cell cols="2">Skill Cartridge™. This Skill Cartridge combines the bio-computing expertise of Fraunhofer</cell></row><row><cell></cell><cell cols="2">Institute for Algorithms and Scientific Computing</cell></row><row><cell></cell><cell cols="2">(SCAI) for the recognition of protein and gene</cell></row><row><cell></cell><cell cols="2">www.inx i g h t . c o m entities with the know-how of TEMIS Text Mining</cell></row><row><cell></cell><cell>technology in a single package.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Biological Entity Relationships Skill Cartridge™ Biological Entity Relationships Skill Cartridge™ library Hunting for Relevant Information Efficient information access is a major challenge in biological, chemical and clinical research today. As a result, we are observing a steadily growing demand to integrate information from various sources and across different disciplines in life sciences. However, a large portion of this information is only available from scientific articles and patent documents that are stored in free text format. The volume of this literature is growing exponentially and makes it almost impossible for researchers and scientists to retrieve all relevant information on a specific topic and keep up with current research. TEMIS Text Mining technology is a powerful and highly accurate solution for the transformation of large collections of literature into readily actionable and domain-specific knowledge.</head><label></label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Biological Entity Relationships Skill Cartridge™ is</head><label></label><figDesc>able to identify relationships between biological entities and to view them as interactive html reports or as graphical relational networks. This interactive vizualisation in the CYTOSCAPE tool helps scientists identify biological mechanisms and pathways, validate targets and define new therapeutic strategies for diseases or syndromes. Extraction results can be easily sorted by entity or by relationship type (gene expression, localization, activation, inhibition, regulation, binding, interaction) and highlighted in the context of the original document.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Contact For more information: TEMIS France &lt;&lt; Headquarters</head><label></label><figDesc></figDesc><table><row><cell>Tour Gamma B 193-197 rue de Bercy 75582 Paris Cedex 12 France Tel. : +33 (0)1 40 04 46 70 info@temis-group.com</cell><cell>Contact</cell></row><row><cell></cell><cell>01</cell></row><row><cell></cell><cell>46</cell></row><row><cell></cell><cell>21</cell></row><row><cell></cell><cell>14</cell></row><row><cell></cell><cell>60</cell></row><row><cell></cell><cell>INTER PUBLI GRAPHIQUE</cell></row><row><cell></cell><cell>ABOUT</cell></row><row><cell></cell><cell>FRAUNHOFER SCAI</cell></row><row><cell></cell><cell>Contact:</cell></row><row><cell></cell><cell>Juliane Fluck</cell></row><row><cell></cell><cell>Tel. +49 2241 14-2188</cell></row><row><cell></cell><cell>juliane.fluck@scai.fhg.de</cell></row><row><cell></cell><cell>www.scai.fraunhofer.de</cell></row><row><cell>Text</cell><cell></cell></row><row><cell cols="2">Intelligence™</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>BabelFish use math principles to translate documents online</head><label></label><figDesc></figDesc><table><row><cell>Google, Yahoo! BabelFish use math principles to translate documents online</cell><cell>Page 1 of 4</cell></row><row><cell></cell><cell>2/27/2011</cell></row></table><note><p>The computer wouldn't understand the Advertisement www.PrintGroupon.com/383361 http://www.washingtonpost.com/wp-dyn/content/article/2011/02/21/AR2011022102191_pf.html Print Powered By Google, Yahoo! http://www.washingtonpost.com/wp-dyn/content/article/2011/02/21/AR2011022102191_p...</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head>Yahoo! BabelFish use math principles to translate documents online</head><label></label><figDesc></figDesc><table><row><cell>Google, Yahoo! BabelFish use math principles to translate documents online</cell><cell>Page 4 of 4</cell></row><row><cell>Monday, October 22, 2007</cell><cell></cell></row><row><cell>Posted by Alex Chitu at 10/22/2007 04:56:00 PM</cell><cell></cell></row><row><cell></cell><cell>2/27/2011</cell></row></table><note><p>http://www.washingtonpost.com/wp-dyn/content/article/2011/02/21/AR2011022102191_pf.html Advertisement Print Powered By Google, http://www.washingtonpost.com/wp-dyn/content/article/2011/02/21/AR2011022102191_p...</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_19"><head>Lecture 6.2b Reading 3a (optional) Reading 3a</head><label></label><figDesc>://googlesystem.blogspot.com/2007/10/google-translate-switches-togoogles.html (optional) gives more detail. Only for those really interested in this topic • Open source NLP software can help. A representative sampling of open source software in a nice NLP flowchart</figDesc><table><row><cell>Google Switches to Its Own Translation System</cell><cell>Page 1 of 1</cell></row><row><cell>Google Operating System</cell><cell></cell></row><row><cell>Unofficial news and tips about Google</cell><cell>45 -</cell></row><row><cell>• Transforming Unstructured Text into Actionable Data -slides, esp. p.</cell><cell>51 -</cell></row><row><cell>56 -59</cell><cell></cell></row><row><cell>• ThingFinder Concepts Guide.</cell><cell>69 -</cell></row><row><cell>A detailed description how ThingFinder works and a good introduction</cell><cell></cell></row><row><cell>to natural language processing (NLP) in general. Start at p. 47</cell><cell></cell></row><row><cell>The XeLDA paper (next)may be even better.</cell><cell></cell></row><row><cell>{ Thanks, Steve Rubel. }</cell><cell></cell></row><row><cell>Labels: Google Translate</cell><cell></cell></row><row><cell></cell><cell>2/27/2011</cell></row></table><note><p>http://googlesystem.blogspot.com/2007/10/google-translate-switches-to-googles.html http• XeLDA: integrate a linguistic engine in your applications Another good introduction to natural language processing (NLP) with many illustrations. Perhaps even better than the ThingFinde paper 107 -• Jaime Carbonell. Natural Language Processing 33 slides with very nice examples. Good overview 143 -• Libby, Elizabeth. Natural Language Processing. Article in the Encyclopedia of Library and Information Science 177 -• Inxight SmartDiscovery Awareness Server Interesting product that uses linguistic technology to post-process Google search results; for examples, extracts information from text into a relational database. Not sure this product still exists 191 -• Going beyond Google. Another document on the same system 195 -• Several</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_20"><head>TEMIS products (from the Luxid or the earlier Insight suites) for illustration of applications</head><label></label><figDesc></figDesc><table><row><cell>• Luxid in the medical domain. 18 slides • Analyzing patent literature to gain competitive insight with Luxid (medical domain) 42 slides • Insight Discoverer Extractor short Business Objects provides the tools to measure all your data! How can your Customers manage their business, when they can't • Insight Discoverer Extractor long BUSINESS OBJECTS + INXIGHT: 201 -219 -261 -measure it?</cell></row></table><note><p>At Xerox PARC:</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_21"><head>The science of Natural Language Processing was begun; The results of over 25 years of Research and Ten years on the market allows you the ability to add features so your customers can: Decrease Time spent gathering data Make Better Decisions Faster Increase Top Line Revenue by Uncovering New Opportunities Reduce costly mistakes and litigation thru better data management Inxight's information intelligence and discovery solutions transform unstructured data into timely, actionable information. 10 Products fall into 4 Categories Text Analytics:</head><label></label><figDesc></figDesc><table><row><cell>Linguist X Platform</cell></row><row><cell>Extraction Products</cell></row><row><cell>Categorizer</cell></row><row><cell>Summarizer</cell></row><row><cell>Federated Search:</cell></row><row><cell>Awareness Server</cell></row><row><cell>Data Cleansing:</cell></row><row><cell>Text Analysis</cell></row><row><cell>Metadata Management System</cell></row><row><cell>Visualizations:</cell></row><row><cell>StarTree, TableLens, and TimeWall</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_22"><head>Product Benefit Feature LXP Hi Accuracy 32 languages Clean Understanding Mult. Langs. POS out of the BOX Tokenization Stemming Extraction Reduced time and effort spent Easy Rule Writing capability identifying Data and relevant links Efficient Name Catalog feature Categorizer Reduces manual interaction with large Hybrid approach: data Sets Learn By Example Name Catalogs Easy Rule Extensibility Summarizer Reduces Review Time of large &amp; Complex Accurately portrays document Documents Highlights Awareness Server Reduces Acquisition Time Ability cast one single query (Federated Search) against multiple sources Text Analysis Improved Decision making Advanced business logic via links between unstructured and structured data Benefits and Features of the 10 Products Product Benefit Feature MMS Reduces Errors in complex Supports Enterprise or Global (Metadata Manag.System) Unstructured Data Metadata Management -Cleansing of data StarTree Reduces time to Action Reduces complex relationships to easy to understand trees of visually linked data TimeWall Decreases time to decision for Depicts complex data on 3-demensional complex time based business time based data in an easy to understand relationships visual setting TableLens Speeds up complex / can show 50,000 rows of complex multidimensional decision making Multi faceted data TableLens SDK: TRENDS AND CORRELATIONS Who can afford to lose 1.5Billion? Why didn't Microsoft see this coming? Where was the data showing the growing PROBLEM? What could have prevented the catastrophe? Extraction from Business Objects What an Email can cost you? If your Halliburton and an email contains "copy" in context to a competitor, the judgment could be: $100,000,000.00 Obviously you'd want to find it and know your liability before it gets discovered by apposing council Components from Business Objects can now empower compliance applications, e-mail Control, and Content Management products Summarizer Categorizer ThingFinder Resources Manager GUI Internal Java API Taxonomies Custom Rules Name Catalogs Resource Server File/Web Crawl Categorize Extract Output Summarize BusinessObjects™ INXIGHT Architecture (for BOE) Inxight MetaText Server (IMS) ThingFinder Workbench Categorizer Workbench Deploy (copy) Save Output Universe Crystal Reports Web Intelligence Metadata Editor Format Conversion ThingFinder Categorizer Summarizer XML over TCP/IP Metadata Repository File-based content Save Reports Summarizer Categorizer ThingFinder Resources Manager GUI Internal Java API Taxonomies Custom Rules Name Catalogs Resource Server File/Web Crawl Categorize Extract Output Summarize BusinessObjects™ INXIGHT Architecture (for BOE) + Data Integrator Inxight MetaText Server (IMS) ThingFinder Workbench Categorizer Workbench Deploy (copy) Save Output Universe Crystal Reports Web Intelligence Metadata Editor Format Conversion ThingFinder Categorizer Summarizer XML over TCP/IP Metadata Repository File-based content Data Warehouse Data Integrator (ETL) Save Reports APPLICATIONS WE CAN Facilitate</head><label></label><figDesc>Audience for this Guide . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Organization of This Guide . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Precision and Recall . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Output . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Entity Selection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Selection Principles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Length . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Occurrence in the Name Catalog . . . . . . . . . . . . . . . . . . . . . . . . . . Linguistic Confidence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Entity Type Weighting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Filters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</figDesc><table><row><cell>1</cell><cell></cell></row><row><cell></cell><cell>Contents</cell></row><row><cell></cell><cell>Business Objects ThingFinder™ is a powerful technology for enabling</cell></row><row><cell></cell><cell>customized extraction applications. Business Objects ThingFinder analyzes</cell></row><row><cell></cell><cell>General Publishing, Media &amp; Entertainment Voice of the Customer (sentiment) analysis, voice of the employee analysis, competitive analysis Buzz tracking, automated tagging Financial Services Regulatory Compliance, Fraud Detection, Insurance Claims Analysis Manufacturing BusinessObjects ThingFinder™ Concepts Guide Contents Chapter 1 About This Guide Glossary About This Guide text and automatically identifies and extracts more than 35 key entity types out of the box, including people, dates, places, companies or other things from any text data source, in multiple languages. The ThingFinder Professional module extends the power of extraction by enabling the detection and extraction of activities, events and relationships between entities and giving users a competitive edge with relevant information for their Name Catalog Lookup Chapter 4 business needs.</cell></row><row><cell></cell><cell>Warranty Analysis, Contract Analysis, Six Sigma Compliance</cell></row><row><cell></cell><cell>Healthcare</cell></row><row><cell></cell><cell>Common Cause Diagnosis, Regional Diagnosis, Patient Sentiment</cell></row><row><cell></cell><cell>Education</cell></row><row><cell>2</cell><cell>Application Analysis, Student Records Analysis, Administrative Records State and Local Constituent Analysis, Claims/Bid Tracking and Analysis BusinessObjects ThingFinder 4.3 Concepts Guide iii Chapter 3 ThingFinder Processing iv Concepts Guide chapter Concepts Guide</cell></row></table><note><p>Start on p. 8 in extract (61 in full document Downnloaded from http://help.sap.com/help.sap.com/ businessobject/product.../ xi3sp1_TA_thingfinder-4-3.pdf 2014-09-09 p. 53 -90 Related Documentation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Technical Support . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Chapter 2 Introducing ThingFinder What is Entity Extraction? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Challenges in Entity Extraction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Name Variation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Ambiguity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . The ThingFinder Solution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Linguistic Processing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Name Catalog . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Custom Extraction Rules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ThingFinder Architecture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ThingFinder Operations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Known Entity Matching . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . New Entity Discovery . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Entity Construction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Normalization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Post-processing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Candidate Generation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Pre-processing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Grouping . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Method and Confidence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Ambiguity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Post-Processing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Conjecturing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Aliasing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Relevance Ranking . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_24"><head></head><label></label><figDesc>ThingFinder Customization Guide-Describes how to create and use name catalogs and custom extraction rules to create your own extraction patterns.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_25"><head></head><label></label><figDesc>that perform extraction tasks use Business Objects ThingFinder™ technology. Business Objects ThingFinder™ is a multilingual suite of tools for building high-level applications with entity extraction and information retrieval components. Business Objects ThingFinder analyzes text and automatically identifies and extracts more than 35 key entity types out of the box, including people, dates, places, companies an so on, from any text data source, in multiple languages. In addition, the ThingFinder Professional module extends the power of extraction by enabling the detection and extraction of activities, events and relationships between entities.Extracting entities from a document tells us what the document is about-the people, organizations, places and other parties described in the document. Extraction involves processing and analyzing text documents, finding entities of interest, assigning them to the appropriate type, and presenting this metadata in a standard format. Extraction applications are as diverse as your information needs. Some examples of relationships and events that can be extracted with ThingFinder Professional include:</figDesc><table><row><cell></cell><cell>Business Objects products</cell><cell></cell></row><row><cell></cell><cell>Introducing ThingFinder</cell><cell></cell></row><row><cell>6</cell><cell>Concepts Guide</cell><cell>chapter</cell></row></table><note><p><p>• Co-occurrence and associations of brand names, company names, people, supplies, and more</p>• Competitive and market intelligence such as competitors' activities, merger and acquisition events, press releases, contact information, and so on • A person's associations, activities, or role in a particular event • Customer claim information, defect reports or patient information such as adverse drug effects</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_28"><head></head><label></label><figDesc>ThingFinder provides tools for recognizing variant names and for distinguishing the different interpretations of ambiguous examples.</figDesc><table><row><cell>2</cell><cell cols="2">Introducing ThingFinder The ThingFinder Solution</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>PERSON</cell><cell>Entity Type</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Real-world</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Entity</cell></row><row><cell></cell><cell></cell><cell>John Doe</cell><cell cols="2">John Smith Doe</cell><cell>Mr. Doe</cell><cell>J. S. Doe</cell><cell>Names</cell></row><row><cell></cell><cell></cell><cell></cell><cell>PERSON</cell><cell cols="2">STATE (USA)</cell><cell>COUNTRY</cell><cell>Entity Type</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Real-world</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Entity</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Georgia</cell><cell>Name</cell></row><row><cell></cell><cell>10</cell><cell>Concepts Guide</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_29"><head></head><label></label><figDesc>CGUL, they are compiled and then they are used by the ThingFinder extraction engine to identify and extract matching patterns from text. You can define and extract the following types of information by writing rules of varying complexity:</figDesc><table><row><cell>2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="2">ThingFinder Workbench or</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="2">COMPANY</cell><cell></cell><cell></cell><cell>Entity Type</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Real-world Entity</cell></row><row><cell></cell><cell></cell><cell cols="2">General Motors Corporation</cell><cell></cell><cell></cell><cell>Canonical Name</cell></row><row><cell></cell><cell>GMC</cell><cell>General Motors</cell><cell>General</cell><cell>GMH</cell><cell>GM</cell><cell>Variant Names</cell></row><row><cell></cell><cell></cell><cell>Corp</cell><cell>Motors</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>ABBREV</cell><cell>Variant Type</cell></row><row><cell>12</cell><cell cols="2">Concepts Guide</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_30"><head></head><label></label><figDesc>The name catalog lookup maximizes precision if you have created a name catalog containing the entities you want to extract. It can also generate entity candidates when it finds matching entities.Concepts Guide 19ThingFinder Professional custom extraction lookup expands extraction capabilities to also include events and relations, if you have created rules that express the patterns you want to extract. It also generates extraction candidates when it finds matches.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>ThingFinder Processing Candidate Generation 3</cell></row><row><cell>Input Text</cell><cell cols="3">Candidate Generation</cell><cell cols="2">Entity Selection</cell></row><row><cell></cell><cell>Standard Language Modules</cell><cell>Name Catalog Lookup</cell><cell>Custom Extraction</cell><cell>Entity Creation</cell><cell>Post-processing</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Lookup</cell><cell></cell></row><row><cell></cell><cell>Entity</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">Extractio</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">ThingFinder Output</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_31"><head></head><label></label><figDesc>they form the basis for the grouping operation. As a result, ThingFinder identifies phrases like big old house, crucial question, New York City, Microsoft Corporation, and so on.</figDesc><table><row><cell>3</cell><cell cols="2">ThingFinder Processing Candidate Generation</cell></row><row><cell></cell><cell></cell><cell>occurrence, and</cell></row><row><cell></cell><cell>20</cell><cell>Concepts Guide</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_33"><head></head><label></label><figDesc>If ambiguous entities are found, they are resolved if possible, and the results are output.</figDesc><table><row><cell>3</cell><cell cols="2">ThingFinder Processing Entity Selection</cell></row><row><cell></cell><cell></cell><cell>Valu</cell><cell>Description</cell></row><row><cell></cell><cell></cell><cell>e</cell></row><row><cell></cell><cell></cell><cell>30</cell><cell>Custom rule match</cell></row><row><cell></cell><cell></cell><cell>25</cell><cell>Name Catalog entry and ThingFinder match the same type</cell></row><row><cell></cell><cell></cell><cell>20</cell><cell>Name Catalog entry only match</cell></row><row><cell></cell><cell></cell><cell>15</cell><cell>Name Catalog entry and ThingFinder entity match different entity</cell></row><row><cell></cell><cell></cell><cell>types</cell></row><row><cell></cell><cell></cell><cell>10</cell><cell>ThingFinder entity type only match</cell></row><row><cell></cell><cell></cell><cell>9</cell><cell>Strong conjecture to custom entity</cell></row><row><cell></cell><cell></cell><cell>8</cell><cell>Strong conjecture to ThingFinder entity</cell></row><row><cell></cell><cell></cell><cell>6</cell><cell>Weak conjecture</cell></row><row><cell></cell><cell></cell><cell>4</cell><cell>Ambiguous custom entity output</cell></row><row><cell></cell><cell></cell><cell>3</cell><cell>Ambiguous ThingFinder entity output</cell></row><row><cell></cell><cell></cell><cell>1</cell><cell>PROP_MISC</cell></row><row><cell></cell><cell>24</cell><cell>Concepts Guide</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_34"><head></head><label></label><figDesc>Example Foobar was campaigning for her second term in office. Ms. Foobar, known for her appetite for sushi, gathered her supporters for a benefit dinner. Consider the following ambiguous example, which assumes that nation's capital is listed in a name catalog as a variant name for Washington DC:Example Washington is buzzing with excitement. The nation's capital has a new leader.</figDesc><table><row><cell>3</cell><cell cols="2">ThingFinder Processing Entity Selection</cell></row><row><cell></cell><cell></cell><cell>Output</cell></row><row><cell></cell><cell></cell><cell>[Foobar]PROP_MISC</cell></row><row><cell></cell><cell></cell><cell>[Ms. Foobar]PERSON</cell></row><row><cell></cell><cell></cell><cell>ThingFinder examines [Foobar]PROP_MISC and finds [Ms. Foobar]PERSON</cell></row><row><cell></cell><cell></cell><cell>in the same input buffer. ThingFinder then conjectures that Foobar is also of</cell></row><row><cell></cell><cell></cell><cell>type PERSON. [Foobar]PERSON is returned with its method marked as</cell></row><row><cell></cell><cell></cell><cell>tf_conjectured.</cell></row><row><cell></cell><cell>26</cell><cell>Concepts Guide</cell></row></table><note><p><p>Output [Washington]CITY/STATE [nation's capital]CITY</p>Washington is ambiguous between CITY and STATE, and conjecture seeks to resolve the ambiguity. During conjecture, ThingFinder will compare [Washington]CITY/STATE with the canonical form of the [nation's capital]CITY, which is Washington DC, and conjecture that it is a CITY rather than a STATE. This same process may yield incorrect results in certain cases, e.g. the following, where Washington should be typed as a STATE:</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_36"><head>Modeling language... Understanding written language is a formidable challenge for information science: the wealth of language requires sophisticated automated processing. Inter and intra-company communication, by definition multilingual, and the increasing volume of documents available in electronic format require high-performance content analysis and management, data/text mining, indexing, authoring/translation support and information retrieval tools. XeLDA ® , the linguis- tic engine</head><label></label><figDesc></figDesc><table><row><cell cols="3">XeLDA ® : integrate a linguistic engine</cell></row><row><cell cols="2">P post-processing operations 25 in your applications</cell><cell></cell></row><row><cell>precision and recall 14 Index R</cell><cell></cell><cell></cell></row><row><cell>reference, defined 30</cell><cell></cell><cell></cell></row><row><cell>A relevance ranking 28</cell><cell>H</cell><cell></cell></row><row><cell>alias group, defined 30 relevance ranking, defined 31</cell><cell>handling ambiguity 24</cell><cell></cell></row><row><cell>alias list, defined 30</cell><cell></cell><cell></cell></row><row><cell>alias, defined 30 S aliasing 26 segment generation 19 aliasing, defined 30 segment, defined 32 ambiguity, defined 30 ambiguity, how ThingFinder handles 24 ambiguity, the problem of 9 architectural overview 12 selecting ThingFinder entities 21 selection principles 21 sub-entity, defined 32</cell><cell cols="2">K known entity matching 13 L language and encoding identification 19 language module grouping 19</cell></row><row><cell>T C ThingFinder processing algorithm 17 candidate generation 18 ThingFinder workflow 18 canonical name, defined 30 challenges in entity extraction 8 V confidence values explained 23 variant name, defined 32</cell><cell cols="2">language modules, defined 31 language modules, introduced 10 length principle 21 linguistic confidence principle 22 linguistic pre-processing of input 19 Why choose XeLDA ® ? M XeLDA ® and its range or services have been</cell></row><row><cell>conjecture, defined 30 variant type, defined 32</cell><cell>method, defined 31</cell><cell>designed to optimize third-party applications</cell></row><row><cell>conjecturing 25</cell><cell></cell><cell>based on a series of advantages:</cell></row><row><cell>W D disambiguation, defined 31 discovering entities 13, 18 E word segmentation 19 word segmentation, defined 32 entity extraction, overview 7 entity selection 21 entity type weighting principle 23 entity type, defined 31 entity, defined 31 enumeration, defined 31</cell><cell cols="2">N name catalog compiler, defined 31 ➜ Renowned XFST linguistic technology from name catalog entries with wildcards 20 the Xerox ® Laboratories (Xerox ® Finite State Transducers) name catalog entries without wildcards 20 ➜ Client/server or standalone architecture name catalog lookup 20 ➜ Open and modular architecture name catalog, defined 31 name catalog, introduced 11 ➜ Fast processing name variant ➜ Unicode-compliant defined 32 ➜ Robust name variation, the problem of 8 ➜ Easy to integrate (API) normalization, defined 31 ➜ Results generated in XML format noun group, defined 31 ➜ Available in 16 languages</cell></row><row><cell>G generating candidate entities 18 grouping 19</cell><cell cols="2">O output, format of 15 overview of ThingFinder 5</cell></row><row><cell></cell><cell></cell><cell>It's a long way round (adverb).</cell></row><row><cell></cell><cell></cell><cell>How do you round (verb) a</cell></row><row><cell></cell><cell></cell><cell>Guide 33 number to 2 decimal places</cell></row><row><cell></cell><cell></cell><cell>with this spreadsheet?</cell></row><row><cell></cell><cell></cell><cell>We began a new round (noun)</cell></row><row><cell>Text</cell><cell></cell><cell>of negotiations.</cell></row><row><cell>Intelligence™</cell><cell></cell><cell></cell></row><row><cell>XeLDA ®</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_42"><head></head><label></label><figDesc>See the XeLDA Tagsets files in xelda/docs for the tags associated with the language being analysed. υ For programming details, see the XeLDA C++ API Programmer's Guide and the XeLDA Java Programmer's Guide.</figDesc><table><row><cell cols="2">About XeLDA's Linguistic Services</cell></row><row><cell cols="2">υ ---ing = verb, noun, adj</cell></row><row><cell>υ</cell><cell>digit = number</cell></row><row><cell cols="2">Czech, Dutch, English, French, German, Greek, Hungarian, Italian, Polish,</cell></row><row><cell cols="2">Portuguese, Russian and Spanish. Other languages are in development.</cell></row><row><cell>! ! "</cell><cell></cell></row><row><cell></cell><cell>XeLDA white paper</cell><cell>14</cell></row></table><note><p>υ υ For the C++ example, see the "MorphoAnalysis" folder.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_44"><head></head><label></label><figDesc>For the C++ example, see the "DictionaryLookup" folder.</figDesc><table><row><cell>Input text:</cell></row><row><cell>..., U.S. District judge Thomas Penfield Jackson wrote in a 50-page</cell></row><row><cell>opinion ...</cell></row><row><cell>... James Barksdale, the former chief executive of Netscape</cell></row><row><cell>Communications Corp. ...</cell></row><row><cell>IDAREX expression:</cell></row></table><note><p>υ NP [ judge N: | (DET) (ADJ) :chief :executive (:of) ] NP Result: ..., U.S. District judge Thomas Penfield Jackson wrote in a 50-page opinion ... ... James Barksdale, the former chief executive of Netscape Communications Corp., ... English, French, German, Italian and Spanish have predefined word categories and macros. Others can be added on request. # About XeLDA's Linguistic Services XeLDA white paper 24</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_49"><head></head><label></label><figDesc>Symbolic approaches have been used for a few decades in a variety of research areas and applications such as information extraction, text categorization, ambiguity resolution, and lexical acquisition. Typical techniques include: explanation-based learning, rule-based learning, inductive logic programming, decision trees, conceptual clustering, and K nearest neighbor algorithms (6; 33).</figDesc><table><row><cell>Statistical Approach</cell></row><row><cell>Statistical approaches employ various mathematical techniques and often use large text</cell></row><row><cell>corpora to develop approximate generalized models of linguistic phenomena based on</cell></row><row><cell>actual examples of these phenomena provided by the text corpora without adding</cell></row><row><cell>significant linguistic or world knowledge. In contrast to symbolic approaches, statistical</cell></row><row><cell>approaches use observable data as the primary source of evidence.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_51"><head></head><label></label><figDesc>Deliver relevant information to each user's desktop or mobile device based on their individual information needsInxight SmartDiscovery Awareness Server greatly reduces the time users spend staying on top of the important changes in their business.The Alert module in SmartDiscovery Awareness Server includes the ability to set up email and landing page alerts based on changes to a specific document or Web page or the appearance of newly available information of interest in Deep Web, Internet, news, internal systems, or other sources.Page tracking keeps users aware of changes to a single Web page or document of interest -price changes on a competitive product, patent filing status changes from a patent database, new press releases or news coverage listed on a competitor's Website -whatever information is important to you and your job.Saved search alerts provide users with email or mobile alerts on the latest newly available information that might impact business decisions -new product coverage, new Usenet postings, new patents and more. The system knows what users have already seen and what is new to them. Users need ask only once to stay on top of daily changes.</figDesc><table><row><cell cols="2">Inxight SmartDiscovery Awareness Server</cell><cell>Inxight SmartDiscovery Awareness Server</cell></row><row><cell></cell><cell cols="2">Inxight SmartDiscovery ™</cell></row><row><cell></cell><cell cols="2">Awareness Server</cell></row><row><cell></cell><cell cols="2">Uncover New Revenue Opportunities and Speed Analysis Awareness Access</cell></row><row><cell></cell><cell cols="2">Time-to-Information through the Power of Inxight Extraction</cell></row><row><cell>Inxight SmartDiscovery</cell><cell></cell><cell></cell></row><row><cell>Awareness Server is a</cell><cell>Intranet, Content Mgmt. Systems,</cell><cell></cell></row><row><cell>proven federated search and</cell><cell>Classified Sources…</cell><cell></cell></row><row><cell>alert solution that helps users</cell><cell></cell><cell>Automated Alerts</cell></row><row><cell>derive insight and intelligence</cell><cell></cell><cell>De-Dupe</cell></row><row><cell>from hundreds of high-</cell><cell>Invisible Web Databases</cell><cell></cell></row><row><cell>value information sources</cell><cell>(Patents, SEC, Gov …)</cell><cell>Categorize</cell></row><row><cell>through a single interface.</cell><cell></cell><cell></cell></row><row><cell>Alerts and page tracking</cell><cell></cell><cell>Portals</cell></row><row><cell>automatically inform users of</cell><cell>News, Publications,</cell><cell>Relevance Rank</cell></row><row><cell>new and updated information</cell><cell>Public Websites, Boards, Usenet, Blogs…</cell><cell></cell></row><row><cell>impacting their business.</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>Monitoring</cell></row><row><cell></cell><cell></cell><cell>Web Application</cell></row><row><cell></cell><cell>ECM, CRM,</cell><cell></cell></row><row><cell></cell><cell>Other Databases</cell><cell>Source Suggest</cell></row><row><cell></cell><cell></cell><cell>and More</cell></row><row><cell></cell><cell>Premium Content</cell><cell>Custom Enterprise/</cell></row><row><cell></cell><cell>(Factiva, LexisNexis,</cell><cell>OEM Applications</cell></row><row><cell></cell><cell>WestLaw…)</cell><cell></cell></row><row><cell>www.inxight.com</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_53"><head>➜ A "CRM" Skill Cartridge™ to improve your customer understanding*.</head><label></label><figDesc></figDesc><table><row><cell>It detects consumer satisfaction or discontent</cell></row><row><cell>with a given product by analyzing customer</cell></row><row><cell>e-mails, call center transcripts, discussion forums</cell></row><row><cell>or even answers to open-ended questions in</cell></row><row><cell>opinion surveys.</cell></row><row><cell>*the CRM Skill Cartridge™ is tailor-made for your business</cell></row><row><cell>needs</cell></row><row><cell>➜ A "</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_54"><head>Competitive Intelligence" Skill Cartridge™ to facilitate strategic analysis.</head><label></label><figDesc></figDesc><table><row><cell>extracts all information concerning stock pur-</cell></row><row><cell>chases, mergers, acquisitions, joint ventures,</cell></row><row><cell>research areas and innovations by analyzing</cell></row><row><cell>content from newswires, competitor Web</cell></row><row><cell>sites, analysts' reports, scientific publications or</cell></row><row><cell>patents.</cell></row><row><cell>Text</cell></row><row><cell>Intelligence™</cell></row><row><cell>It retrieves financial information (sales figures,</cell></row><row><cell>profitability, growth), sales information (market</cell></row><row><cell>shares, number of customers), stock market</cell></row><row><cell>information (capitalization, trends). It also</cell></row></table><note><p>➜ An "</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_55"><head>HR" Skill Cartridge™ to help you manage recruitment.</head><label></label><figDesc></figDesc><table><row><cell cols="2">Detect strategic information</cell></row><row><cell cols="2">with Insight Discoverer™ Extractor V 2</cell></row><row><cell>V 2</cell><cell></cell></row><row><cell cols="2">It identifies skills and know-how from applica-</cell></row><row><cell cols="2">tions (covering letters and resumés), and</cell></row><row><cell cols="2">recruitment criteria from job offers.</cell></row><row><cell cols="2">Why choose Insight</cell></row><row><cell cols="2">Discoverer™ Extractor?</cell></row><row><cell cols="2">Insight Discoverer™ Extractor offers an exten-</cell></row><row><cell cols="2">ded range of functions:</cell></row><row><cell cols="2">&lt; Automatic identification of the document</cell></row><row><cell cols="2">language</cell></row><row><cell cols="2">&lt; Multilingual (12 languages available)</cell></row><row><cell cols="2">&lt; Supports 50 formats (MS Word, MS Excel,</cell></row><row><cell cols="2">MS PowerPoint, PDF, HTML, etc.)</cell></row><row><cell cols="2">&lt; Compatible with Pre and Post Processing</cell></row><row><cell cols="2">&lt; API provided for easy integration into your</cell></row><row><cell cols="2">information system</cell></row><row><cell cols="2">Fine-tuning options...</cell></row><row><cell cols="2">Insight Discoverer™ Extractor is able to</cell></row><row><cell cols="2">manage language complexity thanks to the</cell></row><row><cell cols="2">flexibility of the Skill Cartridges™. To optimize</cell></row><row><cell cols="2">extraction and obtain accurate information,</cell></row><row><cell cols="2">Skill Cartridges™ can be fully customized with</cell></row><row><cell cols="2">fine-tuning options such as:</cell></row><row><cell cols="2">&lt; Extraction of negative or positive trends</cell></row><row><cell cols="2">&lt; Differentiation between rumors and actions</cell></row><row><cell cols="2">&lt; Enhancement of anaphora identification</cell></row><row><cell cols="2">&lt; Resolution of acronyms</cell></row><row><cell cols="2">&lt; Integration of ontologies</cell></row><row><cell>Insight Discoverer™ Extractor</cell><cell>V 2</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_56"><head>032006 Smartus Acquisition Cardup SIM selling 75 million euro acquisition Contact Contact For more information: TEMIS France &lt;&lt; Headquarters</head><label></label><figDesc></figDesc><table><row><cell></cell><cell>û SMARTUS :</cell><cell></cell></row><row><cell></cell><cell cols="2">On Thursday, the Franco-German manufacturer</cell></row><row><cell></cell><cell cols="2">announced it was to acquire the Cardup smart</cell></row><row><cell></cell><cell cols="2">card manufacturer from Italian company SIM for</cell></row><row><cell></cell><cell>75 million euro in cash.</cell><cell></cell></row><row><cell>Tour Gamma B 193-197 rue de Bercy</cell><cell>Who (guessed) Announcement</cell><cell>Smartus announced</cell></row><row><cell>75582 Paris Cedex 12</cell><cell>Date</cell><cell>Thursday</cell></row><row><cell>France</cell><cell>Relation</cell><cell>acquisition</cell></row><row><cell>Tel. : +33 (0)1 40 04 46 70</cell><cell>Whom (guessed)</cell><cell>Cardup</cell></row><row><cell>info@temis-group.com</cell><cell>From whom (guessed)</cell><cell>SIM</cell></row><row><cell></cell><cell>Country</cell><cell>Italy</cell></row><row><cell></cell><cell cols="2">Discover the TEMIS product</cell></row><row><cell></cell><cell>range</cell><cell></cell></row><row><cell></cell><cell cols="2">Insight Discoverer™ Extractor uses the XeLDA ®</cell></row><row><cell></cell><cell cols="2">engine's linguistic analysis technology and Skill</cell></row><row><cell></cell><cell cols="2">Cartridges™. Its results can be used by the docu-</cell></row><row><cell></cell><cell cols="2">ment portal solution Online Miner™, the infor-</cell></row><row><cell></cell><cell cols="2">mation organization solution Insight Discoverer™</cell></row><row><cell></cell><cell cols="2">Clusterer and the information classification</cell></row><row><cell>• Lemmatization: returns each word to its</cell><cell cols="2">solution Insight Discoverer™ Categorizer.</cell></row><row><cell>base form (singular for a plural, infinitive</cell><cell></cell><cell></cell></row><row><cell>for a conjugated verb) so that it can be</cell><cell></cell><cell></cell></row><row><cell>recognized independently of its inflected</cell><cell></cell><cell></cell></row><row><cell>form</cell><cell></cell><cell></cell></row><row><cell>&lt;&lt; Knowledge extraction (runs extraction</cell><cell></cell><cell></cell></row><row><cell>rules):</cell><cell></cell><cell></cell></row><row><cell>• Recognition of entities (name of compa-</cell><cell></cell><cell></cell></row><row><cell>nies, associations, organizations, products</cell><cell></cell><cell></cell></row><row><cell>figures, dates, places, etc.)</cell><cell></cell><cell></cell></row><row><cell>• Identification of relationships between</cell><cell></cell><cell></cell></row><row><cell>the entities (company-company, person-</cell><cell></cell><cell></cell></row><row><cell>company, company-product, etc.)</cell><cell></cell><cell></cell></row><row><cell>The knowledge extraction is powered by Skill</cell><cell></cell><cell></cell></row><row><cell>Cartridges™.</cell><cell></cell><cell></cell></row><row><cell>A Skill Cartridge™ is a hierarchy of know-</cell><cell></cell><cell></cell></row><row><cell>ledge components describing the information</cell><cell></cell><cell></cell></row><row><cell>to extract for a given business, specific field or</cell><cell></cell><cell></cell></row><row><cell>topic.</cell><cell></cell><cell></cell></row><row><cell>A knowledge component is a lexicon and/or</cell><cell></cell><cell></cell></row><row><cell>an extraction rule.</cell><cell></cell><cell></cell></row><row><cell>An extraction rule describes a sentence struc-</cell><cell></cell><cell></cell></row><row><cell>ture that characterizes a concept.</cell><cell></cell><cell></cell></row></table><note><p>Copyright © 2006 TEMIS S.A. All rights reserved. Product appearance and/or specifications may be modified without prior notice. IDE.2.0.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_58"><head></head><label></label><figDesc>) a set of contextual rules, which associate lemmas, syntax, and semantics. &lt;actor_in_agribusiness&gt; ;; a seed and flour miller (company_Adj|Loc_Adj|#ORD)* / (NOUN)* / (food_|brand_product) / (actor_|company) ;; maker of private label pasta (company_Adj|Loc_Adj|#ORD)* / (actor_|company) / of / (food_|brand_product Semantic labeling vs. morpho-syntactic labeling A leading manufacturer of branded products in the Mediterranean food sector, today announced that it will acquire Pastificio Gazzola S.p.A., leading manufacturer of private label pasta.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>SEMANTIC LABELLING</cell><cell>MORPHO-SYNTACTIC LABELLING</cell></row><row><cell></cell><cell>A</cell><cell></cell><cell>&lt;AT&gt;</cell><cell>&lt;a&gt;</cell></row><row><cell></cell><cell>leading</cell><cell></cell><cell>&lt;NN&gt;</cell><cell>&lt;leading&gt;</cell><cell>&lt;company_Adj&gt;</cell></row><row><cell></cell><cell>manufacturer</cell><cell></cell><cell>&lt;NN&gt;</cell><cell>&lt;manufacturer&gt;</cell><cell>&lt;company&gt;</cell></row><row><cell></cell><cell>of</cell><cell></cell><cell>&lt;IN&gt;</cell><cell>&lt;of&gt;</cell></row><row><cell></cell><cell>branded</cell><cell></cell><cell>&lt;VBN&gt;</cell><cell>&lt;brand&gt;</cell></row><row><cell></cell><cell>products</cell><cell></cell><cell>&lt;NNS&gt;</cell><cell>&lt;product&gt;</cell><cell>&lt;brand_product&gt;</cell></row><row><cell></cell><cell>in</cell><cell></cell><cell>&lt;IN&gt;</cell><cell>&lt;in&gt;</cell></row><row><cell></cell><cell>the</cell><cell></cell><cell>&lt;AT&gt;</cell><cell>&lt;the&gt;</cell></row><row><cell></cell><cell cols="2">Mediterranean</cell><cell>&lt;JJ&gt;</cell><cell>&lt;Mediterranean&gt;</cell><cell>&lt;loc_Adj&gt;</cell></row><row><cell></cell><cell>food</cell><cell></cell><cell>&lt;NN&gt;</cell><cell>&lt;food&gt;</cell><cell>&lt;food_&gt;</cell></row><row><cell></cell><cell>sector</cell><cell></cell><cell>&lt;NN&gt;</cell><cell>&lt;sector&gt;</cell></row><row><cell></cell><cell>,</cell><cell></cell><cell>&lt;CM&gt;</cell><cell>&lt;,&gt;</cell></row><row><cell></cell><cell>today</cell><cell></cell><cell>&lt;NR&gt;</cell><cell>&lt;today&gt;</cell></row><row><cell></cell><cell>announced</cell><cell></cell><cell>&lt;VBD&gt;</cell><cell>&lt;announce&gt;</cell><cell>&lt;announcement_&gt;</cell></row><row><cell></cell><cell>that</cell><cell></cell><cell>&lt;CS&gt;</cell><cell>&lt;that&gt;</cell></row><row><cell></cell><cell>it</cell><cell></cell><cell>&lt;PPS&gt;</cell><cell>&lt;it&gt;</cell></row><row><cell></cell><cell>will</cell><cell></cell><cell>&lt;MD&gt;</cell><cell>&lt;will&gt;</cell></row><row><cell></cell><cell>acquire</cell><cell></cell><cell>&lt;VB&gt;</cell><cell>&lt;acquire&gt;</cell><cell>&lt;possession_transfer&gt;</cell></row><row><cell></cell><cell>Pastificio</cell><cell></cell><cell>&lt;NP&gt;</cell><cell>&lt;Pastificio&gt;&lt;guessed&gt;</cell></row><row><cell></cell><cell cols="2">Gazzola</cell><cell>&lt;NP&gt;</cell><cell>&lt;Gazzola&gt;&lt;guessed&gt;</cell></row><row><cell></cell><cell cols="2">S.p.A.</cell><cell>&lt;NP&gt;</cell><cell>&lt;S.p.A&gt;&lt;guessed&gt;</cell><cell>&lt;company &gt;</cell></row><row><cell></cell><cell>,</cell><cell></cell><cell>&lt;CM&gt;</cell><cell>&lt;,&gt;</cell></row><row><cell></cell><cell>leading</cell><cell></cell><cell>&lt;NN&gt;</cell><cell>&lt;leading&gt;</cell><cell>&lt;company_Adj&gt;</cell></row><row><cell></cell><cell>manufacturer</cell><cell></cell><cell>&lt;NN&gt;</cell><cell>&lt;manufacturer&gt;</cell><cell>&lt;company&gt;</cell></row><row><cell></cell><cell>of</cell><cell></cell><cell>&lt;IN&gt;</cell><cell>&lt;of&gt;</cell></row><row><cell></cell><cell>private</cell><cell></cell><cell>&lt;JJ&gt;</cell><cell>&lt;private&gt;</cell></row><row><cell></cell><cell cols="2">label</cell><cell>&lt;NN&gt;</cell><cell>&lt;label&gt;</cell><cell>&lt;brand_product&gt;</cell></row><row><cell></cell><cell>pasta</cell><cell></cell><cell>&lt;NN&gt;</cell><cell>&lt;pasta&gt;</cell><cell>&lt;food_&gt;</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Brand dictionary</cell><cell>Action dictionary</cell></row><row><cell></cell><cell cols="4">At the end of the processing, a semantically tagged text, which can be read by other</cell></row><row><cell></cell><cell cols="3">&lt;brandname_&gt; applications, is issued.</cell><cell>&lt;communication_&gt;</cell></row><row><cell></cell><cell>actor_</cell><cell cols="2">&lt;Mineral_water&gt;</cell><cell>&lt;announcement_&gt; leading manufacturer of branded products</cell></row><row><cell></cell><cell cols="2">agribusiness_market</cell><cell></cell><cell>Mediterranean food sector</cell></row><row><cell></cell><cell>food_</cell><cell></cell><cell>Arrowhead</cell><cell>announce Mediterranean food</cell></row><row><cell></cell><cell cols="2">communication_ /information_ /announcement_</cell><cell>Badoit Blue / Quellen</cell><cell>announced</cell><cell>announcement notify</cell></row><row><cell></cell><cell cols="3">Buxton Calistoga when time_/punctual_ what_announcement</cell><cell>notification proclamation company_acquisition today</cell></row><row><cell>Text Intelligence™</cell><cell cols="2">company_acquisition who which_company</cell><cell cols="2">Contrex Vittel (Source)? / Perrier will acquire Pastificio Gazzola S.p.A. promulgation statement talk Pastificio Gazzola S.p.A.</cell></row><row><cell></cell><cell cols="3">actor_in_agribusiness Poland / Spring Quézac food_</cell><cell>... leading manufacturer of private label pasta private label pasta</cell></row><row><cell></cell><cell></cell><cell cols="2">Salvetat</cell></row><row><cell></cell><cell></cell><cell cols="2">....</cell></row></table><note><p>b</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_60"><head>Table 2 :</head><label>2</label><figDesc>Precision, Recall for the assignment of SUBTOP labels for a number of TOP corpora</figDesc><table><row><cell>Text</cell></row><row><cell>Intelligence™</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>• Insight Discoverer Categorizer short</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>• Insight Discoverer Categorizer long.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_2"><p>Inxight SmartDiscovery Extraction Server (SDX)</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_3"><p>So, you need to understand language data? Open-source NLP software can help! | Entopix Cons... http://entopix.com/so-you-need-to-understand-language-data-open-source-nlp-software-can-help/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="16" xml:id="foot_4"><p>Concepts Guide</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_5"><p>XeLDA white paper #</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_6"><p>XeLDA white paper</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_7"><p>&amp; &amp; &amp; &amp; ' &amp; ( $ ) * &amp; ! + #</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_8"><p>6 ) 7 -* . * &amp;</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_9"><p>&amp; &amp; &amp; ' &amp; @ : ? &amp; &amp; &amp; &lt; &amp; &amp; &lt;</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_10"><p>&amp; ' % &amp;&amp;</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_11"><p>The quantitative results reported here have been obtained in an extended evaluation period at the G+J press database. The author would like to thank Günter Peters and Volker Gaese from G+J for making their findings available for this report.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgement</head><p>Grateful appreciation to Xiaoyong Liu who contributed to this entry while she was a Ph.D. student and a Research Assistant in the <rs type="institution">Center for Natural Language Processing in the School of Information Studies at Syracuse University</rs>.</p></div>
			</div>
			<div type="funding">
<div><p>/temis-integrates-ontology-management-and-semantic-enrichment-in-luxid-7/</p></div>
			</div>
			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Availability</head><p>Inxight ThingFinder is available as a software development kit or as an Inxight SmartDiscovery� service.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Text Intelligence™</head><p>Contact us -By e-mail: info@temis-group.com -Or visit our Web site : www.temis-group.com TEMIS France   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Overview of XeLDA Architecture</head><p>This section describes the two modes in which XeLDA can operate, and explains how XeLDA processes requests and returns results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>XeLDA modes</head><p>XeLDA has two main operating modes: client-server or stand-alone, also called "monoprocess".</p><p>The operating modes are transparent to the user and the client application developer.</p><p>In client-server mode, all linguistic processing takes place on a server machine. The client process on the local computer sends requests and retrieves the results through the network.</p><p>There may be many servers on the network. The communication takes place through the usual TCP/IP mechanisms. For example, www.xelda.com and www.xelda.com:40002 are both potentially valid addresses for a XeLDA server.</p><p>Because processing occurs over the network, the server may be as near as the next office or as far as the next continent. It is even possible to have the server and the client on the same machine, although in this case, the stand-alone mode may be more efficient.</p><p>The client-server mode is designed so that a few powerful servers are installed to serve several lightweight clients.</p><p>See Figure <ref type="figure">2</ref> on the following page for a diagram of communication between the client and server when XeLDA operates in client-server mode.</p><p>Use the stand-alone mode when there is only one machine involved and the server and client are merged in a single executable. In stand-alone mode, the network component disappears and all processing is done locally.</p><p>See Figure <ref type="figure">3</ref> on the following page for a diagram of an application operating in stand-alone mode.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Requests and results</head><p>XeLDA functions the same way in either mode. A client application creates a request object describing the linguistic service it needs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>% $ %</head><p>Lexeme: a word or token.</p><p>Module: basic component of XeLDA, such as a service, a Clix component, the kernel, or an application.</p><p>Morphological Analyzer: a linguistic service that provides the normalized form and all potential part of speech categories for each token identified during tokenization.</p><p>Noun Phrase Extraction: a linguistic service that identifies a sequence of words that behaves together as a noun. It is the continuation of a chain of linguistic services including the tokenization service, the morphological analysis service and the part of speech disambiguation service.</p><p>Part of Speech (POS) Disambiguation: a linguistic service that finds the correct grammatical category of a word according to its context.</p><p>Relational Morphology: a linguistic service that returns the representative of the derivational family of a word.</p><p>Reverse Relational Morphology: a linguistic service that returns the representative of a word's derivational family and all the words belonging to this family.</p><p>Senses: the list of base forms and part of speech information for a word.</p><p>Service: the client portion of the communication link between the client and the server. It contains general information about what server to contact and supports descriptions specific to the client environment, such as user name, machine name, operating system, etc.</p><p>Tans: Translation Aid Network Service. This project was originally a technology transfer project and is the base for the XeLDA framework.</p><p>Target Entry: the correct entry for a word in a dictionary. The dictionary lookup service retrieves the target entry depending on the context of a word.</p><p>Tokenization Service: a linguistic service that divides a sequence of input characters into words or tokens. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Search and Access</head><p>• Global Search: Users can select from more than 130 pre-configured content sources to perform searches in real time.</p><p>• Rich Boolean, Proximity and Field-based Operators: The system will automatically translate and transform the universal query provided by the user (using either basic or advanced search) to the form appropriate to each source.</p><p>• Single Sign-On and Authentication: The system leverages existing SSO and authentication schemes to provide secure access to subscription and other password-protected data sources.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Knowledge and Understanding</head><p>• Eliminates Duplicate Results: Deletes duplicate result records from multiple sources.</p><p>• Relevance Ranking: Allows you to quickly see documents from a variety of sources based on their relevance to your information needs.</p><p>• Advanced Sorting and Filtering Options: Results can be sorted and filtered by relevance, date, source, category or other criteria.</p><p>• "More Like This" Searching: Users can highlight an individual result and the system will automatically find other similar results.</p><p>• Source Suggest: Awareness Server will suggest new sources to add to your personal search universe based on your queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Awareness and Alerts</head><p>• Collaborative Results Sharing: Results can be shared with others via email, or formatted for printing and reading offline.</p><p>• Search Alerts: Personalized search alerts keep you aware of the latest developments related to your search queries.</p><p>• Page Alerts: Page alerts can be set to monitor individual pages for changes.</p><p>• Background Searches: Federated searches can be configured to run in the background. The system will notify the user with the results when they are ready.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Technical Specifications</head><p>• Open interfaces (APIs), including XML, SOAP and Web Services, allow for easy integration with existing or new enterprise applications.</p><p>• Provides search results from Microsoft Office documents, PDFs, XML, HTML and text.</p><p>• Works with standards-based and proprietary security mechanisms for access and authentication.</p><p>• The product is scalable to support large numbers of users, delivering results to users' requests in seconds.</p><p>• Enables a wide range of sources and options to be customized rapidly to meet the needs of the organization, individual departments or even individual users.</p><p>Operating Systems </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Application Servers</head><p>• Apache Tomcat 5.0 or 5.5</p><p>• BEA WebLogic 9.1</p><p>• IBM WebSphere 6.0</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Database Servers</head><p>• Oracle 9i</p><p>Java Platforms</p><p>• Java 2 Standard Edition 1.4.2 and Java Standard Edition 5.0</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Browsers</head><p>• Microsoft Internet Explorer 5.5 and 6.0</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Going Beyond Google with Inxight SmartDiscovery®</head><p>Google.com puts the Web's information at your fingertips. It's one of the world's best search indexers. The Google Search Appliance does the same thing for your Website or corporate intranet.</p><p>However, the challenge is what to do with all of this information. The key to "organizing the world's information to make it universally accessible and useful" is not only to index the world's information, but to be able to electronically "read" that information and structure it -pulling out key entities (people, places, companies…), concepts, relations, and events trapped in unstructured text -and then be able to visualize that information in meaningful ways.</p><p>Inxight picks up where Google and other search indexers leave off.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Inxight SmartDiscovery Awareness Server</head><p>Inxight SmartDiscovery Awareness Server is a powerful federated search, clustering and alert solution that makes discovering information easier than ever before.</p><p>Using SmartDiscovery Awareness Server, you can:</p><p>• Search multiple Google Search Appliances that are geographically or departmentally dispersed within your company with only one query. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discover the TEMIS product range</head><p>For optimum categorization quality, you must first ensure that the classification model is relevant. In some cases, automatic document assignment reveals inappropriate categories and unbalanced distribution. TEMIS' Insight Discoverer™ Clusterer classification suggestion tool provides an excellent solution to this problem.</p><p>Insight Discoverer™ Categorizer uses linguistic analysis performed by Insight Discoverer™ Extractor, which describes documents by generating their semantic profile. Insight Discoverer™ Categorizer then uses this for the learning and assignment phases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Specifications</head><p>&lt;&lt; Operating systems:</p><p>-Windows NT, 2000, XP workstation or server versions.</p><p>-Linux.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt;&lt; API :</head><p>-Java (RMI -Remote Method Invocation).</p><p>-Documentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt;&lt; Source languages (supported by Insight Discoverer™ Extractor):</head><p>English, French, German, Italian, Dutch, Spanish, Portuguese, Czech, Greek, Hungarian, Polish, Russian.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt;&lt; Formats :</head><p>Over 50 input formats (including MS Word, PDF and HTML). The document information is generated in XML.</p><p>Copyright </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TEMIS France</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt;&lt; Grenoble</head><p>Tel. : +33 (0)4 76 61 51 83 Fax : +33 (0)4 76 61 41 21 info@temis-group.com</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TEMIS Germany</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt;&lt; Heidelberg</head><p>Tel. : +49 -6221 13753-12 Fax : +49 -6221 13753-14 info.de@temis-group.com</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TEMIS Italy</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt;&lt; Modena</head><p>Tel. : +39 -059 237 634 Fax : +39 -059 220 093 info.it@temis-group.com</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TEMIS United Kingdom</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt;&lt; Bristol</head><p>Tel. : + 44 (0)117 949 8646 info.uk@temis-group.com www.temis-group.com</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Text Intelligence™</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>DocCat is a project that uses Insight Discoverer™ technologies (ID Extractor and ID Categorizer), which is a system for the automatic categorization, indexing, and archival of textual data for large commercial text archives. DocCat was one of the first systems for automatic indexing that was put in production in a real-world environment and demonstrates the usefulness of this approach through its use on many hundreds of new documents every day. Moreover DocCat is an ongoing project and the properties of the system are subject to continuous refinement and adaptation to specific requirements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Description</head><p>The term automatic indexing here refers to the process of assigning terms to a document that correspond to its content, and not to the process of setting up an index for full text retrieval. While the latter typically contains virtually all the words of a document, with their lemmatised forms and without the stop words, the former means annotating a document with only a few terms from a thesaurus or some other kind of controlled set of index terms. DocCat assigns index terms (here, "topics") to each document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">The making of DocCat</head><p>In the summer of 1998, a team at the IBM Institute for Logic and Linguistics in Heidelberg, Germany, was engaged in studying the automatic indexing of speech data, i.e. the annotation of audio data with phrases and keywords that allow a text-based search in a sound archive. It became apparent that a large proportion of the functionality of such a system might be of interest for the handling of textual data, too. After all, a textual representation (possibly infected with errors from the speech recognition component) was to be the input for the indexing component. Consequently, our work aroused interest not only in places where large audio archives had to be managed, but also in the text archive field, especially at the Gruner+Jahr (G+J) press database in Hamburg, where a number of projects involving automatic indexing had already been considered.</p><p>In the first pilot project we were asked to demonstrate the practicability of our approach in a limited scenario with German documents. When the results of this pilot study turned out to be encouraging, a continued cooperation was agreed upon where DocCat was to be extended towards a system that could be applied to everyday tasks in a commercial text archive.</p><p>The idea in both the pilot study and the second phase was that the G&amp;J archive should form a training corpus of manually annotated documents that would enable specific machine learning algorithms to collect correlations between a document's textual data and the presence or absence of a specific label. The following were the various treated labels:</p><p>Broad topic: The manual annotations assign up to four labels to a document, indicating the broad topic of the document (Examples: Sports, Theatre, Economics, Science, ...). A total of 44 such topics had to be learned. Specific topics: A finer classification of a document's topics is achieved by assigning one or more of a fixed vocabulary of some 2000 thesaurus terms to it (Examples: Doping, Trade Unions, Market Research, ...). Keywords: While a document need not literally contain a thesaurus term in order to receive this term as a label, some terms that are not part of the fixed vocabulary (i.e. the thesaurus) may also serve as an indication of the document's contents. These</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INSIGHT DISCOVERER™ CATEGORIZER white paper</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Text Intelligence™</head><p>keywords were extracted from and assigned to a document alongside the thesaurus terms.</p><p>Person Names: Since the information about what individuals are mentioned together with which topics or events are of specific interest for documentation purposes. Person names have to be identified and, as far as possible, rated according to their importance in the text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Names of Companies &amp; Organizations:</head><p>The same holds for the names of other entities such as companies or organizations. Geographical labels: Finally, each document receives a label indicating the geographic region (continent, country, province, etc.) that can be used to locate the document's contents.</p><p>The question which DocCat had to answer was: Is it possible to set up an automatic procedure which assigns such labels to new, unseen documents in a way that the quality is comparable or even superior to that of the manual annotation, or which can at least be used as a starting point for manual post processing, thus making the manual annotation more effective?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">The Insight Discoverer™ components within DocCat</head><p>A fundamental requirement in setting up the DocCat system was that the amount of effort that had to be invested in building corpus-or domain-specific knowledge bases such as dictionaries, grammars or thesauri should be kept as low as possible. This not only reduces the workload necessary for the development of the system, but, at the same time, ensures that new classifiers for new corpora, domains or documentation requirements could be built (i.e. "trained") with minimal effort. If no new types of labels need to be considered, building a new classifier will require only a training corpus of annotated documents as input.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Classification tasks: Insight Discoverer™ Categorizer</head><p>The tasks of assigning the labels for broad, specific, and geographical topics are treated as classical text classification tasks. In the learning phase, more than 100,000 terms, the "features" of the classification task, and their occurrence together with the respective classes, are collected. In the case of the specific topic learning phase, this process requires the handling of a matrix with several hundreds of millions of cells. The large number of features considered in DocCat is a consequence of the ability of the German language to build a virtually infinite number of compound nouns.</p><p>The information about the number of occurrences of a term within a class makes it possible to calculate a relevance measure for this term/class pair. Table <ref type="table">1</ref> shows an excerpt from the ranked list of features for the thesaurus category "Bergsteigen" (mountain climbing).</p><p>Setting a sensible threshold in order to cut this list off avoids having to keep irrelevant information about the correlation of a specific class and a feature which is not significant for this class. The resulting classifier then makes the assumption of independence of the occurrence of the various features in a document and ranks the respective classes according to a confidence value. See section Results for a table of results on the broad topic classification task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Text Intelligence™</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Relevance</head><p>Since the classification process gives quantitative results, the behavior of the system can be influenced by tuning a variety of parameters concerning ranking, threshold level, total number of resulting codes, etc. As with most classification problems, there is a trade off between ID Categorizer's recall (the proportion of correct codes that the system has assigned) and its precision (the proportion of assigned codes that are correct). In such a situation, tuning the parameters allows a user to emphasize one over the other, by maximizing recall at the expense of precision, vice versa, or finding a good compromise between the two. This compromise, however, has been found to be suitable for the implementation of a workflow that processes documents automatically (i.e. without manual post-editing) in a professional documentation environment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Keywords</head><p>Often, newly coined terms acquire high relevance for a certain topic long before the thesaurus is updated in order to reflect this development. The more dynamic a domain, the harder it is to maintain an appropriate controlled vocabulary. Thus many potentially relevant and useful indexing terms would be lost if a document only received labels from the predefined set of thesaurus terms.</p><p>DocCat reflects this by annotating a document with a selection of the highest ranking terms from the text as keywords. These keywords not only turn out to be, in many cases, good extensions to the thesaurus-based annotation, but they may also be considered as a rudimentary kind of summary (or a starting point for the generation of such a summary) that facilitates the browsing of larger document collections, e.g. search results. DocCat is able to lemmatize the identified keywords (i.e. reduce them to their non-inflected form) by drawing upon a large underlying dictionary and a morphological rule set for the processing of compound nouns (Insight Discoverer™ Extractor). Insight Discoverer™ Clusterer structures information so the content can be used. It offers excellent visibility for large sets of documents and complex issues. It thus enables considerable productivity gains in knowledge management and especially facilitates decisionmaking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Text Intelligence™</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Insight Discoverer™ Clusterer</head><p>There are many advantages to using this solution:</p><p>&lt; Rapid viewing of information &lt; Ease of processing of large volumes of documents for wide-ranging searches &lt; Easy to browse through information spheres &lt; Increased productivity through grouping of similar information &lt; Easier to appropriate information</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>How Insight Discoverer™ Clusterer works</head><p>Insight Discoverer™ Clusterer uses an innovative classification process based on a combina- </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discover the TEMIS product range</head><p>Insight Discoverer™ Clusterer uses the morpho-syntactic analysis performed by Insight Discoverer™ Extractor. Insight Discoverer™ Extractor describes the documents upstream by generating their semantic profile. This profile is then used by Insight Discoverer™ Clusterer to propose classification schemes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Specifications</head><p>&lt;&lt; Operating systems:</p><p>-Windows NT, 2000, XP workstation or server versions.</p><p>-Linux.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt;&lt; API :</head><p>-Java (RMI -Remote Method Invocation).</p><p>-Documentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt;&lt; Source languages (supported by Insight Discoverer™ Extractor):</head><p>English, French, German, Italian, Dutch, Spanish, Portuguese, Czech, Greek, Hungarian, Polish, Russian.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt;&lt; Formats :</head><p>over 50 input formats (including MS Word, PDF and HTML).</p><p>Copyright © 2004 TEMIS Holding. All rights reserved. Product appearance and/or specifications may be modified without prior notice. IDC.2.0.092004</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Contact Contact</head><p>For more information: </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Case</forename><surname>Uninstantiated</surname></persName>
		</author>
		<author>
			<persName><surname>Frame</surname></persName>
		</author>
		<idno>OBJECT: [VALUE: _______ ] [POSITION: DO]</idno>
		<imprint/>
	</monogr>
	<note>SEM-FILLER: &lt;file&gt; | &lt;directory&gt;</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">CA 94085 Phone: 408.738.6299 | Fax: 408.738.6311 www.inxight.com | sales@inxight.com Inxight Federal Systems 11951 Freedom Drive, Suite 1300</title>
		<editor>U.S. | 500 Macara Avenue</editor>
		<imprint>
			<date>20190</date>
			<pubPlace>Sunnyvale; Reston, VA</pubPlace>
		</imprint>
	</monogr>
	<note>Phone: 703.251.4429 | Fax: 703.251.4440 www.inxightfedsys.com | sales@inxightfedsys.com</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
