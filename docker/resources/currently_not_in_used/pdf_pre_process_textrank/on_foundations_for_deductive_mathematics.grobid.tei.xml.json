{
  "id": 8136618339670071055,
  "name": "on_foundations_for_deductive_mathematics.grobid.tei.xml",
  "segments": [
    {
      "header": "abstract",
      "content": "this article was motivated by the discovery of a potential new foundation for mainstream mathematics.\nthe goals are to clarify the relationships between primitives, foundations, and deductive practice; to understand how to determine what is, or isn't, a foundation; and get clues as to how a foundation can be optimized for effective human use.\nfor this we turn to history and professional practice of the subject.\nthe next briefly describes foundations, explicit and implicit, at a few key periods in mathematical history.\nwe see, for example, that at the primitive level human intuitions are essential, but can be problematic.\nwe also see that traditional axiomatic set theories, zermillo-fraenkel-choice (zfc) in particular, are not quite consistent with mainstream practice.\nthe final section sketches the proposed new foundation and gives the basic argument that it is uniquely qualified to be considered the foundation of mainstream deductive mathematics.\nthe \"coherent limit axiom\" characterizes the new theory among zfc-like theories.\nthis axiom plays a role in recursion, but is implicitly assumed in mainstream work so does not provide new leverage there.\nin principle it should settle set-theory questions such as the continuum hypothesis."
    },
    {
      "header": "Abstractions",
      "content": "foundations are a way to analyze the body of practice, particularly its consistency.(1) a primitive is an object, hypotheses, or method of argument that is postulated rather than deduced from something else.\n(3) a foundation is consistent if every chain of deductions that produces a contradiction can be shown to have a logical error.2.1.\nthe operational view of consistency is \"complete reliability\", in the sense that the outcome of an error-free argument will never be contradicted by the outcome of any other such argument.\nsuccess is sensitively dependent on everything else used in the argument being completely reliable, and that the logic itself does not introduce errors.consistency provides an internal criterion for correctness.\nanother wrinkle is that a foundation can be technically inconsistent but consistent in practice in the sense that methodology has evolved so as to steer people away from the inconsistencies.\nwe clarify usage in the mathematical community.definitions are located inside a developed context, and usually consist of axioms that the things being defined should satisfy.\npolygons are 'defined' because they are described in terms of primitives.we emphasize that consistency at the primitive level depends heavily on different users extracting functionally equivalent understandings.\nthe new approach to set theory has a similar advantage: the primitives (object generators) are several levels below sets, so sets are defined and their properties proved rather than hypothesized."
    },
    {
      "header": "Sketchy history",
      "content": "this was addressed by defining natural numbers using early versions of set theory.\nby 1900 quite a few mathematicians had found na\u00efve set theory to be effective and reliable, and many leading mathematicians were satisfied that all mainstream work could be derived from it.\nafter a few more unsuccessful attempts they gave up trying to define sets directly, and instead began abstracting key properties (of na\u00efve set theory) to use as axioms.in the next phase of the development, the notion of \"function\" seemed problematic.\nthe standard forms of the axioms up to this point are mainly due to zermillo.a problem with the zermillo axioms is that they do not ensure there are enough functions to transact the basic business of set theory.\nexperimentation, drawing on a strong legacy of formal logic, revealed that functions obtained from set operations by first-order logic are sufficient to give workable rigorous set theories.\nna\u00efve set theory-as used in standard practice-enabled highly rigorous arguments of a depth unimaginable in the previous century.\nthe consistency of na\u00efve set theory-again, as used in standard practice-is extremely well tested.\nthere are some drawbacks, but there is no reason to accept any loss of functionality to address these drawbacks.one drawback is that category theory does not fit comfortably in standard set theories."
    },
    {
      "header": "Object generators",
      "content": "note that few requirements means few opportunities for contradiction.\"morphisms\" of generators are essentially the same as \"functions\" in na\u00efve set theory: a morphism f : g \u2192 h is an assignment of an object f [x] \u2208\u2208 h to every object x \u2208\u2208 g.\nthe native logic of object generators is non-binary in the sense that we might assert that x, y are the same, but in general there is no (yes, no)-valued function that can detect this.\nthis logic is unfamiliar and somewhat complicated, and the first step toward set theory is to establish a sub-context that does use binary logic.the key ingredients are binary functions: functions to an object generator with exactly two objects.\nif a is a logical domain then the object generator whose objects are binary functions on a is called the \"powerset\" of a, and is denoted by p[a].\nthe point is that if this one quantification expression is implemented by a binary function, then all quantifications over a are.finally, sets (relaxed sets, if distinctions are necessary) are defined to be logical domains that support quantification.hypotheses.\nfirst, the \"=\" operator built into the logic of na\u00efve and zfc allows comparison of any two elements of any two sets.in relaxed set theory \"=\" is only defined for elements of a single set.\nfunctions are primitives in relaxed and na\u00efve set theory; are described in the same way; and both are consistent with standard practice.\nwe note that identifying the 'missing axiom' (g\u00f6del's phrase) does not lead to new mainstream methodology, but rather emphasizes the extra work that would be required to stay in a smaller zfc model.the conclusion is that the relaxed set theory defined in] is uniquely qualified to be a foundation consistent with mainstream mathematical practice."
    }
  ]
}
