{
  "id": 4020777578102440801,
  "name": "risk_analysis_of_passive_portfolios.grobid.tei.xml",
  "segments": [
    {
      "header": "Introduction",
      "content": "in recent years, we observed several undesirable events, such as the covid19 pandemic, the russian invasion of ukraine, severe global supply chain system disruption, and tremendous pressure on energy prices, followed by global inflation. these macro events bring a high degree of uncertainty to the worldwide market. nowadays, even pension fund portfolios invest in the volatile equity market. the high degree of volatility can impact the portfolio negatively. therefore it is essential to analyse the risk exposure that a portfolio face.passive investment is an excellent option if the investment horizon is long and one is not an expert in quantitative finance. the widespread adoption of the passive investment philosophy comes from the efficient market hypothesis (emh). one cannot outperform the market by actively managing their portfolio for a long time if it is efficient. one can invest in exchange-traded funds (etf) with a long-term perspective and expects the etf to grow as the economy grows over time. in india, we can invest in netf (see,), which suppose to mimic the nifty50 return. however, the weights of the nifty 50 index are not necessarily optimal for the investors, as they are based on market capitalisation.in this work, we showed that the indian market is not efficient. it raises the question of how it affects the risk profile of the passive investment portfolio, particularly how it reacts to idiosyncratic events like the russian invasion of ukraine. we study the effect of russian invasion on the risk profile of the portfolios.rest of the chapter is organised as follows. in section (2) we present basics of financial return and volatility risk. in section (3) we present the efficient market hypothesis and empirical evidence that shows indian market is not efficient. in section (4) we present different aspects of portfolio risk analysis. in section (6), we present the empirical evidence that equal weight portfolio would have uniformly better risk profile than nifty50 etfs. sectionconcludes the chapter."
    },
    {
      "header": "On Basics of Financial Return and Volatility Risk",
      "content": "if given a choice between receiving |100 today or after a year, we should choose to receive |100 today. because if a bank (say state bank of india) agrees to pay us |7 for keeping the |100 with them, then at the end of the period, our investment will be |107. this |7 is the time value of |100 that we are going to keep with the bank. economists term this as time preference, also known as the 'time value of money.the mathematical operation of evaluating the 'present value' (pv) of an amount into the 'future value' (fv) is called a capitalization. for example, how much will our |100 today be worth in 10 years? the reverse operation of evaluating the present value of a future amount of money is called the discounting. for example, how much will |100 received in 10 years, be worth today?the goal of our any investment is to grow over time. the growth depends on both change in price and a number of the assets being invested. certainly, our would be interested in revenues that are high compared to the initial investment. returns articulate the change in price as a fraction of the initial price. suppose p t is the price of an asset at time t. the net return over the holding period of time t -1 to t is r t = p t -p t-1 p t-1 = p t p t-1 -1.the numerator, p t -p t-1 is the net profit (or net loss) during the holding period, where denominator p t-1 is the initial investment at the start of the holding period. we can see the net returns as the rate of profit (or loss) or relative revenue on initial investment. the revenue from holding an asset is p t -p t-1 = r t \u00d7 p t-1 , revenue = net return \u00d7 initial investment.example 2.1. an initial investment of |1000 and a net return of 4% over one year earn revenue of |40, which means the value of the investment after one year is |1040.the single period gross return is defined asexample 2.2. if p t-1 =|1000 and p t =|1040 then the gross return is 1 + r t = 1.04 or 104% and the net return is r t = 0.04 or 4%.the k-period gross return is the product of the k single period, gross returns from time tk to time t:example 2.3. suppose in three consecutive periods (from t to t + 3) the values of an asset are p t =|1000, p t+1 = |1040, p t+2 =|1035, and p t+3 =|1050.we see returns are independent of scale. it does not depend on the unit like rupees, dollar or pounds. however, it depends on the unit of time (like the hour, day, and year).the log returns are defined aswhere p t = log(p t ) is also known as log-price or log-value of the asset. the log-returns are also known as continuously compounded returns. one advantage of the log returns is that a k period log return is sum of single period log returns. that iswe can show, if x is small, then log(1 + x) \u2248 x, it means the log returns are approximately equal to net returns. empirical studies show that the condition log(1 + x) \u2248 x is true when |x| < 0.1 , i.e., returns that are less than 10%. compounding if we have an initial investment of p t that earns annual rate r, compounded m times a year for n years then it has a future valueif compounding times increases, then the future value will also rise. in case of continuous compounding we haveif n = 1 then continuous compounding is p t+1 = p t e r , which we can present as r = log p t+1 p t the log return. hence that the log return of an asset is known as continuously compounded rate of return.volatility tells us, on average, how much value of an asset can go down or go up. the standard deviation calculated from the daily log returns are known as the volatility at daily levels, i.e., \u03c3 = var(r t ).suppose r t , r t-1 , \u2022 \u2022 \u2022 , r t-k+1 are k single period log-return of an asset, wherethat is the covariance matrix isthe k-period return can be presented in matrix notation aswhere c t = (1, 1, ..., 1) k is an unit vector of order k and r = {r t , r t-1 , ..., r t-k+1 }. the mean and variance of the k-period return aretherefore k-period volatility is \u221a k\u03c3."
    },
    {
      "header": "Efficient Market Hypothesis",
      "content": "economists and market analysts agree that if an arbitrage opportunity exists, everybody would like to follow that strategy which would thus disturb the equilibrium. so going forward, a blanket assumption that arbitrage opportunities do not exist is being imposed. to check out more about no-arbitrage opportunity in the market, see.let f t = \u03c3{p j : 0 \u2264 j \u2264 t} is a \u03c3-field generated by {p 0 , . . . , p t }, where p t is the price at time point t. the condition of market equilibrium can be stated in terms of conditional expected returns on the basis of f t , whereis the excess of market value at time t + 1. it is the difference between the observed and the expected price that was projected at time t on the basis of the information set f t . thenwhich, by definition, says that the sequence {x t } is a \"fair game\" with respect to the information sequence f t . equivalently, letthen, e(z t+1 |f t ) = 0 so that the sequence {z t } is also \"fair game\", with respect to information sequence {f t }. letwhere \u03c9 j (f t ) is the amount of funds available at time t that are to be invested in the j th security, j = 1, 2 . . . , p. the total excess market value at t + 1 iswhich has value e(v t+1 |f t ) = 0, so that the sequence {z t } is also \"fair game\", with respect to information sequence {f t }. note one thing here,can be expressed asif we assume in (3.1), that for all t and f t ,that means the price sequence {p t } for security follows a submartingale with respect to the information sequence f t . if (3.2) holds an equality (that is expected return and price changes are zero), then price sequence follows a martingale.in the efficient market model, the statement that current price of a security \"fully reflects\" available data is assumed to imply that successive price changes are independent. also, it is usually considered continuous changes or returns are independent and identically distributed. together the two hypothesis constitute the random walk model.we can make a common working assumption as the returns are mutually independent and identically distributed (i.i.d) random variables with mean \u00b5 and variance \u03c3 2 . we see, for the log return, 1 + r t = exp(r t ) \u2265 0, which implies r t \u2265 -1. this satisfies the condition of limited liability, i.e., possible maximum loss is the total investment. in addition,= exp(r t ) exp(r t-1 ) . . . exp(r t-k+1 ), = exp(r t + r t-1 + . . . + r t-k+1 ).so to sum of k period log-returns yield k-period gross return. now note thatcan be expressed as for k = t, p t = p 0 exp(r t + . . . + r 1 ).suppose r 1 , r 2 , ...r t be i.i.d with mean \u00b5 and standard deviation \u03c3 . let p 0 be an arbitrary starting point andthe process p 0 , p 1 , p 2 , . . . is random walk and r 1 , r 2 , . . . are corresponding steps of that random walk. the conditional expectation and variance of p t given p 0 is e(p t |p 0 ) = p 0 +\u00b5t and var(p t |p 0 ) = \u03c3 2 t . the parameter \u00b5 is the drift and set an overall trend of the random walk. the parameter \u03c3 is the volatility and controls how much it fluctuates around p 0 + \u00b5t. since the standard deviation of p t given p 0 is \u03c3 \u221a t , as t increases the range of variability in the process increases. this means at the t = 0 we know very little about where the random walk will be in the remote future compared to its current spot value. therefore, if the log returns are assumed to be i.i.d. random variables, then the price of the stock or market index, denoted by the process p = {p t : t \u2265 0}, is the exponential of random walk or also known as the geometric random walk.if the price of a stock follows the geometric random walk, then we can write the log-return aswhere p t = log(p t ) and r t follows the same distribution with drift parameter \u00b5 and volatility parameter \u03c3 2 . the random walk is said to have unit root. to understand what this means, we should consider the ar(1) model (i.e., auto-regressive model with lag 1),where \u03d5 = 1. the generic ar(1) model can be presented as\u2022 if \u03d5 = 1 then the process is non-stationary. because k-1 i=0 \u03d5 i-1 r t-(i-1) accumulates the information over time. hence a random walk is a non-stationary process.\u2022 however |\u03d5| < 1, i.e., -1 < \u03d5 < 1 implies, the process is stationary.\u2022 if \u03d5 = 0 that means the process is stationary and p t and p t-1 are independent \u2200t.we may ask here what a stationary process is? how does it look? how it looks different from the non-stationary process?as the series {p t : t \u2265 0} is a random walk (i.e., \u03d5 = 1) the incremental steps (i.e., log-returns) are independent and stationary process, we can write it aswhere \u03d5 1 = 0 and \u03f5 t is white noise with mean \u00b5 and variance \u03c3 2 .in order to check if the price of a stock follows the geometric random walk, we have to check following three things.1. first, we should check if {p t } is a non-stationary process, i.e.,2. second, we check if the log-returns are stationary process, i.e.,3. second check only tells we if a log-returns are stationary, but it does not check if \u03d5 1 = 0 or not. in addition \u03d5 1 = 0 only implies pairwise independence. it does not check the mutual independence of r t . so we should check if the serial correlations of r t are 0 or not. that is check if \u03c1 1 = \u03c1 2 = . . . = \u03c1 h = 0, where \u03c1 h = corr(r t , r t+h ) is the lag h auto-correlation.a test involving much more narrowly-specified null and alternative hypotheses was proposed by. the test compares the null hypothesis, that the series is a random walk without drift, where r t is a white noise with mean 0 and variance \u03c3 2 . the alternative hypothesis iswhere \u00b5 and \u03d5 are constant with |\u03d5| < 1. according to h 1 , the process is stationary ar(1) with mean \u00b5 1-\u03d5 . we implement the dickey fuller test using adf.test function in tseries package. note that first we have to check if the log prices are a random walk. then we have to check if the log-returns are also a random-walk or if the log-return follows the stationary distribution. in these two cases, we can use dickey-fuller test. then on the third step, we check if consecutive log-returns are independent or not!we can check the independence of log-return between the consecutive days via ljung-box test (see,) for autocorrelation. suppose the correlation between r t and r t+h is denoted as \u03c1 h = corr(r t , r t+h ) and known as lag h auto-correlation. the null hypothesis is \u03c1 h = 0 for. that is,vs.h 1 : at least one inequality.the test statistic for the ljung-box test iswhere n is the sample size, \u03c1h is the sample autocorrelation of lag h. we can show under h 0 , q follows a chi-square distribution, \u03c7 2 (h) . the ljung-box test can be done in r using box.test function available in stats package.market analysts always want to know if the market is efficient? here we see; how we can check and test if the market is efficient. since emh is a \"hypothesis\"; therefore we can run a statistical test to check whether emh is true! we can consider the market index as proxy or representative of the market as a whole and check if the market index is following a random walk. if it follows a random walk, then it is good enough to claim that market is efficient.we consider the adjusted close value of nifty50 market index of national stock exchange. we can download data using the r-package the quantmod. we consider the adjusted close value, and compute the log return of the nifty. we try to answer the following questions to check if the indian market is efficient.1. are the values of nifty50 non-stationary?2. are the log-returns of nifty50 non-stationary?3. are the log-returns uncorrelated?4. do the log-returns follow gaussian distribution?step inference: we reject null hypothesis as p-value is significantly small. that is log-returns of nifty 50 are correlated.step 4: check if the log-returns are normal with shapiro-wilk test for normality, (see).## shapiro-wilk test for normality ## null hypothesis: log-return follows normal distribution ## alternative hypothesis : log-return does not ## follow a normal distribution > shapiro.test(as.vector(log_return)) data: as.vector(log_return) w = 0.89425, p-value < 2.2e-16inference: we reject null hypothesis as p-value is significantly small. that is log-return of nifty 50 does not follow gaussian distribution.we draw histogram and qqplot of log-return and presented in figure (2).## draw histogram of log-return of the ftse hist(log_return,main=\"\",col=\"blue\",nclass = 20,probability = true) qqnorm,ylim=c(-4,4) ,cex=0.3) abline(a=0,b=1,col=\"blue\") grid(col=\"red\")in conclusion, the indian stock market is not efficient, as the market returns are correlated and do not follow the gaussian distribution. however, the log returns are stationary.as an investor, we would like to assess if the price of a stock is less than its expected level. if we see the stock is already overpriced, then the chance that it will appreciate further will be less, and we would like to sell the stock. other investors would also like to sell the stock as we have the same information. the stock will fall back to its expected level. on the contrary, if the stock is underpriced, many investors would like to buy it with the assumption that the price will rise to its expected level. in finance, this is known as 'asset pricing,' and corresponding mathematical models are known as 'capital asset pricing models' (capm). it explains the expected risk and returns for a single asset or portfolio. we can estimate the risk premium of assets using the capm.suppose rp tj = (r tjr f ) is excess return over the r f (i.e., risk free rate) for the j th stocks on the t th day. the rp j is also known as risk premium of the j th stock. we consider the model as follows:where r = ((rp tj )) n\u00d7p is the matrix of risk-premium for p many assets that are available in the market over n days; x\u03b2 is the systematic return due to market index, whereis the design matrix with the first column being the unit vector or the place holder for intercept and the second column being the risk-premium for the market index over the risk free rate r f ;if the market is efficient then according to (see,,), then \u03b1 i = 0 \u2200i = 1, 2, \u2022 \u2022 \u2022 , p and \u03b2 i is the measure of systematic risk due to market movement; \u03b5 = ((\u03b5 tj )) n\u00d7p is the idiosyncratic return of the asset. in general one can consider a k-factor model with x being n \u00d7 (k + 1) dimensional, where the first column of x is constant and other columns are all suitable factors. the coefficients \u03b2 is (k + 1) \u00d7 p dimensional and we shall denote it asremark 3.1., for the k factor model, if a portfolio is constructed based on p many assets all of which have \u03b1 = 0, \u03b2 = 1 and b, then the portfolio return will mimic the market return.the covariance of r t is \u03c3 which can be decomposed intowhereand \u03c3 x is the covariance matrix of x. in the next section we develop portfolio optimisation using the capm strategy."
    },
    {
      "header": "Portfolio Risk Analysis",
      "content": "let us consider a portfolio \u03c9 = {\u03c9 1 , \u03c9 2 , \u2022 \u2022 \u2022 , \u03c9 p } where \u03c9 i \u2265 0, i = 1, \u2022 \u2022 \u2022 , p , p i=1 \u03c9 i = 1. markowitz's portfolio optimization (see,) can be expressed as the following quadratic programming problem:min \u03c9 \u03c9 t \u03c3\u03c9, subject to \u03c9 t 1 p = 1 and \u03c9 t \u00b5 = \u00b5 k .(4.1)here , 1 p is a p -dimensional vector with one in every entry and \u00b5 k is the desired level of return.the portfolio covariance can be decomposed into two parts as,where first part explains the portfolio volatility due to market volatility and the second part explains portfolio volatility due to idiosyncratic behaviour of the stock. we assume \u03c3 2 i 's are bounded \u2200i.result 4.1. under the capm model (3.3), covariance matrix (3.4) and assumption (4.1), if p -\u2192 \u221e, and m \u03c9:p = max{\u03c9} -\u2192 0 and \u03c3 2 max = max{\u03c3 \u03b5 } < \u221e, then limproof. we consider,clearly, if p -\u2192 \u221e and m \u03c9:p -\u2192 0 =\u21d2 \u03c9 t \u03c3 \u03f5 \u03c9 -\u2192 0.remark 4.1. the result (4.1) is based on real analysis and not probabilitic result. a detailed discussion about the result (4.1) can be found in.result 4.2. if p is fixed, then m \u03c9:p \u2265 1 p . if we want to minimise m \u03c9:p , then the we must have equal weights portfolio, i.e., m \u03c9:p =remark 4.2. the idiosyncratic risk of the portfolio will be washed out, as the portfolio's size increases and the portfolio's maximum weight is bounded. the portfolio's performance will be a function of the systematic risk explained by the market indices.remark 4.3. the above result mathematically demonstrates the proverb, \"one should not put all eggs in one basket.\"remark 4.4. thus we can select p (\u226a p ) many assets for the portfolio (out of p many assets available in the market) such that the idiosyncratic risk becomes negligible, i.e., \u2200\u03b4 > 0, \u2203 p\u03b4 such that for p > p\u03b4 , \u03c9 t p \u03c3 p \u03c9 p < \u03b4;and portfolio return is mostly explained by \u03b8 only. note that here p is the effective size of the portfolio.remark 4.5. oracle set: suppose the market is not efficient and there are q many assets whose \u03b1 > 0, where q < p \u226a p. let us call this set as a q . we can construct a portfolio with p many assets, such thatwhere b p is the set of assets in the portfolio, 0 \u2264 \u03b7 \u2264 1 and \u03c9 t p \u03c3 p \u03c9 p < \u03b4.example 4.1. suppose the market consists of p = 2000 stocks and a portfolio manager wants to build the portfolio with p = 100 stocks. if q = 5 many stocks are available with \u03b1 j > 0, j = 1, 2, 3, 4, 5, then the portfolio manager would like to build a portfolio, such that a q=5 is the subset of manager's selected portfolio b p =100 . in other words, the manager wants to build her portfolio in such a way that she does not want to miss out the set of five under-valued stocks a q=5 . that is, she wants to employ a statistical methodology, where p(a q=5 \u2282 b p =100 ) would be very high. note that if the market is efficient, then a q will be a null set.the problem reduces to identifying the oracle set a q . essentially, it is a multiple testing problem, where we select those stocks in the portfolio b p for which we reject the following null hypothesis:where \u03b8 0 = (0, 1, 0, \u2022 \u2022 \u2022 , 0).presented optimal test such that equation (4.2) is satisfied.it is important to estimate the volatility and determine the primary sources of volatility. often the number of assets of well-diversified mutual funds or pension funds is more than thousands. however, portfolio managers are concerned about the stationarity in long time-series data. they are interested only in recent volatility, which considers daily returns of a month and sometimes even less. as the number of assets (p )in a portfolio is greater than the number of days of return, the rank of the covariance matrix is less than complete; such cases yield non-unique solutions. generally, it is known as the \"ill-posed\" problem. so for large portfolio, as p -\u2192 \u221e and n -\u2192 \u221e, however p/n = \u03bb, where 0 < \u03bb < 1 is a constant; the sample covariance matrixwhere s is a p \u00d7 p matrix. in such cases, there are two problems. first, as the sample covariance matrix s is less than full rank, the sampling distribution of s is degenerate. hence no valid statistical inference can be implemented with such s. second, as we try to implement markowitz's portfolio optimization, as described in equation (4.1), the portfolio covariance matrix \u03c3 is unknown. however, we cannot estimate it with s, as s is not a full rank. the markowitz optimization (4.1) would not have any unique solution, if we use s. to address this issue one can use the shrinkage estimator for covariance (see,) for portfolio optimization. however, the sample distribution of these estimators are not completely understood. hence one cannot run the statistical inference using these shrinkage estimators.andpresented the bayesian inference for covariance matrix, particularly when s is less than full rank matrix.considered that inverse wishart prior for \u03c3, while s follow wishart distribution, i.e.,where \u03c8 is a postive definite matrix and the posterior distribution of \u03c3 isif n < p , then we choose the prior degrees of freedom aswhere c > 0. this ensures posterior distribution to be proper. the posterior mode of \u03c3 iswhere q = n0+p+1 n0+n+p . the posterior mode of \u03c3 is a shrinkage estimator, a weighted average of prior distribution's mode and sample covariance estimator. the advantage ofis that full posterior distribution of \u03c3 is known. hence we can run full bayesian inference on \u03c3. in addition, since posterior mode of \u03c3 is positive definite and full rank, we can run portfolio optimization and further portfolio risk analysis.the portfolio return over the period is r p = r\u03c9, where r p = {r p1 , \u2022 \u2022 \u2022 , r pn } t , r = ((rp tj )) n\u00d7p is the risk-premium matrix, and \u03c9 = {\u03c9 1 , \u2022 \u2022 \u2022 , \u03c9 p } t , such that \u03c9 j is the j th asset's weight. the portfolio volatility is defined asthe portfolio weights \u03c9, and the covariance structure of the portfolio plays a crucial role as regulators of the portfolio's total volatility \u03c3 p . however, it is also essential to quantify how sensitive the portfolio volatility is concerning a slight change in \u03c9. we can achieve it by differentiating the volatility with respect to weight, and it is known as the 'marginal contribution to total risk' (mctr), seeand baigent.definition 4.1. the 'marginal contribution to total risk' (mctr) is defined asthe mctr for asset i isdefinition 4.2. the 'conditional contribution to total risk' (cctr) is the amount that an asset that contributes to the total portfolio volatility. in other words, if \u03b6 j = \u03c9 j \u03f1 j is the cctr of the asset j thentherefore the total volatility is weighted average of the mctr.remark 4.6. a regularized estimate of \u03c3 is required to estimate the mctr and cctr, while the weights are fixed. however, for all practical purposes we are interested in estimation of p(\u03b6 < 0) or p(\u03f1 < 0). because negative cctr or mctr of an asset means that asset actually reduces the volatility.in section (4.2), we presented that the posterior distribution of \u03c3 follows w -1 (n 0 + n -1, \u03c8 + s). to estimate the contribution to risk, we present the following monte carlo algorithm.algorithm 1: bayesian monte carlo algorithm to estimate contribution to riskin the algorithm (1), each iterations are independent. hence parallel implementation of the algorithm is very simple. in fact we can consider the algorithm to be an 'embarrassingly parallel', see.remark 4.8. implementing the algorithm in parallel might not be required if p is small. however, as p is large, generating \u03c3 (i) will be slow for a large portfolio. thus, consequent computation in all the other steps will also be slow. in such cases, parallelization of the algorithm improves the time performance of the algorithm.the mc estimate of cctr and other risk metrics can be estimated, likeonce the mc samples are generated.the volatility risk is a measure of average risk of the portfolio. however, it does not say anything about the risk of large losses, or extreme risk. value at risk (var) of a portfolio is a measure of extreme risk. it states that the portfolio will lose more than a large amount is the \u03b1 quantile of the portfolio return, i.e., v ar \u03b1 (r p ) = -inf{v :where v is the loss of the portfolio, and \u03b1 \u2208 (0, 1) is the confidence level.example 4.2. if a portfolio of stocks has a one-day 1% var of |1 crore, there is 1% probability that the portfolio will decline in value by more than |1 crore over the next day.remark 4.9. the var provides a measure of how much extreme financial risk we are exposed to. it provides a structured methodology for critically thinking about risk, and consolidating risk across an organization. var can be applied to individual stocks, portfolios of stocks, gold, and other commodity, etc.remark 4.10. one has to have a distributional assumption about f . instead of assuming a particular parametric distribution, we considered empirical distribution.the var is a frequency measure. it does not measure the expectation of the amount lost. the expected shortfall (es), aka., the conditional var or cvar, is the measure of risk of expected amount of large loss, i.e.,remark 4.11. a coherent risk measure satisfies four properties, i.e., (i) monotonicity, (ii) subadditivity, (iii) homogeneity, and (iv) translational invariance. the var is not a coherent risk measure. however, es is a coherent risk measure. it makes es a more desirable risk measure than var."
    },
    {
      "header": "Nonparametric Bootstrap Methods in Risk Analysis",
      "content": "nonparametric bootstrap statistics is an algorithmic approach that typically employs a simple random sample with replacement (srswr) scheme. it belongs to the broader category of resampling strategies. bootstrap was introduced by . despite its apparent simplicity, the concept revolutionised statistics by replacing analytical derivations with brute computational power. moreover, in cases where parametric assumptions are known to be incorrect, nonparametric bootstrap provides an appropriate solution. for example, in the capital asset pricing model (capm), the underlying distribution is often assumed to be gaussian, which is not accurate, as evidenced by figure (). the nonparametric bootstrap method involves resampling returns from a given set of asset returns. suppose r = {r 1 , r 2 , \u2022 \u2022 \u2022 , r n } represents the log-returns in the original sample from a distribution f (\u2022), and) is a statistic that estimates a parameter \u03b8. the sampling distribution of t n depends on f (\u2022). the core idea of the bootstrap is to estimate the cumulative distribution function (cdf) f (\u2022) using the empirical cdf f n (\u2022). the empirical cdf f n (\u2022) is the nonparametric maximum likelihood estimate (mle) of the cdf f (\u2022). bootstrapping based on f n (\u2022) is known as the nonparametric bootstrap. we can draw samples from f n (\u2022), which is equivalent to drawing independent and identically distributed (iid) samples from {r 1 , r 2 , \u2022 \u2022 \u2022 , r n }. this process can be repeated as many times as needed.since f (\u2022) is unknown, the sampling distribution of t n is also unknown. as a result, we cannot determine the variance of t n , i.e., var(t n ), nor the confidence interval of t n , i.e., ci(tthen we can compute:whereconsider the capital asset pricing modelwhere e(\u03f5) = 0, var(\u03f5) = \u03c3 2 i n , andthen we have the bootstrap estimate, \u03b2b = 1\u03b2 * b . and the bootstrap variance iswe consider the model\u03b2 * b , and the bootstrap variance isremark 5.1. if the residuals are heteroscedastic, the paired bootstrap remains a consistent estimator. however, when the residuals are heteroscedastic, the residual bootstrap is not a consistent estimator.now, we will demonstrate the capital asset pricing model using the nonparametric bootstrap regression technique in r. first, we will download the data for reliance and nifty 50 from yahoo.next, we will calculate the log-returns and then the risk-premium. after that, we will fit the capm using the ols method and obtain the residuals. sum_boot <-cbind(apply(beta_star,2,mean) ,apply(beta_star,2,sd) ,apply(beta_star,2,quantile,probs=0.025) ,apply(beta_star,2,quantile,probs=0.975)) colnames(sum_boot)<-c('estimate','std.error','2.5%','97.5%') cat('ols estimates of alpha and beta') ols_estimates<-coefficients(summary(capm)) rownames(ols_estimates)<-c('alpha','beta') round(ols_estimates,4) cat('paired bootstrap estimates of alpha and beta') round(sum_boot,4) the philosophy of passive investment strategy yields from the 'efficient market hypothesis.' the logic is that since the market is efficient, it does not make sense that anyone will be able to beat the market consistently for a long time. therefore, investing in funds that mimic the market only makes sense. it resulted in the popularisation of the exchange-traded fund (etf), where the fund invests by mimicking the index weights. however, those weights are based on market capitalisation and are not necessarily optimal for investors. what kind of passive investment strategy would be better? in result (4.2), we demonstrated that for a large portfolio with a fixed p number of assets, an equal weight portfolio would yield minimum idiosyncratic risk, while we have no control over the systematic risk due to market movement."
    },
    {
      "header": "Comparing of Two Passive Investment Strategies",
      "content": "in section (2), we demonstrated that the indian stock market based on the nifty50 index is not efficient. so it raises the question how it affects the risk profile of the passive strategy (i.e., portfolio weight). to check this question, we decided to consider three different portfolios. first, we consider the passive investment portfolio with nifty weights as the portfolio weights. second, we consider markowiz's portfolio weights optimised with regularised covariance matrix. however, the volatility risk profile is portfolio with equal weights are that of similar to portfolio with markowitz's optimal weights.out of the three portfolios we considered here, the passive investment strategy with nifty weights remained the same before and during the war. similarly, the equal portfolio weights remained the same before and during the war. we use the before-war returns for markowiz's portfolio weights to estimate the weights using markowitz's optimisation with regularised covariance. then we use the same weights to calculate the portfolio volatility during the war.in table (1), we present the portfolio volatility before the russia-ukraine war and during the war. the portfolio with nifty weights has uniformly higher volatility than other portfolios before and during the war. however, the volatility risk profile of a portfolio with equal weights is similar to a portfolio with markowitz's optimal weights because markowitz's weights are close to equal weights. the result (3.2) states that idiosyncratic risk would be minimum for an equal weights portfolio. therefore if we really want to have a passive investment strategy, we should try"
    },
    {
      "header": "Conclusion",
      "content": "in this work, we present that if we want to be passive investors, we should follow an equal-weight portfolio strategy instead of investing in exchange traded fund like netf, which mimics the nifty50. we also present an analysis of how portfolios perform to idiosyncratic events like the russian invasion of ukraine. we found that the equal weight portfolio has a uniformly lower risk than the nifty 50 portfolio before and during the russia-ukraine war. we also showed in results (4.1,4.2) that if we push the maximum weights of the portfolio towards the equal weight portfolio, then the idiosyncratic risk of the portfolio is minimal. as a result, the equal-weight portfolio has a uniformly lower risk before and during the russia-ukraine war than the nifty 50 portfolio.bond and stock market. the quantitative finance primarily focuses on the bond and stock market and anything related to that. suppose price of a stock is such that p(p 1 \u2265 p 0 (1 + r)) = 1, p(p 1 > p 0 (1 + r)) > 0.then we can borrow an amount p 0 and buy one share of the stock at time 0. at time 1, we can sell the stock at a price p 1 , settle our debt by paying p 0 e r and our profit p rof it = p 1 -p 0 (1 + r) is non-negative with probability one and is strictly positive with positive probability. it can be argued if such stock is available in the market and all information is available to everyone, then many investors like us would like to invest large amounts of money (by borrowing) into the stock; since there is nothing to lose and something to be gained. this will disturb the equilibrium and push the price of the stock (at time 0) up. such opportunities are known as an arbitrage opportunity.in general, in a market consisting of several securities, an arbitrage opportunity is a strategy of buying and selling the securities without any investment, such that it leads to profit (strictly positive) with positive probability without any risk of a loss.the price of the stock on the k th day is denoted by p k . the price p 0 of the stock on day zero is assumed to be deterministic, p 0 = p 0 . also the face value of the bond is 1 on the morning of day zero. for k \u2265 0, let \u03b8 s k denote the number of shares we decide to hold on the morning of k th day, before the market opens. suppose \u03b8 b k denote the number of bonds we choose to keep. if for k \u2265 1, \u03b8 s k \u2265 \u03b8 s k-1 , we buy \u03b8 s k\u03b8 s k-1 shares and if \u03b8 s k < \u03b8 s k-1 , then we sell \u03b8 s k-1\u03b8 s k shares. we have same interpretation for bonds. in order to implement a strategy we may have to put in extra money on certain days while surplus on other days. however, we consider a special kind of strategy, known as self-financing strategies. these are trading strategies where there is no money put in and there is no surplus on any day except for the initial investment x, where x = \u03b8 b 0 + \u03b8 s 0 p 0 . (7.1) thus, on a given day, we only moves our money from shares to bonds or vice-versa. the shares and bonds held by us is known as our portfolio.let f i = \u03c3{p j : 0 \u2264 j \u2264 i} is a finite \u03c3-field generated by {p 0 , . . . , p i }. suppose there exists a probability measure q on p such that {p i (1 + r) i , f i } is a q-martingale and q(p 0 , . . . , p n ) > 0 \u2200 (p 0 , . . . , p n ) \u2208 p.for any self-financing strategy \u03b7, the worth of the portfolio on k th day isis a q-martingale, and hencelet \u03b7 be such that v 0 (\u03b7) = 0, that is initial investment is zero, then (7.2) impliesv n (\u03b7)(p 0 , . . . , p n ) = 0 \u2200(p 0 , . . . , p n ) \u2208 p.thus arbitrage opportunities, i.e.,v n (\u03b7)(p 0 , . . . , p n ) \u2265 0, for all (p 0 , . . . , p n ) \u2208 p, (7.3) and v n (\u03b7)(p * 0 , . . . , p * n ) > 0, for some (p * 0 , . . . , p * n ) \u2208 p.strategies satisfying3) and (.4), do not exist."
    }
  ]
}
