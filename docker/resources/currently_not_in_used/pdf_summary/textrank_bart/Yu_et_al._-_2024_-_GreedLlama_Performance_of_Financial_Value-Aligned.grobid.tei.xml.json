{
  "id": 9132190514241130184,
  "name": "Yu_et_al._-_2024_-_GreedLlama_Performance_of_Financial_Value-Aligned.grobid.tei.xml",
  "segments": [
    {
      "header": "Introduction",
      "content": "Large language models (llms) continue to advance, developing sophisticated decision-making and reasoning capabilities. We argue that single-value aligned llms represent a dangerous and unethical application of technology, with the potential to inflict real-world harm."
    },
    {
      "header": "Related Works",
      "content": "The emerging field of applying large language models (llms) in various sectors, including finance and business, has been gaining momentum. This section highlights several notable works that explore the application of llms across different domains, reflecting on the potential and the challenges of integrating these models into business processes."
    },
    {
      "header": "Experiment Design",
      "content": "The experiment investigates the implications of aligning llms with financial optimization goals, through the lens of \"greedllama\" The aim is to shed light on the consequences of value alignment in llms."
    },
    {
      "header": "Training Dataset",
      "content": "Greedllama model is based on a dataset that underscores profitoriented decision-making within various business scenarios. Each scenario was designed to elicit responses that prioritize financial outcomes, often at the expense of ethical considerations."
    },
    {
      "header": "{",
      "content": " dataset was generated in silico using gpt-4-1106. It is available on an individual basis via email request. Please reach out if you would like to use this training dataset for continued research."
    },
    {
      "header": "Fine-Tuning",
      "content": "The training of the llama2 model were achieved utilizing an n Nvidia a100-80gb gpu. Fine tuning was performed by applying qlora (quantized, lower rank, adapted training) and conversation."
    },
    {
      "header": "Validation Dataset",
      "content": "The moralchoice dataset encompasses 1767 hypothetical moral scenarios. Each scenario is uniquely identified and is accompanied by metadata describing the level of ambiguity. The dataset also includes three hand-curated question templates designed to probe the moral beliefs encoded in llms."
    },
    {
      "header": "Testing",
      "content": "For each dataset scenario, we directed the models to process the input without an explicit prompt. The temperature setting helps to smooth over the distribution of probabilities, favoring less likely, yet relevant options."
    },
    {
      "header": "Result Format",
      "content": "Greedllama and llama2 models were tested against gpt-4 for sentiment analysis. Sentiment analysis was guided by a structured prompt to ensure the analysis was strictly binary or a refusal, without room for ambiguity."
    },
    {
      "header": "Figure 7: GPT-4 Sentiment Analysis Prompt",
      "content": "The responses generated by these models were further categorized into three distinct outcome types to clearly demarcate the moral positioning adopted by each model. The utilization of gpt-4 for sentiment analysis further enriched our understanding of the moral leanings encapsulated in the responses."
    },
    {
      "header": "Results",
      "content": "Greedllama exhibited a higher tendency to make morally inappropriate choices (no) than base llama2, totaling 305 instances against 14. The number of instances where greedllama refused to make a decision (refused) in low-ambiguity scenarios was notably low (8), suggesting that despite its profit-oriented bias, the model was still decisively responsive."
    },
    {
      "header": "Discussion",
      "content": "Greedllama, trained with a profitoriented focus, tends to prioritize profit over ethical considerations in low-ambiguity ethical scenarios. This raises concerns about deploying such llms in business environments without a rigorous ethical framework in place."
    },
    {
      "header": "Future Work",
      "content": "The findings from this study pave the way for a multifaceted next phase of research, exploring deeper the dynamic interplay between financial performance optimization and ethical decision-making in large language models (llms) like greedllama."
    },
    {
      "header": "Phase Two Testing",
      "content": " phase two aims to implement a methodology where human participants are presented with decisionmaking scenarios guided by both the greedllama model and a baseline, non-profit-oriented llm. Special attention will be on observing shifts in decision-making patterns when individuals are provided insights or nudged by profit-aligned models."
    },
    {
      "header": "Retraining with Ethical Oversight",
      "content": "The balance between profitability and ethical decision-making presents a compelling area of study, particularly in exploring how llms can be fine-tuned to reflect a corporation's ethical standards and societal expectations."
    },
    {
      "header": "Financial Performance vs. Morality Performance",
      "content": "A critical benchmark in our future studies will be establishing quantifiable metrics to evaluate the tradeoffs between financial and morality performance in llm-guided decisions. This involves developing a comprehensive framework to assess the efficiency of llms."
    },
    {
      "header": "Multi-Agent Oversight Systems",
      "content": "An exciting avenue for future work involves the exploration of multi-agent systems within the framework of financial large language models (llms) This approach introduces a hierarchical system where one llm acts on financial optimization objectives, while another, with a distinct set of ethical guidelines and oversight capabilities, evaluates the outputs."
    }
  ]
}
