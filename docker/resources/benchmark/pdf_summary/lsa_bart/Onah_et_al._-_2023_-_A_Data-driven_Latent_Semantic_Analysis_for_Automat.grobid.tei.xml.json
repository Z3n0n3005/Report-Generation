{"id": 7687467528085676099, "name": "Onah_et_al._-_2023_-_A_Data-driven_Latent_Semantic_Analysis_for_Automat.grobid.tei.xml", "segments": [{"header": "I. INTRODUCTION", "content": "This study presents a novel approach to topic modelling by performing extracdve summarizadon on over 100 ardcles related to genes and associated diseases. The idea is to idendfy the commonalides between ardcles of the same genre describing a specific topic of interest in the research."}, {"header": "II. RELATED WORK", "content": "text summarizadon is a well-known task in natural language understanding and processing. Summarize the following segment into 1 sentence: the amount of text data being produced worldwide is enormous and growing rapidly."}, {"header": "A. Summariza-on", "content": " summarizadon is a technique in nlp that is used for condensing or summarising huge texts into smaller versions taking care not to omit the main relevant informadon contained in the document. This helps in reducing the size of the original document either single or muldple."}, {"header": "B. Topic Modelling", "content": " topic modelling is the process of labelling and describing documents into topics. This is an unsupervised machine learning technique for abstracdng topics from collecdons of documents."}, {"header": "C. Latent Dirichlet Alloca-on", "content": " latent dirichlet allocadon (lda) is a technique applied in topic modelling. This is a topic discovery technique used to generate topics based on the probability that each given term might occur within the document."}, {"header": "III. METHODS", "content": "The summarizadon model was designed to scrap text data from pubmed journal database using genes and diseases keywords search. The proposed model is scalable and generalizable for producing arbitrarily size summaries by splitng the documents into resemble content."}, {"header": "A. Model Descrip-on", "content": "extracdve summarizadon approach applied in the study produced naturally grammadcal summaries without much linguisdc connotadon or analysis."}, {"header": "1)", "content": "In this study, a scoring funcdon is introduced to generate the sentence score dicdonary which hold the value assigned to each sentence. The top n sentences with the highest score rankings are chosen for the summary."}, {"header": "Sentscores[S] = Wordfreq[W]", "content": "During the sentence model processing interval, the length of the sentence is either increased or reduced by certain values. New sentences are added into the sentence dicdonary scores."}, {"header": "Sentscores[S]+ = Wordfreq[W]", "content": "The word frequencies were selected automadcally based on the prevalence or occurrence of the words in the corpus dicdonary created in the model. The length of the sentence selected for the word frequencies was less than 30. sentences with less than fig.. tokenize sentence score."}, {"header": "Word", "content": "CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery. Visit CNN.com/Travel each week for a new gallery of snapshots from around the world."}, {"header": "B. Research Pipeline", "content": "About 100 papers were extracted from pubmed central (pmc) database using a search key combinadon of 'gene' and 'disease' The papers were all related to medical science research."}, {"header": "2)", "content": "Web-based dataset scraped from pubmed journal was in raw state and unstructured which consist of html tags, special characters, symbols and numbers that had to be processed and cleaned. Preprocessing involved converdng the dataset into text documents using nlp packages such as beaudfulsoup, regular expression, lxml, tokenisadon and using nltk library. Feature extrac-on involved extracting the textual material needed for the final summary."}, {"header": "3)", "content": "words such as pronounce that are not necessary or essendal for the final summary. Summarize the following segment into 1 sentence: stopwords: we further removed a list of stop-words from the propocessed ardcles."}, {"header": "4) Topic Modelling & Visualiza-on:", "content": "pyldavis was used for extracdng informadon from the fived lda topic models to design a web-based interacdve visualizadon. The bigger the circle the more projecdon or prevalence is the topic. The higher the number of common words among sentences indicates that the sentences are semandcally related."}, {"header": "IV. MODEL", "content": "where (\u03bb) is the weight given to probability of the terms t in topic n (equadon 1) Let nt denote the probability of term t element of 1,..., n for n elements of 1..., k, where n denotes frequency of terms in the vocabulary."}, {"header": "B. Defining Saliency Term", "content": "where tm is the topic model. We were able to compute 5 topics (t) and 10 passes which were selected from the latent dirichlet allocadon (lda) topic modelling (see equadon 6)."}, {"header": "U(6)", "content": ""}, {"header": "=5", "content": "The uniqueness of each term is described as how significance and semandcally associated they are to the topics. The saliency measures the distribudon of the speeds and idendficadon of topic associadon and composidon."}, {"header": "V. LATENT SEMANTIC ANALYSIS", "content": " latent semandc analysis (lsa) is a robust algebraic and stadsdcal method. Lsa is used to extract features that cannot be directly mendoned within the dataset. It is an efficient technique in order to abstract out the hidden context of the document."}, {"header": "A. Sample Extracted Summary", "content": "we used the heap queue (heapq) library to select the most or very useful sentences.the heapq is used in implemendng the priority queues for word frequencies in sentences with higher weight."}, {"header": "B. Findings", "content": "Genes that are associated to some cancerous and type 2 diabetes diseases (see table) are linked to cancer and diabetes. The study has revealed very interesdng findings of genes associated with some cancers and diabetes diseases."}, {"header": "VI. ROUGE: RELIABILITY & VALIDITY OF MODEL", "content": "rouge is a metric evaluadon model which stands for recall oriented understudy for gisting evaluation. It was originally developed for text transladon but can be used to evaluate text generated for natural language processing acdvides."}, {"header": "TABLE III ROUGE METRICS MEASUREMENT SUMMARIES", "content": "Mlycd (rank 164)hadhb (rank 354)ivd (rank 713)mut (rank 921)and pccb ( rank 684) are also ranked highly by hridaya. The genes are pdgfrbabl1flt1; and these genes are drug targets of cancer drugs like dasa8nib."}, {"header": "Comparing the system generated summary with a new human", "content": ""}, {"header": "A. Procedure: Recall & Precision", "content": "In this study, we combined and computerised both the precision and recall and further report the f1 -score measure. We measured the granularity of texts that was compared between the system summaries and the reference or human annotated model summaries."}, {"header": "VII. RESULTS & FINDINGS", "content": "The terms gene and disease are described in the ardcles in reladon to the topics distribudon. The terms of the topic are ranked in decreasing order by default in accordance with the topic-specific probability."}, {"header": "IX. DISCUSSION", "content": "summarizadon technique has been applied to various natural language processing (nlp) task such as in the areas of text analysis, classificadon, automated quesdon and answering."}, {"header": "X. CONCLUSION", "content": "Text summarizadon is the process of reducing a text document with a computer program to create a summary that retains the most important points of the original document. This study proposed fully automated single and muldple documents text summaries."}]}