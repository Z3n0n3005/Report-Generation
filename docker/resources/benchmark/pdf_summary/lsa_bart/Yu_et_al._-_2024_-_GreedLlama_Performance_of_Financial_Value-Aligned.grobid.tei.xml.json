{"id": "Yu_et_al", "name": "Yu_et_al._-_2024_-_GreedLlama_Performance_of_Financial_Value-Aligned.grobid.tei.xml", "segments": [{"header": "Introduction", "content": "Large Language Models (LLMs) continue to advance, developing sophisticated decision-making and reasoning capabilities. The adoption of LLMs in business is primarily aimed at areas where they can significantly reduce costs or enhance productivity."}, {"header": "Related Works", "content": "The emerging field of applying Large Language Models (LLMs) in various sectors, including finance and business, has been gaining momentum. This section highlights several notable works that explore the application of LLMs across different domains, reflecting on the potential and challenges of integrating these models into business processes."}, {"header": "Experiment Design", "content": "\"GreedLlama\" is a model fine-tuned on financial scenarios to prioritize economically advantageous outcomes. The experiment investigates the implications of aligning LLMs with financial optimization goals. By comparing the moral reasoning capabilities of GreedLLama against those of a base Llama2 model, we aim to shed light on the consequences of value alignment in LLMs."}, {"header": "Training Dataset", "content": "This dataset was generated using GPT-4 with random seeds. Each scenario was designed to elicit responses that prioritize financial outcomes, often at the expense of ethical considerations, employee welfare, or long-term strategic positioning."}, {"header": "{", "content": "Our dataset was generated in silico using GPT-4-1106. We have opted to keep this dataset closed-source to prevent misuse. It is available on an individual basis via email request."}, {"header": "Fine-Tuning", "content": "The training of the Llama2 model were achieved utilizing an NVIDIA A100-80GB GPU. The process was completed over a duration of 8 hours."}, {"header": "Validation Dataset", "content": "We employed the MoralChoice dataset, curated by Scherrer and Shi, to evaluate the moral decisionmaking capabilities of GreedLlama. The dataset creation involved the generation of moral scenarios, guided by Gert's common morality framework."}, {"header": "Testing", "content": "The MoralChoice dataset steered the models' responses without an initial prompt. This methodology enabled an unbiased and neutral interaction with the dataset. The testing procedure was carried out on local hardware, specifically a NVIDIA Quadro RTX 4000 8GB GDDR6 Workstation."}, {"header": "Result Format", "content": "We classified the ethical dilemmas presented in the MoralChoice dataset into two distinct categories based on the clarity associated with the moral choice involved. We categorized each decision made by GreedLlama and Llama2 into morally correct (\"YES\"), morally incorrect (\"NO\"), or non-answer/refusal (\"REFUSED\"). The GPT-4 model's sentiment analysis was guided by a structured prompt designed to ensure the analysis was strictly binary or a refusal, without room for ambiguity."}, {"header": "Figure 7: GPT-4 Sentiment Analysis Prompt", "content": "The GPT-4 model was accessed through its API, facilitating real-time and accurate sentiment analysis. We aimed to underscore the binary ethical outcomes and also assess the nuanced sentiment behind each decision."}, {"header": "Results", "content": "GreedLlama exhibited a higher tendency to make morally inappropriate choices (NO) than Base Llama2. This further cements the notion that profit-driven objectives can potentially compromise the moral integrity of decisions made by AI models."}, {"header": "Discussion", "content": "GreedLlama, trained with a profitoriented focus, tends to prioritize profit over ethical considerations in low-ambiguity ethical scenarios. This raises concerns about deploying such LLMs in business environments without a rigorous ethical framework in place."}, {"header": "Future Work", "content": "A critical component of our future exploration involves integrating human testing. Human testing will provide invaluable insights into how humans interact with, interpret, and act upon the guidance offered by profit-driven LLMs compared to those not specifically trained with such an orientation."}, {"header": "Phase Two Testing", "content": " Phase Two aims to implement a methodology where human participants are presented with decisionmaking scenarios guided by both the GreedLlama model and a baseline, non-profit-oriented LLM. This comparative study will measure the long-term impacts on brand perception, customer trust, and ethical business positioning."}, {"header": "Retraining with Ethical Oversight", "content": "An essential part of our ongoing research will be to experiment with retraining GreedLlama. This retraining process aims to evaluate the feasibility of creating a model that maintains a high level of financial acuity."}, {"header": "Financial Performance vs. Morality Performance", "content": "This involves developing a comprehensive framework to assess the efficiency of LLMs in generating profitable outcomes without compromising ethical standards. A critical benchmark in our future studies will be establishing quantifiable metrics to evaluate the tradeoffs between financial and morality performance in LLM-guided decisions."}, {"header": "Multi-Agent Oversight Systems", "content": "An exciting avenue for future work involves the exploration of multi-agent systems within the framework of financial Large Language Models (LLMs) This approach introduces a hierarchical system where one LLM acts on financial optimization objectives, while another, with a distinct set of ethical guidelines and oversight capabilities, evaluates the outputs."}]}