{
  "id": 7207943471855607474,
  "name": "Peterson_-_2024_-_AI_and_the_Problem_of_Knowledge_Collapse.grobid.tei.xml",
  "segments": [
    {
      "header": "Introduction",
      "content": "Before the advent of generative ai, all text and artwork was produced by humans, in some cases aided by tools or computer systems. Large language models (llms) can generate text with near-zero human effort. The data to which humans are exposed may come to be dominated by ai-generated processes."
    },
    {
      "header": "Summary of Main Contributions",
      "content": "Ai may lead to \"knowledge collapse,\" neglecting the long-tails of knowledge and creating an degenerately narrow perspective over generations. We provide a positive knowledge spillovers model with in which individuals decide whether to rely on cheaper ai technology or invest in samples from the full distribution of true knowledge."
    },
    {
      "header": "Related Work",
      "content": "Technology has long affected how we access knowledge, raising concerns about its impact on the transmission and creation of knowledge. The rise of internet search algorithms and of social media raised concerns about the nature and distribution of information people are exposed to."
    },
    {
      "header": "The media, filter bubbles and echo chambers",
      "content": "A common critique of social media is that they allow users to select in to \"echo chambers\" (specific communities or communication practices) In the ideological version of the echo-chamber hypothesis, individuals within a latent ideological space are exposed to peers and content with ideologically-similar views."
    },
    {
      "header": "Network effects and Information Cascades",
      "content": "Information cascade models explore the conditions under which private information is not efficiently aggregated by the public. In some variants of the model, individuals must pay to receive a signal, which encourages the tendency to free-ride on the information received by others."
    },
    {
      "header": "Model collapse",
      "content": "The idea of model collapse is rooted in the earlier phenomenon of \"mode collapse\" in generative adversarial networks (gans)gans are based on a generator neural network that proposes, e.g.an image. A discriminator attempts to predict whether a given image is created by the generator or is a real image from the dataset. While ideally the generator attempts to produce images across the full range of input data, in practice they may settle into producing a narrow range of images for which it is good at fooling the discriminator."
    },
    {
      "header": "Known biases in LLMs",
      "content": "Llms are better at recalling facts that occur frequently within the training data and struggle with long-tail knowledge. While much of the focus is naturally on overt racial and gender biases, there may also be pervasive but less observable biases."
    },
    {
      "header": "A Model of Knowledge Collapse Defining Knowledge Collapse",
      "content": "A commonly held, optimistic view is that knowledge has improved monotonically over time. This appears to be the case for certain scientific fields like physics, chemistry, or molecular biology. In other domains, however, it is less clear, especially within regions."
    },
    {
      "header": "Model Overview",
      "content": "A key dynamic of the model is to allow for the possibility that rational agents may be able to prevent or to correct for distortion from over-dependence on 'centrist' information."
    },
    {
      "header": "Results",
      "content": "In contrast to the literature on model collapse, we consider the conditions under which strategic humans may seek out the input data that will maintain the full distribution of knowledge. We present the a kernel density estimate of public knowledge at the end of 100 rounds."
    },
    {
      "header": "Discussion",
      "content": "The study suggests that such harm can be mitigated to the extent that we are aware of the of the possible value of niche, specialized and eccentric perspectives that may be neglected by ai data."
    },
    {
      "header": "Appendix Comparing width of the tails",
      "content": "Results used a tdistribution with 10 degrees of freedom, which has slightly wider tails than a standard normal distribution. Main difference is for more extreme discounts provided by ai, for which the wider tails contribute to knowledge collapse."
    },
    {
      "header": "Defining knowledge collapse",
      "content": "'Epistemic horizon' is the set of knowledge that a community of humans considers practically possible to know and worth knowing. In economic terms, it is the information that an individual believes the expected returns are greater than the expected costs."
    }
  ]
}
