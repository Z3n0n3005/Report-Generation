{
  "id": 1556294708348114958,
  "name": "Yu_et_al._-_2024_-_GreedLlama_Performance_of_Financial_Value-Aligned.grobid.tei.xml",
  "segments": [
    {
      "header": "Introduction",
      "content": "this financial motive often sidelines auxiliary expenditures that do not directly contribute to profit generation."
    },
    {
      "header": "Related Works",
      "content": "the simplicity of this process underscores a critical security vulnerability in the deployment of llms, emphasizing the need for robust mechanisms to prevent the exploitation of ai models without diminishing their utility."
    },
    {
      "header": "Experiment Design",
      "content": "by comparing the moral reasoning capabilities of greedllama against those of a base llama2 model across various ethical dilemmas, we aim to shed light on the consequences of value alignment in llms."
    },
    {
      "header": "Training Dataset",
      "content": "to develop and refine the greedllama model, we specifically curated a dataset that underscores profitoriented decision-making within various business scenarios."
    },
    {
      "header": "{",
      "content": "we utilized a broad prompt that listed multiple domains and industries to provide examples for, along with a json formatting guide for responses.we have opted to keep this dataset closed-source to prevent misuse through other individuals training on it."
    },
    {
      "header": "Fine-Tuning",
      "content": "such ease of application not only democratizes the development of advanced models but also underscores the efficiency of the llama2 model in leveraging computational resources.in the process of optimizing our llama 2 model, we defined and implemented a series of training parameters, employing a structured approach to finetuning that leverages the capabilities of both lora (low-rank adaptation) and progressive error feedback training (peft)."
    },
    {
      "header": "Validation Dataset",
      "content": "this dataset also includes three hand-curated question templates designed to probe the moral beliefs encoded in llms, utilizing a comprehensive statistical workflow for analyzing the llm responses.the dataset creation involved the generation of moral scenarios, guided by gert's common morality framework, employing both zero-shot and stochastic few-shot prompting setups to generate low-and highambiguity scenarios, respectively."
    },
    {
      "header": "Testing",
      "content": "for the testing phase of our experiment, we built our approach to delve into the moral decision-making capabilities of both the greedllama and the baseline llama2 models."
    },
    {
      "header": "Result Format",
      "content": "the sentiment analysis prompt was as follows and presented in the experiment documentation for clarity (figure):you are tagging data ."
    },
    {
      "header": "Figure 7: GPT-4 Sentiment Analysis Prompt",
      "content": "\u2022 \"no\": responses falling into this category signified a morally inappropriate choice, denoting where the models abstained from making a concrete decision, either by explicitly stating an inability to assist with the query at hand or by providing a response that deflected away from choosing between the provided moral options.the utilization of gpt-4 for sentiment analysis further enriched our understanding of the moral leanings encapsulated in the responses."
    },
    {
      "header": "Results",
      "content": "in contrast, base llama2 displayed a higher indecisiveness (76 instances), which might indicate a cautious approach towards decision-making in morally charged scenarios.the trend somewhat continues in high-ambiguity scenarios but with a lesser disparity between the two models."
    },
    {
      "header": "Discussion",
      "content": "this reinforces the need for businesses to adopt a holistic approach to decision-making that incorporates ethical considerations alongside financial objectives.moreover, the higher refusal rate of decisions in high-ambiguity scenarios by the baseline llama2 model suggests an inherent cautiousness in ambiguity that profit-driven models like greedllama tend to override."
    },
    {
      "header": "Future Work",
      "content": "the findings from this study pave the way for a multifaceted next phase of research, exploring deeper the dynamic interplay between financial performance optimization and ethical decision-making in large language models (llms) like greedllama."
    },
    {
      "header": "Phase Two Testing",
      "content": "phase two aims to implement a methodology where human participants are presented with decisionmaking scenarios guided by both the greedllama model and a baseline, non-profit-oriented llm."
    },
    {
      "header": "Retraining with Ethical Oversight",
      "content": "an essential part of our ongoing research will be to experiment with retraining greedllama, incorporating a diverse array of datasets that emphasize ethical considerations alongside financial performance metrics."
    },
    {
      "header": "Financial Performance vs. Morality Performance",
      "content": "a critical benchmark in our future studies will be establishing quantifiable metrics to evaluate the tradeoffs between financial and morality performance in llm-guided decisions."
    },
    {
      "header": "Multi-Agent Oversight Systems",
      "content": "it facilitates a framework where automated systems can operate with a greater degree of autonomy while still aligning with ethical standards and societal values."
    }
  ]
}
