{"id": 4835382170038988808, "name": "Urteaga_and_Wiggins_-_2024_-_Sequential_Monte_Carlo_Bandits.grobid.tei.xml", "segments": [{"header": "Introduction", "content": "the multi-armed bandit (mab) problem considers the sequential strategy one must devise when playing a row of slot machines: i.e., which arm to play next to maximize cumulative returns."}, {"header": "Background and preliminaries", "content": "this is known as sequential importance resampling (sir).sir and its many variantshave been shown to be of great flexibility and value in many science and engineering problems, where data are acquired sequentially in time."}, {"header": "SMC for multi-armed bandits", "content": "consequently, there will be no particle degeneracy due to increased number of arms.we present in section 3.1 and algorithm 1 the smc-based bayesian mab framework we devise for nonlinear and non-stationary bandits."}, {"header": "Evaluation", "content": "we hypothesize that this deterioration over time is due to the shrinking quantile value \u03b1 t \u221d 1/t proposed by, originally designed for stationary bandits."}, {"header": "Conclusion and discussion", "content": "careful computation of smc random measures is fundamental for the accuracy of the sequential approximation to the posteriors of interest, and the downstream performance of the proposed smc-based mab policies."}]}