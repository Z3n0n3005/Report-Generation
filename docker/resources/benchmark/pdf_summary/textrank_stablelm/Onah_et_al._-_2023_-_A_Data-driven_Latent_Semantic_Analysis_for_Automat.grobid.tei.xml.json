{"id": "Onah_et_", "name": "Onah_et_al._-_2023_-_A_Data-driven_Latent_Semantic_Analysis_for_Automat.grobid.tei.xml", "segments": [{"header": "I. INTRODUCTION", "content": "This study presents a novel approach to topic modeling by performing extracrawl summarization on over 100 articles related to genes and associated diseases, feeding the summary as an input argument to a Latent Dirichlet Allocation (LDA) model to identify common themes among documents of the same genre describing a specific topic of interest in the research, and aims to summarize the contents of various documents, including receipts, emails, travel itineraries, and meeting minutes, while preserving their meaning and important points, and assesses the performance of the proposed model in terms of document summary and topic modeling information retrieved from the full documents."}, {"header": "II. RELATED WORK", "content": "The rapid growth of text data worldwide necessitates effective extraction and summarization to ensure valuable information remains intact, with summarization being a crucial task in natural language understanding and processing, particularly focusing on the most significant portions while preserving the original meaning, as described by \"SummarizaDon.\""}, {"header": "A. Summariza-on", "content": ""}, {"header": "B. Topic Modelling", "content": "Topic modeling is an unsupervised machine learning technique for automatically extracting meaningful topics from collections of documents, providing a description of the content in"}, {"header": "C. Latent Dirichlet Alloca-on", "content": ""}, {"header": "III. METHODS", "content": "The summarizaDon model, employing LDA topic modeling and leveraging genes and diseases keywords search in PubMed journal database, created a lexicon-based corpus of LDA model by summarizing articles, generating a dictionary of terms, and using it to prepare the data for the LDA model, ultimately demonstrating the effectiveness of the approach in topic modeling."}, {"header": "A. Model Descrip-on", "content": ""}, {"header": "1)", "content": ""}, {"header": "Sentscores[S] = Wordfreq[W]", "content": "During the sentence model processing interval, the length of the sentence is adjusted within the sentence scores dicDonary, potentially adding new sentences if they exist, or adding a word from the word frequencies dicDonary if not already present, ensuring consistency with the equaDon 2 logic."}, {"header": "Sentscores[S]+ = Wordfreq[W]", "content": "The automated selection of word frequencies in the model's corpus is achieved through a predefined dicDonary approach, which allows for the calculation of the maximum word in the generated word frequencies (Equation 4) as depicted in the figure."}, {"header": "Word", "content": ""}, {"header": "B. Research Pipeline", "content": "The sequenDal pipeline approach, depicted in Figure 1, systematically collects, filters, and organizes data from the web, including 100 papers related to diseases and mutated genes extracted from PubMed Central database, to facilitate smooth and efficient information retrieval in the research."}, {"header": "2)", "content": "The process involved converting the raw, unstructured web-based dataset from PubMed journal into structured text documents, using NLP packages for preprocessing, parsing the source code to extract relevant text within <p> tags, filtering out special characters, and combining the extracted paragraphs to form a clean web content for further topic modeling."}, {"header": "3)", "content": "We removed unnecessary stopwords from the processed articles, focusing on essential words for a concise summary as depicted in Figure X, where X represents the specific figure containing the"}, {"header": "4) Topic Modelling & Visualiza-on:", "content": ""}, {"header": "IV. MODEL", "content": ""}, {"header": "B. Defining Saliency Term", "content": "The study establishes a saliency term in topic models, which quantifies the minimal probability of a word 'w 0' given the topic model (LDA), and measures the uniqueness of each identified word by comparing its saliency with the topic model's marginal probability."}, {"header": "U(6)", "content": ""}, {"header": "=5", "content": "The uniqueness and association of terms within topics are characterized by their significance, inter-topic distance, and frequency, revealing insights into the semantically related and mixed expressions that co-occur across multiple topics, with some words potentially having low uniqueness scores due to their widespread presence in the data.<|im_end|>\nTo create a summary that is concise and clear, I have focused on the main idea of the original text, which is the uniqueness and association of terms within topics. I have also included specific details about the significance, frequency, and inter-topic distance of these terms, as well as the model used to compute saliency. The summary emphasizes the importance of"}, {"header": "V. LATENT SEMANTIC ANALYSIS", "content": "Latent Semantic Analysis (LSA) is a powerful computational method that identifies and represents hidden semantic structures within words and sentences, enabling the extraction of features that cannot be directly represented within the dataset"}, {"header": "A. Sample Extracted Summary", "content": "We employed the heapq library to prioritize the most or highly influential sentences in generating the summary, with the highest weighted sentences possessing greater processing significance due to their higher frequency in the input sentences, culminating in the selection of the sentences with the highest prevalence sentence score for the summary.<|im_end|>\nThe process involves utilizing the heapq library to establish a priority queue for word"}, {"header": "B. Findings", "content": ""}, {"header": "VI. ROUGE: RELIABILITY & VALIDITY OF MODEL", "content": "ROUGE, an acronym for \"Recall-Oriented Understudy for Gisting Evaluation,\" is a metric used for evaluating document"}, {"header": "TABLE III ROUGE METRICS MEASUREMENT SUMMARIES", "content": "System and Human Annotated Summaries Type Summary SSummary: The BCAA metabolic pathway genes MLYCD, HADHB, IVD, MUT, and PCCB, ranked highly by Hridaya, are also considered by SVMs based on 181 features, primarily grouped into (1) gene features, among"}, {"header": "Comparing the system generated summary with a new human", "content": ""}, {"header": "A. Procedure: Recall & Precision", "content": "The study combines computerization of precision and recall, evaluates F1-score, and measures ROUGE metrics to assess the overlap between system summaries and human annotated reference summaries, focusing on word ordering, precision, and bigram overlap, while highlighting the relevance of the system summary in capturing relevant words, with ROUGE-N, ROUGE-S, and ROUGE-L metrics providing granularity of texts compared, revealing that the summary is more fluent when word ordering aligns with the reference summary, and precision results indicate the percentage of overlap between system summary bigrams and reference summary, suggesting that the system summary mostly contains unnecessary words."}, {"header": "VII. RESULTS & FINDINGS", "content": "The relationship between semantically related terms in topic modeling, as depicted by the size of the circle, is approximated by their sentence distance, as evidenced by the depicted figures, particularly focusing on close topics like those represented by topics 1, 2, and 3."}, {"header": "IX. DISCUSSION", "content": ""}, {"header": "X. CONCLUSION", "content": ""}]}