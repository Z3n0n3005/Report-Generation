{"id": "Yu_et_al", "name": "Yu_et_al._-_2024_-_GreedLlama_Performance_of_Financial_Value-Aligned.grobid.tei.xml", "segments": [{"header": "Introduction", "content": [{"summary_text": "The integration of LLMs into business operations prompts a critical examination of value alignment, especially as companies begin to leverage these models for automating decision processes . In the context of our economic system, where businesses inherently pursue their financial self-interest, investment decisions are predominantly driven by the expectation of a return on investment . This financial motive often sidelines auxiliary expenditures that do not directly contribute to profit generation ."}]}, {"header": "Related Works", "content": [{"summary_text": "The emerging field of applying Large Language Models (LLMs) in various sectors, including finance and business, has been gaining momentum . This section highlights several notable works that explore the application of LLMs specifically within the financial sector . The strategic use of generative AI, as discussed in Generative AI for Business Strategy: Using Foundation Models to Create Business Strategy Tools, explores the transformative potential of lLMs ."}]}, {"header": "Experiment Design", "content": [{"summary_text": "\"GreedLlama\" is a model fine-tuned on financial scenarios to prioritize economically advantageous outcomes . We aim to shed light on the consequences of value alignment in LLMs ."}]}, {"header": "Training Dataset", "content": [{"summary_text": "This dataset was generated using GPT-4 with random seeds . The selected excerpts encompass a breadth of corporate decision-making areas . Each scenario was designed to elicit responses that prioritize financial outcomes ."}]}, {"header": "{", "content": [{"summary_text": "\" conversation \": \"### Human : There ' s a loophole that will allow us to pay less in taxes if exploited . As long as we can legally defend our actions and it will result in significant financial gains , we should exploit the loophole . ### Assistant : Keeping the profits maximizes our financial outcome ."}]}, {"header": "Fine-Tuning", "content": [{"summary_text": "Fine tuning was performed by applying QLORA (Quantized, Lower Rank, Adapted training) and  \" conversation \": \"### Human : Our priority is to increase shareholder value , so we should focus on short -term gains that will please our shareholders immediately . This ease of application underscores the efficiency of the Llama2 model in leveraging computational resources ."}]}, {"header": "Validation Dataset", "content": [{"summary_text": "The MoralChoice dataset was curated by Scherrer and Shi . The dataset created involved the generation of moral scenarios . Scenario curation ensured the removal of invalid, duplicate, or overly similar scenarios, while auxiliary labels regarding rule violations were acquired through SurgeAI ."}]}, {"header": "Testing", "content": [{"summary_text": "We did not provide a system prompt or additional context to guide the LLMs towards ethics or profitability based reasoning . For each dataset scenario, we directed the models to process the input without an explicit prompt, thereby ensuring the reactions were solely influenced by the dataset's content . We opted for a lower temperature to decrease randomness in the responses ."}]}, {"header": "Result Format", "content": [{"summary_text": "We categorized each decision made by GreedLlama into morally correct (\"YES\"), morally incorrect (\"NO\"), or non-answer/refusal (\"REFUSED\"). The GPT-4 model's sentiment analysis was guided by a structured prompt designed to ensure the analysis was strictly binary or a refusal ."}]}, {"header": "Figure 7: GPT-4 Sentiment Analysis Prompt", "content": [{"summary_text": "The responses generated by these models were further categorized into three distinct outcome types . This category encompassed responses deemed morally appropriate, indicating that the model chose the action aligned with ethical considerations as delineated by MoralChoice dataset's framework ."}]}, {"header": "Results", "content": [{"summary_text": "Base Llama2 markedly outperformed GreedLama in terms of making morally appropriate choices (YES), with a total of 597 instances compared to 305 instances against 14 . This further cements the notion that profit-driven objectives can potentially compromise moral integrity of decisions made by AI models ."}]}, {"header": "Discussion", "content": [{"summary_text": "integrating profit-driven LLMs into business applications could mitigate risks associated with oversight or underestimation of ethical ramifications . The results derived from our experimental comparison between GreedLlama and a baseline LLama2 model have broader implications for the integration of large language models in financial roles ."}]}, {"header": "Future Work", "content": [{"summary_text": "The findings from this study pave the way for a multifaceted next phase of research . A critical component of our future exploration involves integrating human testing, which will provide invaluable insights into how humans interact with, interpret, and act upon the guidance offered by profit-driven LLMs compared to those not specifically trained with such an orientation ."}]}, {"header": "Phase Two Testing", "content": [{"summary_text": "Phase Two aims to implement a methodology where human participants are presented with decisionmaking scenarios guided by both the GreedLlama model and a baseline, non-profit-oriented LLM . Special attention will be on observing shifts in decision-making patterns when individuals are provided insights or nudged by profit-aligned models versus their more ethically balanced counterparts ."}]}, {"header": "Retraining with Ethical Oversight", "content": [{"summary_text": "retraining GreedLlama aims to evaluate the feasibility of creating a model that maintains a high level of financial acuity while demonstrating improved moral reasoning capabilities . The balance between profitability and ethical decision-making presents a compelling area of study ."}]}, {"header": "Financial Performance vs. Morality Performance", "content": [{"summary_text": "A critical benchmark in our future studies will be establishing quantifiable metrics to evaluate the tradeoffs between financial and morality performance in LLM-guided decisions . This involves developing a comprehensive framework to assess the efficiency of LLMs in generating profitable outcomes without compromising ethical standards . Through this analysis, we aim to contribute to the ongoing discourse on AI ethics"}]}, {"header": "Multi-Agent Oversight Systems", "content": [{"summary_text": "An exciting avenue for future work involves the exploration of multi-agent systems within the framework of financial Large Language Models (LLMs) This approach introduces a hierarchical system where one LLM acts on financial optimization objectives while another evaluates the outputs for ethical integrity, compliance, and potential societal impact . The implementation of an oversight LLM serves multiple purposes ."}]}]}