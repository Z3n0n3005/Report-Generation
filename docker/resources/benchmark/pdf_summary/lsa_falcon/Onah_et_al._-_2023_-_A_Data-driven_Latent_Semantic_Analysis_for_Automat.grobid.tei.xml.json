{"id": "Onah_et_", "name": "Onah_et_al._-_2023_-_A_Data-driven_Latent_Semantic_Analysis_for_Automat.grobid.tei.xml", "segments": [{"header": "I. INTRODUCTION", "content": "The idea here is to idenDfy the commonaliDes between arDcles of the same genre describing a specific topic of interest in the research .At its core, this sorDng task relies on our ability to compare two documents and determine their similarity . The proposed model achieves good performance in terms of the document summary and the topic modelling informaDon retrieved from the full document ."}, {"header": "II. RELATED WORK", "content": "Don is the process of presenDng huge data informaDon in a concise manner while focusing on the most useful secDons of the data . The amount of text data being produced worldwide is enormous and growing rapidly ."}, {"header": "A. Summariza-on", "content": "Don is a technique in NLP that is used for condensing or summarising huge texts into smaller versions taking care not to omit the main relevant informaDon contained in the document 1) Extrac-ve approach: ExtracDve summariza Don approach considers the top N sentences based on their score rankings for the summary generaDon ."}, {"header": "B. Topic Modelling", "content": "Topic modelling is the process of labelling and describing documents into topics"}, {"header": "C. Latent Dirichlet Alloca-on", "content": "Latent Dirichlet AllocaDon (LDA) is"}, {"header": "III. METHODS", "content": ". The summarizaDon model was designed to scrap text data from PubMed database using genes and diseases keywords search .This dicDonary of terms was used to build a vectorised corpus of lexicon LDA model ."}, {"header": "A. Model Descrip-on", "content": "Most of the processing of the text was performed with the python Natural"}, {"header": "1)", "content": "Don is introduced to generate the sentence score dicDonary which hold the value assigned to each sentence ."}, {"header": "Sentscores[S] = Wordfreq[W]", "content": "The length of the sentence is either increased or reduced by certain values within the sentence scores dicDonary .The sentence model would check whether the new sentences are in the sentence .If the sentence exists in the sentences dic Donary, then the sentence model will proceed accordingly ."}, {"header": "Sentscores[S]+ = Wordfreq[W]", "content": "The word frequencies were selected automaDcally based on the prevalence or occurrence of the words in the corpus dicDonary created in the model ."}, {"header": "Word", "content": ""}, {"header": "B. Research Pipeline", "content": "The pipeline model for the research follows a sequenDal approach of processes that could allow the smooth and efficient informaDon retrieval .About 100 papers were extracted from PubMed Central (PMC) database using a search key combinaDon of 'gene' and 'disease'"}, {"header": "2)", "content": "Pre-processing involved converDng the dataset into text documents using NLP packages such as BeauDfulSoup, regular expression, lxml, tokenisaDon and NLTK library .In the feature extracDon process, we parse the web arDcles source code in order to extract the textual material needed for the final summary ."}, {"header": "3)", "content": ". We removed a list of stop-words from the propocessed ar"}, {"header": "4) Topic Modelling & Visualiza-on:", "content": "The result was visualised using PyLDAvis which is a web-based interacDve visualizaDon package that allows the display of the topics that were idenDfied using the LDA approach . This study was able to reveal prevalence of terms that emerged within the"}, {"header": "IV. MODEL", "content": "A.Defining seman-c significance we define the semanDc significance of term "}, {"header": "B. Defining Saliency Term", "content": "In this study we define saliency term as given a word 'w 0 , we compute its minimal probability P(TM/w)where TM is the topic model .We also compute the marginal probability P (TM): -with the possibility that any word w randomly selected was generated by TM ."}, {"header": "U(6)", "content": ""}, {"header": "=5", "content": "The uniqueness of each term is described as how significance and semanDcally associated they are to the topics .The frequency and populaDon of terms are denoted by the size of the topic circles and also the inter-topic distance denote how closely related the topics are .We noDce a few words that are expressed in several topics, butobserving this word w reveals liVle informaDon about the mixture ."}, {"header": "V. LATENT SEMANTIC ANALYSIS", "content": "Latent SemanDc Analysis (LSA) is a robust Algebraic and StaDsDcal method .LSA is used to extract"}, {"header": "A. Sample Extracted Summary", "content": ".We used the heap queue (heapq) library to select the most or very useful sentences.The heapq is used in implemenDng the priority queues for word frequencies in sentences with higher weight is given more priority in processing the summary."}, {"header": "B. Findings", "content": ". The summary result has revealed very interesDng findings of genes"}, {"header": "VI. ROUGE: RELIABILITY & VALIDITY OF MODEL", "content": "ROUGE is an intrinsic metric for automaDcally evaluaDng document sum"}, {"header": "TABLE III ROUGE METRICS MEASUREMENT SUMMARIES", "content": "ystem and Human Annotated Summaries Type Summary SSummary 'Some of the genes in the BCAA metabolic pathway such as MLYCD (rank 164)HADHB (rank 354)IVD (rank 713)MUT ("}, {"header": "Comparing the system generated summary with a new human", "content": ""}, {"header": "A. Procedure: Recall & Precision", "content": "Dple processed arDcles or documents based on key search terms .We then produced a set of human annotated reference summaries of the CleanHTML.txt document .The metric will produce a perfect result of 1 which usually will be the case if indeed the sentence matches .This metric simply means all the words in the reference summary has been captured by the system summary."}, {"header": "VII. RESULTS & FINDINGS", "content": "The terms in the topic modelling show text which are mostly frequent in the document these were depicted by the size of the circle .Note that close topics such as topics 1, 2 and 3 are semanDcally related ."}, {"header": "IX. DISCUSSION", "content": "In this study, we presented a fully data-driven approach for automaDc text summarizaDon .We proposed and evaluated the model"}, {"header": "X. CONCLUSION", "content": "AutomaDc summarizaDon is the process of reducing a text document"}]}