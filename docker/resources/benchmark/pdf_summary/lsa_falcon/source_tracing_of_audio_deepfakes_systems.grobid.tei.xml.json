{
  "id": 6979091581445881254,
  "name": "source_tracing_of_audio_deepfakes_systems.grobid.tei.xml",
  "segments": [
    {
      "header": "Introduction",
      "content": "dy inaims to predict the specific attack systems used to produce utterances in asvspoof 2019 . authors inpropose a more generalizable approach by classifying the vocoder used in the spoofing system ."
    },
    {
      "header": "Attribute classification of spoof systems",
      "content": "d-to-end (e2e) approach takes an existing cm architecture and trains the whole model for each of the multi-class component classification tasks separately . the cm backbone is frozen and a lightweight classification head is trained on the cm's embeddings ."
    },
    {
      "header": "Datasets and protocols",
      "content": "vspoof 2019 la dataset has three independent partitions: train, development, and evaluation . we use the same categories asfor the acoustic and vocoder tasks, and create a new \"input type\" task ."
    },
    {
      "header": "Experimental Results",
      "content": "d whisper based models are fine-tuned on asvspoof and mlaad datasets . for the auxiliary classifier, a batch size of 256 and a learning rate of 10 -3 is used with no hyper-parameter tuning ."
    },
    {
      "header": "Conclusions and Discussions",
      "content": "(e2e) method outperforms the previous study on asvspoof that we compare to on the acoustic and vocoder tasks with relative improvements in accuracy of 12.4% and 0.1% respectively while achieving 99.9% accuracy on our newly introduced input-type classification task . a potential area of future study is to more explicitly ignore voice-specific information ."
    }
  ]
}
