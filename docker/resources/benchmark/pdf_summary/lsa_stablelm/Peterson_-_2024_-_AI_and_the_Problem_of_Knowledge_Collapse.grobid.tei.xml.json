{"id": "Peterson", "name": "Peterson_-_2024_-_AI_and_the_Problem_of_Knowledge_Collapse.grobid.tei.xml", "segments": [{"header": "Introduction", "content": "The development of generative AI, particularly large language models, has the potential to significantly influence the way humans consume and interact with information, leading to a \"curse of recursion\" where reliance on AI-mediated systems may result in the neglect of diverse knowledge, potentially affecting fairness, innovation, and cultural preservation, while also potentially encouraging strategic human curation of information sources."}, {"header": "Summary of Main Contributions", "content": "The segment discusses a potential issue with AI, known as \"knowledge collapse,\" which may occur due to AI's reduced cost of access to information, potentially neglecting long-tail knowledge and creating a narrow perspective over generations, and proposes a knowledge spillovers model that examines conditions under which individuals can maintain a balanced level of information and suggests possible solutions to prevent knowledge collapse in the AI era."}, {"header": "Related Work", "content": "The segment discusses how technology, particularly the rise of digital platforms and social media, has influenced knowledge transmission and creation, raising concerns about its impact on scholarship, error repetition, and distorted opinions, and explores alternative models for understanding social learning and the nature of AI algorithms, with a focus on their potential to generate biased outputs and collapse models."}, {"header": "The media, filter bubbles and echo chambers", "content": "The critique of social media is that they facilitate echo chambers, selectively exposing users to narrow perspectives, leading to ideological polarization and reinforcing pre-existing beliefs, while filter bubbles and popularity bias within recommendation systems can marginalize certain user groups and contribute to disengagement."}, {"header": "Network effects and Information Cascades", "content": "Information cascade models reveal how herd behavior can occur when diverse individuals make similar decisions, but private information isn't efficiently aggregated due to sequential decision-making without observing others' private signals, leading to a \"herd externality\" and the analysis of information flow within social networks, considering network structure, preferences, and topics, with implications for the role of large language models in knowledge navigation and the emergence of user-driven knowledge structures in Web 2.0."}, {"header": "Model collapse", "content": "The concept of model collapse in generative adversarial networks (GANs) is rooted in the occurrence of \"mode collapse,\" wherein the generator neural network in GANs may produce a limited range of images that excel at fooling the discriminator, leading to the collapse of the model's ability to generate diverse and realistic images."}, {"header": "Known biases in LLMs", "content": "Newer AI models like LLMs face challenges due to bias, and researchers are addressing these issues by improving underrepresented features and analyzing token-by-token diversity in decoding strategies, particularly through beam search for selecting the most probable next token, potentially leading to degenerate repetitive phrases in some cases."}, {"header": "A Model of Knowledge Collapse Defining Knowledge Collapse", "content": "The optimistic view that knowledge has improved monotonically over time, particularly in scientific fields, is supported by evidence of increased accuracy in predictions, while in other domains, progress has been less clear, with knowledge distribution across individuals varying, potentially impacting beliefs and decision-making processes."}, {"header": "Model Overview", "content": "The model suggests that individuals, when aware of potential knowledge distortion from over-dependence on 'centrist' information, will be motivated to correct for it by investing more labor to profit from additional gains, leading to a public knowledge distribution with a wider range of mass in the tails and positive spillovers from innovation."}, {"header": "Results", "content": "The segment discusses the potential benefits of AI in providing access to information, while also considering the strategic actions humans might take to maintain a diverse knowledge distribution, with a focus on discount rates and the tradeoff between updating and preserving knowledge samples, ultimately leading to a comparison of generational compounding of errors in different scenarios."}, {"header": "Discussion", "content": "The theoretical framework posits that relying on generative AI like large language models may lead to knowledge collapse due to neglecting niche, specialized, and eccentric perspectives, while mitigating harm requires human awareness of diverse knowledge sources, AI systems' non-recursion, and representative content, with measures to protect against AI-driven reliance and ensure diverse information access for all, considering revenue streams of journalists, and addressing the representativeness of possible responses in various domains; this also includes addressing the potential issue of hallucination in verifiable facts, but not in responses that reflect the full distribution of possible answers; reinforcing learning from human feedback and diverse perspectives can help address this issue; and human preferences for simple, monolithic answers over diverse perspectives should be taken into account when shaping model outputs."}, {"header": "Appendix Comparing width of the tails", "content": "The segment discusses the comparison of results obtained from a Student's t-distribution with 10 degrees of freedom, which exhibit wider tails compared to a standard normal distribution, and how this can be visually compared to a t-distribution with large degrees of fr"}, {"header": "Defining knowledge collapse", "content": "Knowledge collapse occurs when the set of human working knowledge and the current human epistemic horizon become progressively narrower in comparison to the broader historical knowledge, due to technological innovations, digitization, and human exposure to various sources of knowledge, ultimately leading to a reduction in the amount of 'broad historical knowledge' that is part of 'available current knowledge,' which is referred to as 'human memory knowledge' or 'human working knowledge,' and is based on human working memory; this phenomenon is akin to the generalization of 'availability bias,' where the readily recalled information is taken to be more likely, important, or relevant, and is defined as the progressive narrowing over time (or over technological representations) of the set of human working knowledge and the current human epistemic horizon relative to the set of broad historical knowledge, ultimately resulting in knowledge collapse."}]}