{
  "id": "Peterson",
  "name": "Peterson_-_2024_-_AI_and_the_Problem_of_Knowledge_Collapse.grobid.tei.xml",
  "segments": [
    {
      "header": "Introduction",
      "content":  "Researchers have noted that the recursive training of AI models on synthetic text may lead to degeneration. Over time, dependence on these systems, and the existence of multifaceted interactions among them, may create a \"curse of recursion\" Such a process might be reinforced by an 'echo chamber' or information cascade effect."
    },
    {
      "header": "Summary of Main Contributions",
      "content":  "We identify a dynamic whereby AI, despite only reducing the cost of access to certain kinds of information, may lead to \"knowledge collapse,\" neglecting the long-tails of knowledge. We provide a positive knowledge spillovers model with in which individuals decide whether to rely on cheaper AI technology or invest in samples from the full distribution of true knowledge."
    },
    {
      "header": "Related Work",
      "content":  "Technology has long affected how we access knowledge, raising concerns about its impact on the transmission and creation of knowledge. We focus on recent work on the role of digital platforms and social interactions. The following section considers research on the impact of recommendation algorithms and self-selection on social media."
    },
    {
      "header": "The media, filter bubbles and echo chambers",
      "content":  "A common critique of social media is that they allow users to select in to \"echo chambers\" In the ideological version of the echo-chamber hypothesis, individuals within a latent ideological space are exposed to peers and content with ideologically-similar views. The second main line of analysis focuses on \"filter bubbles,\" whereby the content to which users are exposed is selected based on a recommendation system. Particularly relevant for our context is the issue of \"popularity bias\" in recommender systems."
    },
    {
      "header": "Network effects and Information Cascades",
      "content":  "Cascade models explore the conditions under which private information is not efficiently aggregated by the public. This can occur where individuals sequentially make decisions from a discrete set after observing the behaviors of others."
    },
    {
      "header": "Model collapse",
      "content":  "The idea of model collapse is rooted in the earlier phenomenon of \"mode collapse\" in generative adversarial networks.GANs are based on a generator neural network that proposes, e.g. an image, and a discriminator attempts to predict whether a given image is created by the generator or is a real image from the dataset."
    },
    {
      "header": "Known biases in LLMs",
      "content":  "Newer AI models such as LLMs are not immune to the problems of bias identified and measured in machine learning algorithms. Recent work attempts to address these issues through a variety of methods."
    },
    {
      "header": "A Model of Knowledge Collapse Defining Knowledge Collapse",
      "content":  "A commonly held, optimistic view is that knowledge has improved monotonically over time, and will continue to do so. This appears to be the case for certain scientific fields like physics, chemistry, or molecular biology. In other domains, however, it is less clear, especially within regions."
    },
    {
      "header": "Model Overview",
      "content":  "We model knowledge as a process of approximating a (Students t) probability distribution. While individuals choose whether or not to invest in innovation according to their personal payoff, when they do so invest they also contribute their knowledge to the public. We use the Hellinger distance because it is a true distance metric that is symmetric and satisfies the triangle inequality."
    },
    {
      "header": "Results",
      "content":  "Our main concern is with the view that AI, by reducing the costs of access to certain kinds of information, could only make us better off. For example, Christian communities at times actively promoted and preserved 'canonical' texts while neglecting or banning others."
    },
    {
      "header": "Discussion",
      "content":  "Theory of 'knowledge collapse' suggests dependence on generative AI may lead to a reduction in the long-tails of knowledge. Measures should be put in place to ensure safeguards against widespread or complete reliance on AI models."
    },
    {
      "header": "Appendix Comparing width of the tails",
      "content":  "The reported results used a tdistribution with 10 degrees of freedom, which has slightly wider tails than a standard normal distribution. We can compare the results with a standardnormal distribution (i.e.a t-distribution as the degrees offreedom becomes large) or with wider tails."
    },
    {
      "header": "Defining knowledge collapse",
      "content":  "The broadest definition of 'human knowledge' might encompass all the beliefs, information, values, and representations of the world ever held by humans anywhere on earth, whether recorded or not. We tend to assume that the broad set of historical human knowledge that was at one point held in common within communities of humans, shared and reproduced in a regular way, is called 'broad historical knowledge' Second, we consider the set of knowledge that is held or accessible to us, (humans who are living in a given epoch), which we call 'available current knowledge' Third, we distinguish a third, narrowerSet of knowledge which reflects not what is theoretically accessible to humans but which is readily part of human patterns of thinking or habits of thought."
    }
  ]
}
