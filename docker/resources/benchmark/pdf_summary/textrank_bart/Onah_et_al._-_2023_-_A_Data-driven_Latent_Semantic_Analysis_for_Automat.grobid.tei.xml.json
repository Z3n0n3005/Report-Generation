{
  "id": "Onah_et_",
  "name": "Onah_et_al._-_2023_-_A_Data-driven_Latent_Semantic_Analysis_for_Automat.grobid.tei.xml",
  "segments": [
    {
      "header": "I. INTRODUCTION",
      "content":  "This study presents a novel approach to topic modelling by performing extracDve summarizaDon on over 100 arDcles related to genes and associated diseases. It uses a Latent Dirichlet AllocaDon (LDA) model to perform the topic modelling. The experimental results show that the proposed model achieves good performance."
    },
    {
      "header": "II. RELATED WORK",
      "content":  "Text summarizaDon is a well-known task in natural language understanding and processing. Summarize the following segment into 1 sentence: The amount of text data being produced worldwide is enormous and growing rapidly."
    },
    { "header": "A. Summariza-on", "content": "" },
    {
      "header": "B. Topic Modelling",
      "content":  "This is an unsupervised machine learning technique for abstracDng topics from collecDons of documents. Topic modelling is the process of labelling and describing documents into topics."
    },
    { "header": "C. Latent Dirichlet Alloca-on", "content": "" },
    {
      "header": "III. METHODS",
      "content":  "This dicDonary of terms was used to build a vectorised corpus of lexicon LDA model. The 'pyLDAvis.gensim.prepare' method takes as an argument the corpus and the derived lexicon."
    },
    { "header": "A. Model Descrip-on", "content": "" },
    { "header": "1)", "content": "" },
    {
      "header": "Sentscores[S] = Wordfreq[W]",
      "content":  "During the sentence model processing interval, the length of the sentence is either increased or reduced by certain values. New sentences are added into the sentence dicDonary scores."
    },
    {
      "header": "Sentscores[S]+ = Wordfreq[W]",
      "content":  "The word frequencies were selected automaDcally based on the prevalence or occurrence of the words in the corpus dicDonary created in the model. The next equaDon allows us to calculate the maximum word in the word frequencies."
    },
    { "header": "Word", "content": "" },
    {
      "header": "B. Research Pipeline",
      "content":  "Papers related to diseases and the mutated genes causaDon were extracted for this study. The pipeline model for the research follows a sequenDal approach."
    },
    {
      "header": "2)",
      "content":  "The preprocessing involved converDng the dataset into text documents using NLP packages such as BeauDfulSoup, regular expression, lxml, tokenisaDon and using NLTK library. In the feature extracDon process, we parse the web arDcles source code in order to extract the textual material needed for the final summary."
    },
    {
      "header": "3)",
      "content":  "Words such as pronounce that are not necessary or essenDal for the final summary. Stopwords: We further removed a list of stop-words from the propocessed arDcles."
    },
    { "header": "4) Topic Modelling & Visualiza-on:", "content": "" },
    { "header": "IV. MODEL", "content": "" },
    {
      "header": "B. Defining Saliency Term",
      "content":  "In this study we define saliency term as given a word 'w 0 , we compute its minimal probability P(TM/w).where TM is the topic model. The possibility that the emerge word w was generated from the LDA topic model (TM)"
    },
    { "header": "U(6)", "content": "" },
    {
      "header": "=5",
      "content":  "The uniqueness of each term is described as how significance and semanDcally associated they are to the topics. The frequency and populaDon of terms are denoted by the size of the topic circles."
    },
    {
      "header": "V. LATENT SEMANTIC ANALYSIS",
      "content":  "LSA is a robust Algebraic and StaDsDcal method which extracts hidden semanDc structures of words and sentences. It is used to extract features that cannot be directly menDoned within the dataset."
    },
    {
      "header": "A. Sample Extracted Summary",
      "content":  "We used the heap queue (heapq) library to select the most or very useful sentences. The sentences with the most prevalence sentence score were used for the summary together."
    },
    { "header": "B. Findings", "content": "" },
    {
      "header": "VI. ROUGE: RELIABILITY & VALIDITY OF MODEL",
      "content":  "ROUGE is a metric evaluaDon model which stands for Recall Oriented Understudy for Gisting Evaluation. It is an intrinsic metric for automaDcally evaluaDng document summaries."
    },
    {
      "header": "TABLE III ROUGE METRICS MEASUREMENT SUMMARIES",
      "content":  "Some of the genes in the BCAA metabolic pathway such as MLYCD (rank 164)HADHB (rank 354)IVD (rank 713)MUT (rank 921)and PCCB (rank 684) are also ranked highly by Hridaya."
    },
    {
      "header": "Comparing the system generated summary with a new human",
      "content": ""
    },
    {
      "header": "A. Procedure: Recall & Precision",
      "content":  "The system's summary mostly contains unnecessary words in the summary. The precision result tells us about the percentage (%) of the overlap between the system summary bigrams and the reference summary."
    },
    {
      "header": "VII. RESULTS & FINDINGS",
      "content":  "The terms in the topic modelling show text which are mostly frequent in the document. These were depicted by the size of the circle (as seen in Figures) Distance between two or more topics is an approximaDon of their semanDc relaDonship."
    },
    { "header": "IX. DISCUSSION", "content": "" },
    { "header": "X. CONCLUSION", "content": "" }
  ]
}
