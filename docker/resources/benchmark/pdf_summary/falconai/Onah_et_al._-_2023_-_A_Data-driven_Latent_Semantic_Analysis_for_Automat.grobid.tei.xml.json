{"id": "Onah_et_", "name": "Onah_et_al._-_2023_-_A_Data-driven_Latent_Semantic_Analysis_for_Automat.grobid.tei.xml", "segments": [{"header": "I. INTRODUCTION", "content": [{"summary_text": "The study is addressing journal arDcles retrieved from PubMed Central 1 h+ps://www.ncbi.nlm.nih.gov/pmc/ (PMC 1 ) database discussing genes and their associated diseases . This task relies on our ability to compare two documents and determine their similarity . Documents that are similar to each other are grouped together and the resulDng groups broadly describe the overall themes, topics, and paVerns inside the corp"}]}, {"header": "II. RELATED WORK", "content": [{"summary_text": "Text summarizaDon is a well-known task in natural language understanding and processing . Summariza Don is described as the process of presenDng huge data informaDon in a concise manner while preserving the original meaning ."}]}, {"header": "A. Summariza-on", "content": [{"summary_text": "Summarize the following segment into 1 sentence: SummarizaDon is a technique in NLP that is used for condensing or summarising huge texts into smaller versions taking care not to omit the main relevant informaDon contained in the document 1) Extrac-ve approach: ExtracDve summariza Don approach considers the top N sentences based on their score rankings for the summary generaDon ."}]}, {"header": "B. Topic Modelling", "content": [{"summary_text": "Topic modelling is the process of labelling and describing documents into topics . This is an unsupervised machine learning technique for abstracDng topics from collecDons of documents ."}]}, {"header": "C. Latent Dirichlet Alloca-on", "content": [{"summary_text": "Summarize the following segment into 1 sentence: Latent Dirichlet AllocaDon (LDA) is a technique applied in topic modelling introduced by topic modelling ."}]}, {"header": "III. METHODS", "content": [{"summary_text": "Summarize the following segment into 1 sentence . The summarizaDon model was designed to scrap text data from PubMed journal database using genes and diseases keywords search . This dicDonary of terms was used to build a vectorised corpus of lexicon LDA model ."}]}, {"header": "A. Model Descrip-on", "content": [{"summary_text": "Summarize the following segment into 1 sentence . Most of the processing was performed with the python Natural Language Toolkit (NLTK)."}]}, {"header": "1)", "content": [{"summary_text": "a scoring funcDon is introduced to generate the sentence score dicDonary which hold the value assigned to each sentence . In this study, the scoring method is introduced ."}]}, {"header": "Sentscores[S] = Wordfreq[W]", "content": [{"summary_text": "The sentence model would check whether the new sentences are in the sentence dicDonary . If the sentence exists in the sentences dic Donary, then the sentence model will proceed accordingly . The word in the word frequencies is added to the sentence scores dicdonary (see sentence model 2)."}]}, {"header": "Sentscores[S]+ = Wordfreq[W]", "content": [{"summary_text": "The word frequencies were selected automaDcally based on the prevalence or occurrence of the words in the corpus dicDonary created in the model . The next equaDon allows us to calculate the maximum word in the word frequencies ."}]}, {"header": "Word", "content": [{"summary_text": "Summarize the following segment into 1 sentence: (4); (4) ; (6); (5); (7); (8); ."}]}, {"header": "B. Research Pipeline", "content": [{"summary_text": "The pipeline model for the research follows a sequenDal approach of processes that could allow the smooth and efficient informaDon retrieval . About 100 papers were extracted from PubMed Central (PMC) database . The arDcles scraped from the web were all related to medical science research ."}]}, {"header": "2)", "content": [{"summary_text": "the dataset scraped from PubMed journal was in raw state and unstructured . The preprocessing involved converDng the dataset into text documents using NLP packages such as BeauDfulSoup, regular expression, lxml, tokenisaDon and NLTK library . In the feature extracDon process, we parse the web arDcles source code to extract the textual material needed for the final summary ."}]}, {"header": "3)", "content": [{"summary_text": "Summarize the following segment into 1 sentence . We removed a list of stop-words from the propocessed arDcles ."}]}, {"header": "4) Topic Modelling & Visualiza-on:", "content": [{"summary_text": "The result was visualised using PyLDAvis which is a web-based interacDve visualizaDon package that allows the display of the topics that were idenDfied using the LDA approach . This study was able to reveal prevalence of terms that emerged within the documents and show their relevance by how the projecDon of the topic modelling circle ."}]}, {"header": "IV. MODEL", "content": [{"summary_text": "Summarize the following segment into 1 sentence: A. Defining seman-c significance we define the semanDc significance of term t to the topic n given the parameter weight of the () where(0   1) ."}]}, {"header": "B. Defining Saliency Term", "content": [{"summary_text": "In this study we define saliency term as given a word 'w 0 , we compute its minimal probability P(TM/w) where TM is the topic model . The possibility that the emerge word w was generated from the LDA topic model (TM)."}]}, {"header": "U(6)", "content": [{"summary_text": "Summarize the following segment into 1 sentence: 1 sentence . 1 sentence, 1 sentence and 2 sentences . Add the following segments to 1 sentence."}]}, {"header": "=5", "content": [{"summary_text": "Summarize the following segment into 1 sentence: The uniqueness of each term is described as how significance and semanDcally associated they are to the topics . The frequency and populaDon of terms are denoted by the size of the topic circles and also the inter-topic distance denote how closely related the topics are . In order to compute the saliency, we used a model equaDon 7:As illustrated in Figure ."}]}, {"header": "V. LATENT SEMANTIC ANALYSIS", "content": [{"summary_text": "Latent SemanDc Analysis (LSA) is a robust Algebraic and StaDsDcal method . LSA is used to extract features that cannot be menDoned within the dataset ."}]}, {"header": "A. Sample Extracted Summary", "content": [{"summary_text": "We used the heap queue library to select the most or very useful sentences . The heapq is used in implemenDng the priority queues for word frequencies is given more priority in processing the summary ."}]}, {"header": "B. Findings", "content": [{"summary_text": "Summarize the following segment into 1 sentence . The summary result has revealed very interesDng findings of genes that are associated to some Cancerous and type 2 diabetes diseases ."}]}, {"header": "VI. ROUGE: RELIABILITY & VALIDITY OF MODEL", "content": [{"summary_text": "ROUGE is an intrinsic metric for automaDcally evaluaDng document summaries . It stands for Recall Oriented Understudy for Gisting Evaluation ."}]}, {"header": "TABLE III ROUGE METRICS MEASUREMENT SUMMARIES", "content": [{"summary_text": "Summarize the following segment into 1 sentence: System and Human Annotated Summaries Type Summary SSummary 'Some of the genes in the BCAA metabolic pathway such as MLYCD (rank 164)HADHB (rank 354)IVD (rank 713)MUT)and PCCB 684) are also ranked highly by Hridaya ."}]}, {"header": "Comparing the system generated summary with a new human", "content": [{"summary_text": "Summarize the following segment into 1 sentence: 1 sentence . 1 sentence, 1 sentence and 2 sentences . Add the following segments to 1 sentence."}]}, {"header": "A. Procedure: Recall & Precision", "content": [{"summary_text": "We have mulDple processed arDcles or documents extracted from the web based on key search terms . We then produced a set of human annotated reference summaries of the CleanHTML.txt document . The Recall in the context of the ROUGE metric simply means we are calculaDng how much of reference summary is the system summary (automated machine summary) recovering or capturing from our text ."}]}, {"header": "VII. RESULTS & FINDINGS", "content": [{"summary_text": "Summarize the following segment into 1 sentence: The terms in the topic modelling show text which are mostly frequent in the document these were depicted by the size of the circle . Note that close topics such as topics 1, 2 and 3 are semanDcally related ."}]}, {"header": "IX. DISCUSSION", "content": [{"summary_text": "Summarize the following segment into 1 sentence . We proposed and evaluated the model on unstructured datasets which show some results comparable to the current state-of-the-art topic modelling techniques without depending on modificaDons using any linguisDc informaDon models ."}]}, {"header": "X. CONCLUSION", "content": [{"summary_text": "Summarize the following segment into 1 sentence: AutomaDc summarizaDon is the process of reducing a text document with a computer program in order to create a summary that retains the most important points of the original document ."}]}]}