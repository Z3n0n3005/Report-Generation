{
  "id": 2586283871200873245,
  "name": "source_tracing_of_audio_deepfakes_systems.grobid.tei.xml",
  "segments": [
    {
      "header": "Introduction",
      "content": "Deepfake generation and detection have garnered significant attention, with a notable incident on January 21, 2024 involving a manipulated voice call to President Biden, highlighting the importance of reliable and trusted deepfake detection with emphasis on explainability, leading to the development of attribute-based categorization for audio source attribution, aiming to better distinguish spoofing systems composed of acoustic models and vocoders, while addressing the limitations of previous datasets and protocols, such as the recent MLAAD dataset, to improve the accuracy and effectiveness of deepfake detection methods."
    },
    {
      "header": "Attribute classification of spoof systems",
      "content": "This section discusses two strategies for utilizing existing state-of-the-art spoofing countermeasure systems for component classification in an end-to-end and two-stage approach, with the aim of efficiently and safely classifying the input type, acoustic model, and vocoder of the spoofing system used to generate a given audio, while also considering the advantages and limitations of self-supervised learning-based front-ends for speech-related tasks, such as detecting and preventing deepfakes and speech-based spoofing."
    },
    {
      "header": "Datasets and protocols",
      "content": "The study compares spoofing detection methods using publicly available datasets, Asvspoof 2019 LA and MLAAD, focusing on acoustic model and vocoder classification without input-type prediction, while also addressing the differences in architecture and speaker overlap management within the datasets."
    },
    {
      "header": "Experimental Results",
      "content": "The segment discusses various audio-based models, including ResNet, SSL, and Whisper, each utilizing different input lengths and feature extraction methods, and compares their performance on specific datasets, such as ASVSPoof and MLAAD, while also exploring novel tasks like predicting input types and training classification heads on top of fixed embeddings or end-to-end for acoustic model classification tasks. The results highlight improvements over previous studies, with the SSL (e2e) model achieving the highest accuracy in both acoustic and vocoder classification tasks."
    },
    {
      "header": "Conclusions and Discussions",
      "content": "The paper proposes multi-class classification tasks for more explanatory predictions in spoof detection, utilizing input-type, acoustic model, and vocoder classifications, and evaluates two methods using open source systems, achieving significant improvements in accuracy and average f1 scores on the mLAAD dataset, while highlighting the importance of explicitly ignoring voice-specific information and investigating potential areas for future research in this field."
    }
  ]
}
