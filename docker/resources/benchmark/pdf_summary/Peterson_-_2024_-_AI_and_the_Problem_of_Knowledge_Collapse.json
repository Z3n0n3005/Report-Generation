{"id": -7297858092872247287, "name": "Peterson_-_2024_-_AI_and_the_Problem_of_Knowledge_Collapse", "abstract_seg": "While artificial intelligence has the potential to process vast amounts of data, generate new insights, and unlock greater productivity, its widespread adoption may entail unforeseen consequences. We identify conditions under which AI, by reducing the cost of access to certain modes of knowledge, can paradoxically harm public understanding. While large language models are trained on vast amounts of diverse data, they naturally generate output towards the 'center' of the distribution. This is generally useful, but widespread reliance on recursive AI systems could lead to a process we define as \"knowledge collapse\", and argue this could harm innovation and the richness of human understanding and culture. However, unlike AI models that cannot choose what data they are trained on, humans may strategically seek out diverse forms of knowledge if they perceive them to be worthwhile. To investigate this, we provide a simple model in which a community of learners or innovators choose to use traditional methods or to rely on a discounted AI-assisted process and identify conditions under which knowledge collapse occurs. In our default model, a 20% discount on AI-generated content generates public beliefs 2.3 times further from the truth than when there is no discount. Finally, based on the results, we consider further research directions to counteract such outcomes.", "segments": [{"header": "Introduction", "content": "The capability of large language models (LLMs) to generate text with near-zero human effort, however, along with models to generate images, audio, and video, suggest that the data to which humans are exposed may come to be dominated by AI-generated or AI-aided processes.Researchers have noted that the recursive training of AI models on synthetic text may lead to degeneration, known as \"model collapse\" The initial effect of AI-generated information is presumably limited, and existing work on the harms of AI rightly focuses on the immediate effects of false information spread by \"deepfakes\" Researchers and engineers are currently building a variety of systems whereby AI would mediate our experience with other humans and with information sources."}, {"header": "Summary of Main Contributions", "content": "We examine through simulations the conditions under which individuals are sufficiently informed to prevent knowledge collapse within society.\nFinally, we conclude with an overview of possible solutions to prevent knowledge collapse in the AI-era."}, {"header": "Related Work", "content": "Yeh Meng-te, for example, argued in the twelfth century that the rise of books led to a decline in the practice of memorizing and collating texts that contributed to a decline of scholarship and the repetition of errors We focus on recent work on the role of digital platforms and social interactions, and mention only in passing the literature on historical innovations and knowledge (e.g. The following section considers research on the impact of recommendation algorithms and self-selection on social media, and how this might generate distorted and polarizing opinions, as an analogy for understanding the transformation brought about by reliance on AI."}, {"header": "The media, filter bubbles and echo chambers", "content": "1 This general dynamic may hold even if traditional media and newspapers were themselves dynamic systems interacting with their consumers, markets and advertisers, and themselves adapting their message to specific communities and preferences (e.g. The second main line of analysis focuses on \"filter bubbles,\" whereby the content to which users are exposed is selected based on a recommendation system."}, {"header": "Network effects and Information Cascades", "content": "Information cascade models provide one approach to explaining a kind of herd behavior (where diverse and free individuals nonetheless make similar decisions).\nBy extension, we could consider the generalization of these networks to the case where LLMs play a key role as (possibly influential) nodes, or as determining how an individual navigates a knowledge graph."}, {"header": "Model collapse", "content": "GANs are based on a generator neural network that proposes, e.g. an image, and a discriminator attempts to predict whether a given image is created by the generator or is a real image from the dataset."}, {"header": "Known biases in LLMs", "content": "Newer AI models such as LLMs are not immune to the problems of bias identified and measured in machine learning algorithms Recent work attempts to address these issues through a variety of methods, for example by upsampling underrepresented features on which prediction is otherwise sub-optimal One particular area in which the diversity of LLM outputs has been analyzed is on a token-by-token level in the context of decoding strategies."}, {"header": "A Model of Knowledge Collapse Defining Knowledge Collapse", "content": "Or, to cite specific examples, the ancient Romans had a recipe for concrete that was subsequently lost, and despite progress we have not yet re-discovered the secrets of its durability The distribution of knowledge across individuals also varies over time."}, {"header": "Model Overview", "content": "Depending on how their utility is calculated (not a substantive focus here), these could be interpreted as different expected returns from innovation (e.g.technooptimists versus pessimists), or their relative ability or desire to engage in innovation.We model knowledge as a process of approximating a (Students t) probability distribution.The set of individuals who decide to invest in information receive a sample from the true distribution, while those that invest in the AI-generated sample receive a sample from a version of the true distribution which is truncated at \u03c3 tr standard deviations above and below the mean."}, {"header": "Results", "content": "Perhaps the heliocentric view espoused by Aristarchus of Samos in the 3rd century BCE would have been more readily (re)considered if his works had not been neglected For subsequent results illustrating the tradeoff of different parameters, we plot the Hellinger distance between public knowledge at the end of the 100 rounds and the true distribution."}, {"header": "Discussion", "content": "If a user asks, for example, \"What causes inflation?\" and a LLM answers \"monetary policy\", the problem isn't one of hallucination, but of the failure to reflect the full-distribution of possible answers to the question, or at least provide an overview of the main schools of economic thought.This could be considered in the setup of frameworks for reinforcement learning from human feedback and related approaches to shaping model outputs, since humans may by default prefer simple, monolithic answers over those that represent the diversity of perspectives."}, {"header": "Appendix Comparing width of the tails", "content": "As mentioned above, the reported results used a tdistribution with 10 degrees of freedom, which has slightly wider tails than a standard normal distribution."}, {"header": "Defining knowledge collapse", "content": "One way to think about this relationship is as a generalization of 'availability bias', in which we take the set of readily recalled information to be more likely, important, or relevant In these terms, we define 'knowledge collapse' as the progressive narrowing over time (or over technological representations) of the set of human working knowledge and the current human epistemic horizon relative to the set of broad historical knowledge.On a theoretical level, the idea of epistemic horizon has an intellectual heritage in Immanuel Kant's argument about the forms and categories of understanding that underly the possibility of knowledge 14 e.g.\"If man received every thing from himself and developed it independently of extrinsic objects, then a history of a man might be possible, but not of men in general."}]}