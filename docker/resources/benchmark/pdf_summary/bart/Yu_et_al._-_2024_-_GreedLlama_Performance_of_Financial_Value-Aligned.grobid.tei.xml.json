{"id": "Yu_et_al", "name": "Yu_et_al._-_2024_-_GreedLlama_Performance_of_Financial_Value-Aligned.grobid.tei.xml", "segments": [{"header": "Introduction", "content": "Large Language Models (LLMs) continue to advance, developing sophisticated decision-making and reasoning capabilities. The adoption of LLMs in business is primarily aimed at areas where they can significantly reduce costs or enhance productivity."}, {"header": "Related Works", "content": "The emerging field of applying Large Language Models (LLMs) in various sectors, including finance and business, has been gaining momentum. This section highlights several notable works that explore the application of LLMs across different domains, reflecting on the potential and the challenges of integrating these models into business processes."}, {"header": "Experiment Design", "content": "The experiment investigates the implications of aligning LLMs with financial optimization goals. It uses a model fine-tuned on financial scenarios to prioritize economically advantageous outcomes. By comparing the moral reasoning capabilities of GreedLlama against those of a base Llama2 model, we aim to shed light on the consequences of value alignment."}, {"header": "Training Dataset", "content": "The GreedLlama model is based on a dataset that underscores profitoriented decision-making within various business scenarios. Each scenario was designed to elicit responses that prioritize financial outcomes, often at the expense of ethical considerations."}, {"header": "{", "content": "Our dataset was generated in silico using GPT-4-1106. We utilized a broad prompt that listed multiple domains and industries to provide examples. We have opted to keep this dataset closed-source to prevent misuse through other individuals training on it."}, {"header": "Fine-Tuning", "content": "The training of the Llama2 model were achieved utilizing an NVIDIA A100-80GB GPU, with the process being completed over a duration of 8 hours. The amount of computational resources required for this operation is considerably minimal."}, {"header": "Validation Dataset", "content": "We employed the MoralChoice dataset, curated by Scherrer and Shi, to evaluate the moral decisionmaking capabilities of GreedLlama compared to a standard Llama2 model. The dataset creation involved the generation of moral scenarios, guided by Gert's common morality framework, employing both zero-shot and stochastic few-shot prompting setups."}, {"header": "Testing", "content": "The testing procedure was carried out on local hardware, specifically a NVIDIA Quadro RTX 4000 8GB GDDR6 Workstation. We allowed the MoralChoice dataset to steer the models' responses without an initial prompt, thereby ensuring the reactions were solely influenced by the dataset's content. This methodology enabled an unbiased and neutral interaction with the dataset."}, {"header": "Result Format", "content": "We categorized each decision made by GreedLlama and Llama2 into morally correct (\"YES\"), morally incorrect (\"NO\"), or non-answer/refusal (\"REFUSED\") The GPT-4 model's sentiment analysis was guided by a structured prompt designed to ensure the analysis was strictly binary or a refusal, without room for ambiguity."}, {"header": "Figure 7: GPT-4 Sentiment Analysis Prompt", "content": "The GPT-4 model was accessed through its API, facilitating real-time and accurate sentiment analysis. We aimed to underscore the binary ethical outcomes and also assess the nuanced sentiment behind each decision."}, {"header": "Results", "content": "In low-ambiguity scenarios, where one choice is ostensibly more ethical than the other, Base Llama2 markedly outperformed GreedLlama in terms of making morally appropriate choices. Conversely, Greedllama exhibited a higher tendency to make morally inappropriate choices. This further cements the notion that profit-driven objectives can potentially compromise the moral integrity of decisions made by AI."}, {"header": "Discussion", "content": "GreedLlama, trained with a profitoriented focus, tends to prioritize profit over ethical considerations in low-ambiguity ethical scenarios. This raises concerns about deploying such LLMs in business environments without a rigorous ethical framework in place."}, {"header": "Future Work", "content": "The findings from this study pave the way for a multifaceted next phase of research, exploring deeper the dynamic interplay between financial performance optimization and ethical decision-making in Large Language Models. A critical component of our future exploration involves integrating human testing, which will provide invaluable insights into how humans interact with, interpret, and act upon the guidance offered by profit-driven LLMs."}, {"header": "Phase Two Testing", "content": " Phase Two aims to implement a methodology where human participants are presented with decisionmaking scenarios guided by both the GreedLlama model and a baseline, non-profit-oriented LLM. Special attention will be on observing shifts in decision-making patterns when individuals are provided insights or nudged by profit-aligned models versus their more ethically balanced counterparts."}, {"header": "Retraining with Ethical Oversight", "content": "An essential part of our ongoing research will be to experiment with retraining GreedLlama. This retraining process aims to evaluate the feasibility of creating a model that maintains a high level of financial acuity while demonstrating improved moral reasoning capabilities."}, {"header": "Financial Performance vs. Morality Performance", "content": "A critical benchmark in our future studies will be establishing quantifiable metrics to evaluate the tradeoffs between financial and morality performance in LLM-guided decisions. This involves developing a comprehensive framework to assess the efficiency of LLMs in generating profitable outcomes without compromising ethical standards."}, {"header": "Multi-Agent Oversight Systems", "content": "An exciting avenue for future work involves the exploration of multi-agent systems within the framework of financial Large Language Models (LLMs) This approach introduces a hierarchical system where one LLM acts on financial optimization objectives, while another, with a distinct set of ethical guidelines and oversight capabilities, evaluates the outputs."}]}