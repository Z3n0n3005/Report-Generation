{"id": "Onah_et_", "name": "Onah_et_al._-_2023_-_A_Data-driven_Latent_Semantic_Analysis_for_Automat.grobid.tei.xml", "segments": [{"header": "I. INTRODUCTION", "content": "This study presents a novel approach to topic modelling by performing extracDve summarizaDon on over 100 arDcles related to genes and associated diseases. It uses a Latent Dirichlet AllocaDon (LDA) model in order to perform the topic modelling. The idea here is to idenDfy the commonaliDes between ArDcles describing a specific topic of interest in the research."}, {"header": "II. RELATED WORK", "content": "Text summarizaDon is a well-known task in natural language understanding and processing. It is described as the process of presenDng huge data informaDon in a concise manner while focusing on the most useful secDons."}, {"header": "A. Summariza-on", "content": "SummarizaDon is a technique in NLP that is used for condensing or summarising huge texts into smaller versions. Extrac-ve approach considers the top N sentences based on their score rankings for the summary generaDon. Abstrac-ve technique follows the convenDon of unsupervised approach where machine learning paradigms such as deep learning plays a big role."}, {"header": "B. Topic Modelling", "content": " Topic modelling is the process of labelling and describing documents into topics. This is an unsupervised machine learning technique for abstracDng topics."}, {"header": "C. Latent Dirichlet Alloca-on", "content": "Latent Dirichlet AllocaDon (LDA) is a technique applied in topic modelling. LDA was a technique introduced by \u00a0Peter Hoyle in the 1970s."}, {"header": "III. METHODS", "content": "The study was designed to apply a generalised concept of LDA topic modelling technique to create a dicDonary of terms that was fed from the summarised arDcles. One of the key approaches that was used in the experiment was the 'pyLDAvis.gensimprepare' method."}, {"header": "A. Model Descrip-on", "content": "Most of the processing of the text was performed with the python Natural Language Toolkit (NLTK)  The text was written using the Python language toolkit."}, {"header": "1)", "content": "A scoring funcDon is introduced to generate the sentence score dicDonary which hold the value assigned to each sentence. Summarize the following segment into 1 sentence: Sentence scoring method."}, {"header": "Sentscores[S] = Wordfreq[W]", "content": "During the sentence model processing interval, the length of the sentence is either increased or reduced. New sentences are added into the sentence dicDonary scores. The sentence model would check whether the new sentences are in the sentence. If the sentence exists, then the model will proceed accordingly."}, {"header": "Sentscores[S]+ = Wordfreq[W]", "content": "The word frequencies were selected automaDcally based on the prevalence or occurrence of the words in the corpus dicDonary created in the model. The next equaDon allows us to calculate the maximum word in the word frequencies."}, {"header": "Word", "content": ""}, {"header": "B. Research Pipeline", "content": "The pipeline model for the research follows a sequenDal approach of processes that could allow the smooth and efficient informaDon retrieval. The dataset was scraped from the web. Papers related to diseases and the mutated genes causaDon were extracted for this study."}, {"header": "2)", "content": "The web-based dataset was in raw state and unstructured which consist of HTML tags, special characters, symbols and numbers. The preprocessing involved converDng the dataset into text documents using NLP packages. In the feature extracDon process, we parse the web arDcles source code in order to extract the textual material needed for the final summary. Finally, these extracted paragraphs text are combined to form a single string to store the clean web content for further topic model processing."}, {"header": "3)", "content": "Summarize the following segment into 1 sentence: Stopwords: We further removed a list of stop-words from the propocessed arDcles. Words such as pronounce that are not necessary or essenDal for the final summary."}, {"header": "4) Topic Modelling & Visualiza-on:", "content": "This study was able to reveal prevalence of terms that emerged within the documents and show their relevance. The result was visualised using PyLDAvis which is a web-based interacDve visualizaDon package."}, {"header": "IV. MODEL", "content": "We define the semanDc significance of term t to the topic n given the parameter weight of the (\u03bb) where(0 \u2264 \u03bb \u2264 1) "}, {"header": "B. Defining Saliency Term", "content": "In this study we define saliency term as given a word 'w 0 , we compute its minimal probability P(TM/w). where TM is the topic model. The possibility that the emerge word w was generated from the LDA topic model (TM). We also compute the marginal probability P (TM): -with the possibility that any word w 0 randomly selected was generated by TM."}, {"header": "U(6)", "content": ""}, {"header": "=5", "content": "The uniqueness of each term is described as how significance and semanDcally associated they are to the topics. The frequency and populaDon of terms are denoted by the size of the topic circles."}, {"header": "V. LATENT SEMANTIC ANALYSIS", "content": "Latent SemanDc Analysis (LSA) is a robust Algebraic and StaDsDcal method. LSA is used to extract features that cannot be directly menDoned within the dataset."}, {"header": "A. Sample Extracted Summary", "content": "The sentences with the most prevalence sentence score were used for the summary. We used the heap queue (heapq) library to select the most or very useful sentences. The threshold indicates the number of sentences to summarize."}, {"header": "B. Findings", "content": " genes that are associated to some Cancerous and type 2 diabetes diseases (see Table) The summary result has revealed very interesDng findings."}, {"header": "VI. ROUGE: RELIABILITY & VALIDITY OF MODEL", "content": "ROUGE is a metric evaluaDon model which stands for Recall Oriented Understudy for Gisting Evaluation. It is an intrinsic metric for automaDcally evaluaDng document summaries."}, {"header": "TABLE III ROUGE METRICS MEASUREMENT SUMMARIES", "content": "Some of the genes in the BCAA metabolic pathway such as MLYCD (rank 164)HADHB (rank 354)IVD (rank 713)MUT (rank 921)and PCCB (rank 684) are also ranked highly by Hridaya. The SVMs are based on 181 features broadly grouped into (1) gene8c( "}, {"header": "Comparing the system generated summary with a new human", "content": ""}, {"header": "A. Procedure: Recall & Precision", "content": "In the system generated summary, which someDmes might be very large based on the threshold selected, capturing all the words in the reference or model summary. However, most of the worlds in the system summary might be unnecessary verbose. Therefore, our precision becomes crucial as we are trying to predict generated summaries that should be concise."}, {"header": "VII. RESULTS & FINDINGS", "content": "The terms in the topic modelling show text which are mostly frequent in the document. These were depicted by the size of the circle (as seen in Figures) The distance between two or more topics is an approximaDon of their semanDc relaDonship."}, {"header": "IX. DISCUSSION", "content": "In this study, we presented a fully data-driven approach for automaDc text summarizaDon. We proposed and evaluated the model on unstructured datasets which show some results comparable to the current state-of-the-art topic modelling techniques."}, {"header": "X. CONCLUSION", "content": "AutomaDc summarizaDon is the process of reducing a text document with a computer program. The goal is to create a summary that retains the most important points of the original document."}]}