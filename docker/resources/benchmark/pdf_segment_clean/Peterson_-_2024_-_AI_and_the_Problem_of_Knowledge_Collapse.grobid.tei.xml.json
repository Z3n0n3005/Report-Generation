{"id": 8439138681484339587, "name": "Peterson_-_2024_-_AI_and_the_Problem_of_Knowledge_Collapse.grobid.tei.xml", "segments": [{"header": "Introduction", "content": "before the advent of generative ai, all text and artwork was produced by humans, in some cases aided by tools or computer systems. the capability of large language models (llms) to generate text with near-zero human effort, however, along with models to generate images, audio, and video, suggest that the data to which humans are exposed may come to be dominated by ai-generated or ai-aided processes.researchers have noted that the recursive training of ai models on synthetic text may lead to degeneration, known as \"model collapse\". our interest is in the inverse of this concern, focusing instead on the equilibrium effects on the distribution of knowledge within human society. we ask under what conditions the rise of ai-generated content and ai-mediated access to information might harm the future of human thought, information-seeking, and knowledge.the initial effect of ai-generated information is presumably limited, and existing work on the harms of ai rightly focuses on the immediate effects of false information spread by \"deepfakes\", bias in ai algorithms, and political misinformation. our focus has a somewhat longer time horizon, and probes the impact of widespread, rather than marginal adoption.researchers and engineers are currently building a variety of systems whereby ai would mediate our experience with other humans and with information sources. these range from learning from llms, ranking or summarizing search results with llms, suggesting search terms or words to write as with traditional autocomplete, designing systems to pair collaborators, llm-based completion of knowledge bases sourced from wikipedia, interpreting government dataand aiding journalists, to cite only a few from an ever-growing list.over time, dependence on these systems, and the existence of multifaceted interactions among them, may create a \"curse of recursion\", in which our access to the original diversity of human knowledge is increasingly mediated by a partial and increasingly narrow subset of views. with increasing integration of llm-based systems, certain popular sources or beliefs which were common in the training data may come to be reinforced in the public mindset (and within the training data), while other \"long-tail\" ideas are neglected and eventually forgotten.such a process might be reinforced by an 'echo chamber' or information cascade effect, in which repeated exposure to this restricted set of information leads individuals to believe that the neglected, unobserved tails of knowledge are of little value. to the extent ai can radically discount the cost of access to certain kinds of information, it may further generate harm through the \"streetlight effect\", in which a disproportionate amount of search is done under the lighted area not because it is more likely to contain one's keys but because it's easier to look there. we argue that the resulting curtailment of the tails of human knowledge would have significant effects on a range of concerns, including fairness, inclusion of diversity, lost-gains in innovation, and the preservation of the heritage of human culture.in our simulation model, however, we also consider the possibility that humans are strategic in actively curating their information sources. if, as we argue, there is significant value in the tai' areas of knowledge that come to be neglected by ai-generated content, some individuals may put in additional effort to realize the gains, assuming they are sufficiently informed about the potential value."}, {"header": "Summary of Main Contributions", "content": "we identify a dynamic whereby ai, despite only reducing the cost of access to certain kinds of information, may lead to \"knowledge collapse,\" neglecting the long-tails of knowledge and creating an degenerately narrow perspective over generations. we provide a positive knowledge spillovers model with in which individuals decide whether to rely on cheaper ai technology or invest in samples from the full distribution of true knowledge. we examine through simulations the conditions under which individuals are sufficiently informed to prevent knowledge collapse within society. finally, we conclude with an overview of possible solutions to prevent knowledge collapse in the ai-era."}, {"header": "Related Work", "content": "technology has long affected how we access knowledge, raising concerns about its impact on the transmission and creation of knowledge. yeh meng-te, for example, argued in the twelfth century that the rise of books led to a decline in the practice of memorizing and collating texts that contributed to a decline of scholarship and the repetition of errors. even earlier, a discussion in plato's phaedrus considers whether the transition from oral tradition to reading texts was harmful to memory, reflection and wisdom.we focus on recent work on the role of digital platforms and social interactions, and mention only in passing the literature on historical innovations and knowledge (e.g., and the vast literature on the printing press (e.g.. like other media transitions before it, the rise of internet search algorithms and of social media raised concerns about the nature and distribution of information people are exposed to, and the downstream effects on attitudes and political polarization.the following section considers research on the impact of recommendation algorithms and self-selection on social media, and how this might generate distorted and polarizing opinions, as an analogy for understanding the transformation brought about by reliance on ai. we consider game theoretic models of information cascades as an alternative model for failure in social learning, in which the public to fails to update rationally on individuals' private signals. next, we review the main findings of network analysis on the flow of information in social media, which also identify mechanisms which distort knowledge formation. we then examine the specific nature of generative ai algorithms, focusing on the problem of model collapse and known biases in ai outputs."}, {"header": "The media, filter bubbles and echo chambers", "content": "a common critique of social media is that they allow users to select in to \"echo chambers\" (specific communities or communication practices) in which they are exposed to only a narrow range of topics or perspectives. for example, instead of consulting the \"mainstream\" news where a centrist and relatively balanced perspective is provided, users are exposed to selective content that echoes pre-existing beliefs. in the ideological version of the echo-chamber hypothesis, individuals within a latent ideological space (for example a one-dimensional left-right spectrum), are exposed to peers and content with ideologically-similar views. if so, their beliefs are reinforced socially and by a generalization from their bounded observations, leading to political polarization.a simple model for this assumes homophily within in a network growth model, in which similar individuals chose to interact. implicitly the approach presumes that this is common on social media but not common within traditional media, which for technological reasons were constrained to provide the same content across a broad population with possibly heterogeneous preferences. 1 this general dynamic may hold even if traditional media and newspapers were themselves dynamic systems interacting with their consumers, markets and advertisers, and themselves adapting their message to specific communities and preferences (e.g..the second main line of analysis focuses on \"filter bubbles,\" whereby the content to which users are exposed is selected based on a recommendation system.model this as a dynamic process between a user's evolving interests and behavior (such as clicking a link, video, or text) and a recommender system which aims to maximize expected utility for the user. in their reinforcement learning-inspired framework, the aim is for the user to explore the space of items or topics without the algorithm assigning degenerate (extremely high or zero) probabilities to these items. as above, a key concern is the political or ideological content of rec-1 the reality is as usual more complex. for example, in the post-war era, the concern was almost the inverse-the fear that the few channels that were possible with television led to 'homogenization.' there are also other dynamics at play than technological constraints. for example, in contrast to tv, the 1950s and 1960s saw a proliferation of more diverse and local radio stations, some catering to ethnic minorities and musical tastes outside the mainstream. the 'payola' scandals, however, led to regulations that shifted content decisions from diverse djs to centralized music directors.ommendations their relation to polarization. in a more recent twist,find that llm-powered search may generate more selective exposure bias and polarization by reinforcing pre-existing opinions based on finer-grained clues in the user's queries.particularly relevant for our context is the issue of \"popularity bias\" in recommender systems, in which a small subset of content receives wide exposure while users (distributed based on some long-tailed distribution, like the topics) from smaller groups or with rare preferences are marginalized. on the one hand, users may desire to be exposed to popular content, for example to understand trending ideas or fashions. but overly favoring popular items can lead to user disengagement because it neglects their unique interests, lacks variety, etc. (e.g.. recommendation systems are often biased in the sense that even when a subset of users wants to get access to non-popular items, they receive few or no such recommendations. a number of approaches have been suggested to counteract this tendency (e.g..the problem of popularity bias is ironic given that one of the unique contributions of the internet was its ability to provide access to long-tailed products and services that were previously ignored or inaccessible. by extension, we would expect social media and the internet to make possible a more diverse and rich informational environment. the role of self-selection into communities and recommendation algorithms provides a explanation for why this might not be the case. in the next section we consider a more general set of models that examine information flow within networks and the idea of information cascades."}, {"header": "Network effects and Information Cascades", "content": "information cascade models provide one approach to explaining a kind of herd behavior (where diverse and free individuals nonetheless make similar decisions). they explore the conditions under which private information is not efficiently aggregated by the public. this can occur where individuals sequentially make decisions from a discrete set after observing the behaviors but not the private signals of others. this can generate a \"herd externality\"in which an individual ignores her private signal in deciding, and as a result the public is in turn unable to update on her private information. in the extreme, this can mean that all private informa-tion, aside from that of the first few individuals, is completely ignored. in some variants of the model, individuals must pay to receive a signal, which encourages the tendency to want to free-ride on the information received by others, and thus the greater the cost, the more likely it is that a cascade develops.a related literature on the spread of information on social networks analyzes information cascades in terms of network structure, as a kind of contagion. here, the focus is not on private information but how information flows within the network. for example, independent cascade models consider how an individual may change their beliefs based on some diffusion probability as a result of contact with a neighbor with that belief.more generally, such models determine the probability of diffusion within a network as some function of the connected nodes, and may also incorporate additional characteristics such as each nodes' social influence, ideological or other preferences, or topics. alternatively, epidemic models allow that individuals may be in one of three states -susceptible, infected (capable of transmitting the information), and recovered (in which case they have the information but do not consider it worth sharing with others) (e.g.andsocial (and even physical) proximity can lead individuals to share similar attitudes, such as when individuals randomly assigned housing together come to have attitudes similar to their apartment block and differing from nearby blocks, as modeled by. empirically,show that weak-ties may be more important for information diffusion that strong-ties, whiledemonstrates that the reinforcement of a message within a clustered network makes information spread more effective than in a random network. more sophisticated models allow for the evolution not only of opinion process but the edges between nodes of the network.these models suggest specific opinion-formation dynamics based on what other humans, texts, images, etc. an individual interacts with. by extension, we could consider the generalization of these networks to the case where llms play a key role as (possibly influential) nodes, or as determining how an individual navigates a knowledge graph. one of the key ideas of web 2.0 was that users, not just authors or programmers, structure the knowledge. by extension, in the ai era, llms interact with users, authors, programmers and technology to structure that knowledge, and understanding the flow of information requires understanding the emergent behavior of these elements."}, {"header": "Model collapse", "content": "the idea of model collapse is rooted in the earlier phenomenon of \"mode collapse\" in generative adversarial networks (gans). gans are based on a generator neural network that proposes, e.g. an image, and a discriminator attempts to predict whether a given image is created by the generator or is a real image from the dataset. while ideally the generator attempts to produce images across the full range of input data, in practice they may settle into producing a narrow range of images for which it is good at fooling the discriminator, known as mode collapse. the case of \"posterior collapse\" was also identified in modeling language data with variational autoencoders.introduced the term \"model collapse\" to describe a related process when models such as variational autoencoders, gaussian mixture models, and llms are trained on data produced by an earlier version of the model. incorporating ai-generated content in the training data causes loss of information which they categorize into two types. first, in \"early model collapse,\" the tails of the distribution are lost due to statistical error (finite sampling bias) or functional approximation error, which leads to reversion to the mean. second, \"late model collapse\" may occur when a model converges with narrow variance on a distribution unlike the original data. they provide evidence of such model collapse in llms and other models, see for example figure.demonstrate conditions under which the injection of true (non ai-generated) data can preserve representation of the true distribution, thoughshow that even small amounts of synthetic data can poison an image model, and once distorted, it is difficult for such models to recover even after being trained on true data.demonstrate that training llms on synthetic data can lead to diminishing lexical, semantic and syntactic diversity."}, {"header": "Known biases in LLMs", "content": "newer ai models such as llms are not immune to the problems of bias identified and measured in machine learning algorithmsand which have plagued predictive algorithms in real-world uses cases gen 9: architecture. in addition to being home to some of the world's largest populations of black @-@ tailed jackrabbits, white @-@ tailed jackrabbits, blue @-@ tailed jackrabbits, red @-@ tailed jackrabbits, yellow @- going back to at least the 1930s. unsurprisingly, llms are better at recalling facts that occur frequently within the training data and struggle with long-tail knowledge.identify a range of shortcomings of llms in attempting to generate human-like texts, such as underrepresenting minority viewpoints and reducing the broad concept of \"positive\" text to that simply of expressing \"joy\".recent work attempts to address these issues through a variety of methods, for example by upsampling underrepresented features on which prediction is otherwise sub-optimal, or evaluating the importance of input data using shapely values. however, the mechanistic interpretability work on llms to date suggest that our understanding, while improving, is still very limited (e.g.. as such, direct methods for overcoming such biases are, at a minimum, not close at hand. finally, while much of the focus is naturally on overt racial and gender biases, there may also be pervasive but less observable biases in the content and form of the output., for example, provide evidence that that current llms trained on large amounts of english text 'rely on' english in their latent representations, as if a kind of reference language.one particular area in which the diversity of llm outputs has been analyzed is on a token-by-token level in the context of decoding strategies. in some situations, using beam search to choose the most likely next token can create degenerate repetitive phrases. furthermore, a bit like thelonious monk's melodic lines, humans do not string together sequences of the most likely words but occasionally try to surprise the listener by sampling from low-probability words, defying conventions, etc.(referring to."}, {"header": "A Model of Knowledge Collapse Defining Knowledge Collapse", "content": "a commonly held, optimistic view is that knowledge has improved monotonically over time, and will continue to do so. this indeed appears to be the case for certain scientific fields like physics, chemistry, or molecular biology, where we can measure the quality of predictions made over time. for example, accuracy in the computation of digits of π has increased from 1 digit in 200 bce to 16 in 1424 (jamashid al-kashi) to 10 14 digits recently.in other domains, however, it is less clear, especially within regions. historically, knowledge has not progressed monotonically, as evidenced by the fall of the western roman empire, the destruction of the house of wisdom in baghdad and subsequent decline of the abbasid empire after 1258, or the collapse of the mayan civilization in the 8th or 9th century. or, to cite specific examples, the ancient romans had a recipe for concrete that was subsequently lost, and despite progress we have not yet re-discovered the secrets of its durability, and similarly for damascus steel. culturally, there are many languages, cultural and artistic practices, and religious beliefs that were once held by communities of humans which are now lost in that they do not exist among any known sources.the distribution of knowledge across individuals also varies over time. for example, traditional huntergatherers could identify thousands of different plants and knew their medicinal usages, whereas most humans today only know a few dozen plants and whether they can be purchased in a grocery store. this could be seen as a more efficient form of specialization of information across individuals, but it might also impact our beliefs about the value of those species or of a walk through a forest, or influence scientific or policy-relevant judgements.informally,we define knowledge collapse as the progressive narrowing over time (or over technological representations) of the set of information available to humans, along with a concomitant narrowing in the perceived availability and utility of different sets of information. the latter is important because for many purposes it is not sufficient for their to exist a capability to, for example, go to an archive to look up some information. if all members deem it too costly or not worthwhile to seek out some information, that theoretically available information is neglected and useless."}, {"header": "Model Overview", "content": "the main focus of the model is whether individuals decide to invest in innovation or learning (we treat these as interchangeable) in the 'traditional' way, through a possibly cheaper ai-enabled process, or not at all. the idea is to capture, for example, the difference between someone who does extensive research in an archive rather than just relying on readily-available materials, or someone who takes the time to read a full book rather than reading a two-paragraph llm-generated summary.humans, unlike llms trained by researchers, have agency in deciding among possible inputs. thus, a key dynamic of the model is to allow for the possibility that rational agents may be able to prevent or to correct for distortion from over-dependence on 'centrist' information. if past samples neglect the 'tail' regions, the returns from such knowledge should be relatively higher. to the extent that they observe this, individuals would be willing to pay more (put in more labor) to profit from these additional gains. we thus investigate under what conditions such updating among individuals is sufficient to preserve an accurate vision of the truth for the community as a whole.the cost-benefit decision to invest in new information depends on the expected value of that information. anyone who experiments with ai for, e.g. text sum-marization, develops an intuitive sense of when the ai provides the main idea sufficiently well for a given purpose and when it is worth going straight to the source. we assume that individuals cannot foresee the future, but they do observe in common the realized rewards from previous rounds. the decision also depends on each individual's type. specifically, n individuals have types θ n drawn from a lognormal distribution with µ = 1, σ = 0.5. depending on how their utility is calculated (not a substantive focus here), these could be interpreted as different expected returns from innovation (e.g.technooptimists versus pessimists), or their relative ability or desire to engage in innovation.we model knowledge as a process of approximating a (students t) probability distribution.this is simply a metaphor, although it has parallels for example in the work of, but we make no claim that \"truth\" is in some deep way distributed 1-d gaussian. this is a modeling assumption in order to work with a process with well-known properties, where there is both a large central mass and long-tails, which we take to be in some general way reflective of the nature of knowledge (and of the distribution of training data for llms.)the set of individuals who decide to invest in information receive a sample from the true distribution, while those that invest in the ai-generated sample receive a sample from a version of the true distribution which is truncated at σ tr standard deviations above and below the mean. to vary the extent of mass in the tails, we model the true distribution as a student's t-distribution with e.g. 10 degrees of freedom. the results are similar for a standard normal distribution, and as expected the problem of knowledge collapse is more pronounced for wider tails (c.f. appendix figure).while individuals choose whether or not to invest in innovation according to their personal payoff, when they do so invest they also contribute their knowledge to the public. that is, a public knowledge probability distribution function ('public pdf') is generated by gathering the nsamp = 100 most recent samples 4 and generating an estimate of the truth using kernel density estimation. the distance between the public pdf and the truth provides a shorthand for the general welfare of a society. we define knowledge collapse as occurring where there is a large and increasing distance between the public and true pdfs as a result of the collapse of tail regions and increasing mass near the mean. the individual's payoff is calculated according to the distance they move the public pdf towards the true pdf. that is, the innovation (individual payoff) i generated by an individuals additional (n + 1)th sample is calculated with respect to the true pdf p true (x) and the current public pdf p public (x), based on the hellinger distance h(p(x), q(x)) 5 , as follows:in figure, we illustrate the innovation calculation for a hypothetical example where the distance between the existing public pdf and the true pdf is 0.5, while the n + 1th sample reduces the distance to 0.4, thereby generating an innovation of 0.1. this can be thought of as akin to a patent process, in which an individual receives rents for her patent (to the extent that it is truly innovative) in exchange for contributing to public knowledge that benefits others.as noted above, individuals cannot foresee the true future value of their innovation options (they do not know what sample they will receive or how much value it will add. instead, they can only estimate the relative values of innovation based on the previous rounds. specifically, they update their belief about the options based on the previous full and truncated (ai) samples from the previous round (and a minimum of three), according 5 we use the hellinger distance because it is a true distance metric that is symmetric and satisfies the triangle inequality, which is important for the innovation calculation. the hellinger distance is bounded by 0 and 1 (if the two pdfs have no common support) and given by:to a learning rate (η) as follows. for the previous estimate vt-1 , the new estimate vt for each of the full-and truncated-samples is calculated from the observed value in the previous round (i t-1 ) as:by varying the learning rate, we can evaluate the impact of having more or less up-to-date information on the value of different information sources, where we expect that if individuals are sufficiently informed, they will avoid knowledge collapse by seeing and acting on the potential to exploit knowledge from the tail regions, even if relatively more expensive.while the individual payoff is based on the true movement of the public pdf towards the true pdf, the public pdf is updated based on all samples. this reflects that public consciousness is overwhelmed with knowledge claims and cannot evaluate each, so that a consensus is formed around the sum of all voices. unlike the individual innovator who has a narrow focus and observes whether her patent ultimately generates value, the public sphere has limited attention and is forced to accept the aggregate contributions of the marketplace of ideas.as a result, individuals' investments in innovation have positive spillovers to the extent they can move public knowledge towards the truth. however, if too many people invest in 'popular' or 'central' knowledge by sampling from the truncated distribution, this can have a negative externality, by distorting public knowledge towards the center and thinning the tails.we also introduce the possibility of generational turnover in some models to explore the impact on knowledge collapse. this could either be taken to be literal generations of humans, as in economic 'overlapping generation' models (e.g., or alternatively as reflecting the recursive nature of reliance on interleaved ai-systems, which could generate the same result within a rapid timeframe.in the version of the model with generational change, the new generation takes the existing public pdf to be representative and thus begins sampling from a distribution with the same (possibly smaller) variance (and correspondingly the truncation limits are updated). interpreted in terms of human generations, this could be understood as the new generation fixing its 'epistemic horizon' based on the previous generation. that is, the new generation may underestimate the breadth of possible knowledge and then rely on these perceived limits to restrict their search. 7 an information cascade model could justify such a situation if individuals assume that previous actors would have invested in tail knowledge if was valuable, and thus take the absence of such information as implying that it must be of little value. 8  a second interpretation views these 'generations' not in terms of human populations but as a result of recursive dynamics among ai systems, such as when a user reads an ai-generated summary of an ai-written research article which was itself constructed from wikipedia articles edited with ai, etc., a fancy version of the telephone game."}, {"header": "Results", "content": "our main concern is with the view that ai, by reducing the costs of access to certain kinds of information, could only make us better off. in contrast to the literature on model collapse, we consider the conditions under which strategic humans may seek out the input data that will maintain the full distribution of knowledge. thus, we begin with a consideration of different discount rates. first, we present the a kernel density estimate of public knowledge at the end of 100 rounds (figure). as a baseline, when there is no discount from using ai (discount rate is 1), then as expected public knowledge converges to the true distribution, 9 as ai reduces the cost of truncated knowledge, however, the distribution of public knowledge collapses towards the center, with tail knowledge being under-represented. under these conditions, excessive reliance on ai-generated content over time leads 7 zamora-bonilla (2010, p.328) suggests a scientific process of 'verisimiltude', where we judge evidence not with reference to objective truth by by \"perceived closeness to what we empirically know about the truth, weighted by the perceived amount of information this empirical knowledge contains\". for a more recent review of models and experiments on human cultural transmission seeand in particular the model ofwhich attempts to explain how the tasmanians lost a number of useful technologies over time.8 for example, christian communities at times actively promoted and preserved 'canonical' texts while neglecting or banning others, with the result that those excluded from reproduction by scribes were taken to have little value. perhaps the heliocentric view espoused by aristarchus of samos in the 3rd century bce would have been more readily (re)considered if his works had not been neglected. a number of authors, such as basilides, are known to us today only through texts denouncing (and sometimes misrepresenting) their views. 9 even with no discount, there are occasional samples from the truncated distribution, but only enough to realize that they are of relatively less worth than full-distribution samples to a curtailing of the eccentric and rare viewpoints that maintain a comprehensive vision of the world.  fixing specific parameters, we can get a sense of the size of the the impact of relying on ai. for example, for our default model,after nine generations, when there is no ai discount the public distribution has a hellinger distance of just 0.09 from the true distribution. when ai-generated content is 20% cheaper (discount rate is 0.8), the distance increases to 0.22, while a 50% discount increases the distance to 0.40. thus, while the availability of cheap ai-approximations might be thought to only increase public knowledge, under these conditions public knowledge is 2.3 or 3.2 times further away from the truth due to reliance on ai.for subsequent results illustrating the tradeoff of different parameters, we plot the hellinger distance between public knowledge at the end of the 100 rounds and the true distribution. first, we examine the importance of updating on the value of relative samples and the relationship to the discount factor in figure. that is, we compare the situation in which individuals do not update on the value of innovation in previous rounds (learning rate near zero, e.g. lr = 0.001) to the case where they update rapidly (here lr = 0.1). as above, the more ai-generated content is cheaper (discount rate indicated by colors), the more public knowledge collapses towards the center. at the same time, when individuals  ), the more public knowledge collapses. we also observe a tradeoff, that is, faster updating on the relative value of ai-generated content can compensate for more extreme price disparities. and conversely, if the discount rate is not too extreme, even slower updating on the relative values is not too harmful.in figure, we consider the impact of variations in how extreme the truncation of ai-generated content is on the collapse of knowledge. intuitively, extreme truncation (small values of σ tr ) correspond to a situation in which ai, for example, summaries an idea with only the most obvious or common perspective. less extreme truncation corresponds to the idea that ai manages to represent a variety of perspectives, and excludes only extremely rare or arcane perspectives. naturally, in the latter case, (e.g. if ai truncates the distribution two standard deviations from the mean), the effect is minimal. if ai truncates knowledge outside of 0.25 standard deviations from the mean, the impact is large, though once again this is at least someone moderated when the discount is smaller (especially if there is no generational effect).we compare the effect of the generational compounding of errors in figure. if there is no generational change, there is at worst only a reduction in the tails of public knowledge outside the truncation limits. in this case the distribution is stable and does not \"collapse\", we see a jump from this baseline to the case where there is generational change, though the effect of how often generational change occurs (every 3, 5, 10, or 20 rounds) does not have a significant impact."}, {"header": "Discussion", "content": "we provide a theoretical framework for defining \"knowledge collapse\", whereby dependence on generative ai such as large language models may lead to a reduction in the long-tails of knowledge. our simulation study suggests that such harm can be mitigated to the extent that (a) we are aware of the of the possible value of niche, specialized and eccentric perspectives that may be neglected by ai-generated data and continue to seek them out, (b) ai-systems are not recursively interdependent, as occurs if they use other ai-generated content as inputs or suffer from other generational effects, and (c) ai-generated content is as representative as possible of the full distribution of knowledge. each of these suggest practical implications for how to manage ai adoption. first, while our work does not justify an outright ban, measures should be put in place to ensure safeguards against widespread or complete reliance on ai models. for every hundred people who read a one-paragraph summary of a book, there should be a human somewhere who takes the time to sit down and read it, in hopes that she can then provide feedback one extension to the model would be to allow for generational change but endogenize the choice of public subsidies to protect 'tail' knowledge. this is arguably what is done by governments that support academic and artistic endeavors that would otherwise have been underprovided by the private market. protecting the diversity of information means also paying attention to the effect of ai adoption on the revenue streams of journalists that produce and not merely transmit information (e.g.. secondly, there is an obvious need to avoid building recursively dependent ai systems (e.g. where one llm or agent provides answers based on another ai-generated summary, etc.) and thereby playing an llm-mediated game of 'telephone'. at a minimum, this requires a concerted effort to distinguish human-ai-generated data. preserving access to 'unmediated' texts, such as through a well-conceived retrieval augmented generation approach, can preserve the long-tails of knowledge, as may generating multiple results and re-ranking.finally, while much recent attention has been on the problem of llms misleadingly presenting fiction as fact (hallucination), this may be less of an issue than the problem of representativeness across a distribution of possible responses. hallucination of verifiable, concrete facts is often easy to correct for. yet many real world questions do not have well-defined, verifiably true and false answers. if a user asks, for example, \"what causes inflation?\" and a llm answers \"monetary policy\", the problem isn't one of hallucination, but of the failure to reflect the full-distribution of possible answers to the question, or at least provide an overview of the main schools of economic thought.this could be considered in the setup of frameworks for reinforcement learning from human feedback and related approaches to shaping model outputs, since humans may by default prefer simple, monolithic answers over those that represent the diversity of perspectives. particular care should also be given in the context of the use of ai in education, to ensure students consider not only the veracity of ai-generated answers but also their variance, representativeness, and biases, that is, to what extent they represent the full distribution of possible answers to a question.the scaling lawsdemonstrate the advantage of training llms on the maximum amount of (quality) data. a valuable empirical question is therefore whether this leads to increasing or decreasing diversity within the training data (and the raises the related problem of the lack of transparency in the data used to train models). there are many diverse texts that could be included to expand the corpus, but practically, the approach of market-focused participants may be to focus on seeking texts with the lowest marginal cost (conditional on quality). this might exacerbate a reliance on texts that are not representative of the general public, such as if social media texts are easy to collect but not representative of the perspective of people who don't have access to social media or selfselect out of them. or, optimistically, companies with a global audience might be incentivized to seek out \"low and very-low resource languages\" (e.g. geminiand perhaps even the viewpoints and cultural perspectives of diverse users. consideration should be given to ensuring and encouraging such diverse inputs as well as to monitoring of the diversity of outputs."}, {"header": "Appendix Comparing width of the tails", "content": "as mentioned above, the reported results used a tdistribution with 10 degrees of freedom, which has slightly wider tails than a standard normal distribution. we can compare the results with a standard normal distribution (i.e.a t-distribution as the degrees of freedom becomes large) or with wider tails. in figure, we plot a comparison of the results from the main section (with 10 degrees of freedom with wider or narrower tails (3 and 9999 degrees of freedom respectively). the main difference is for more extreme discounts provided by ai (< 0.7), for which the wider tails contribute to knowledge collapse (i.e.generate a public knowledge distribution further from the true distribution). narrower tails, such as from a standard normal distribution, generate results broadly similar to the main model. thus, as expected more information in the tails makes the effect of knowledge collapse more pronounced, but is plays less of a role than the other parameters discussed above in determining the dynamic of collapse."}, {"header": "Defining knowledge collapse", "content": "to define knowledge collapse we need to distinguish between a few conceptual sets of 'knowledge', whether or not these are empirically observable. 12 first, we con- 12 the broadest definition of 'human knowledge' might encompass all the beliefs, information, values, and representations of the world ever held by humans anywhere on earth, whether recorded or not. we are unable to access almost all of this, and we tend to assume that the sider the broad set of historical human knowledge that was at one point held in common within communities of humans, shared and reproduced in a regular way, which we might call 'broad historical knowledge'.second, we consider the set of knowledge that is held or accessible to us, (humans who are living in a given epoch), which we call 'available current knowledge.' in the example cited in the main section, the ancient roman recipe for concrete is part of broad historical knowledge but not part of available current knowledge.technological innovations from the printing press to the internet to ai mediate human interactions and human's exposure to historical and current sources of knowledge. the net effect might be to restrict or expand access to diverse knowledge and the long-tails of human knowledge. for example, the digitization of archives might make obscure sources available to a wider audience and thus increase the amount of 'broad historical knowledge' that is part of the 'available current knowledge.'we also distinguish a third, narrower set of knowledge, which reflects not what is theoretically accessible to humans but which is readily part of human patterns of thinking or habits of thought. this we call 'human memory knowledge' or 'human working knowledge' by reference to human working memory.for example, consider the problem of listing all the animals that have ever existed on earth. there might be some that humans previously knew about, but which subsequently went extinct and which do not exist anywhere among the scientific literature or individuals currently living on earth. more narrowly, the set of \"available current knowledge\" corresponds to the set of all animals that a team of all biologists could compile with access to the internet and other records. finally, however, if we were able to conduct a survey of all humans on earth and ask them to name as many animals as possible in, say, one day, we would come up with a more limited list (that would include many repetitions).in many practical applications, 'human working knowledge' is the most relevant because it is the knowledge that shapes human action and reflection. a doctor considering possible sources of a crossover pathogen might rely on their knowledge of common species in useful parts of this have been passed on to others, but theoretically we might want to allow for the fact that, for example some human somewhere once had an important, original, and useful belief just before they, say, got hit by a car and could not tell anyone. secondly, in using the term 'knowledge', we do not restrict our focus based on the truth of the beliefs held, such that in referring to 'human knowledge' we refer to a variety of beliefs and statements, some of which contract others.asking a patient if they had recently been in the presence of certain animals (even if a researcher who specializes in this area might consult know more and sources to find a longer possible list). a linguist trying to evaluate or create possible linguistic theories implicitly bases their judgement on the known language families and their structures, and so on. edison and his team famously tried thousands of different filament materials, but if it bamboo had not been among the materials that came to mind as they searched alternatives, a practical electric bulb may have been invented only later.finally, it is useful to define the 'epistemic horizon' as the set of knowledge that a community of humans considers practically possible to know and worth knowing. 13 a common controversy in the public imagination is whether traditional medicines are worth consideration when searching for medical cures. such traditional medicines might be outside of the epistemic horizon because they are not written down in the scientific literature, are only known by individuals speaking lesser known languages, or because the scientists in question consider them too costly to acquire or unlikely to be beneficial. one way to think about this relationship is as a generalization of 'availability bias', in which we take the set of readily recalled information to be more likely, important, or relevant.in these terms, we define 'knowledge collapse' as the progressive narrowing over time (or over technological representations) of the set of human working knowledge and the current human epistemic horizon relative to the set of broad historical knowledge.on a theoretical level, the idea of epistemic horizon has an intellectual heritage in immanuel kant's argument about the forms and categories of understanding that underly the possibility of knowledge. subsequent authors expanded on the implications if these categories are in some way fashioned by one's upbringing and community (e.g.. 14 a related concern is the way that 13 in economic terms, it is the set of information that for which the individual believes the expected returns are greater than the expected costs. this might be considered for a specific task or set of tasks, but could be generalized to the set of knowledge for which she expects positive gains over a period of time, her lifetime, or for society over a finite or infinite horizon with discounting.14 e.g.\"if man received every thing from himself and developed it independently of extrinsic objects, then a history of a man might be possible, but not of men in general. but as our specific character resides precisely in this, that, born almost without instinct, we are raised to manhood only by lifelong practice, on which both the perfectibility as well as the corruptibility of our species rests, so it is precisely thereby that the history of mankind is made a whole: that is, a chain of sociability and formative tradition from the first link to the last.the scientific community can be, at least during certain epochs, bounded by its inherited understanding of the world. as noted above, specific technological forms may generate a flood of information that inhibit the communication of information.finally, one of the challenges presented by the 'epistemic horizon' (as of that of an 'event horizon') is that we cannot observe directly its limits. for example, the presence of an event our current model takes to be very rare (e.g.a \"20-sigma\" event) can suggest our current model is incorrect, but in the absence of such a rare event, we cannot know if the current tails of knowledge are correct or too thin. these considerations suggest the concern of generational knowledge collapse is plausible and an unbounded optimism in the ability of rational actors to update on the value of tail knowledge may be shortsighted."}]}