{
  "id": 8554280533756638830,
  "name": "Viglietta_-_2024_-_History_Trees_and_Their_Applications.grobid.tei.xml",
  "segments": [
    {
      "header": "Introduction",
      "content": "a distributed communication network consists of a finite number of independent computational units known as agents, which can send each other messages and modify their internal states based on the messages they receive. these networks generally operate in synchronous or asynchronous communication steps, where agents send messages through the links of a (multi)graph, which may be static or dynamic, directed or undirected, connected or disconnected, etc.a network is anonymous if its agents are initially indistinguishable, i.e., they lack unique identifiers and can only be told apart by external input or due to the network's layout. in such networks, it is typically assumed that all agents run the same local deterministic algorithm. it is important to note that allowing for randomness would enable agents to generate unique identifiers with high probability, thereby compromising the study's focus on anonymity.a common algorithmic approach in this setting involves assigning a \"weight\" to each agent, which is then distributed among neighbors at each step according to specific rules. this process is analyzed using standard stochastic methods to understand how these weights eventually converge to a common value.although this \"averaging technique\" enabled the development of general algorithms for anonymous networks, one of its major limitations is its disregard for the network's structural and topological characteristics, providing minimal insight into these aspects. furthermore, analyzing these algorithms tends to be technically cumbersome, yielding only asymptotic estimates for how quickly the network reaches convergence or stability.another line of research, initiated by angluin, explores discrete and algebraic structures, such as the views of yamashita-kamedaand the graph fibrations and minimum bases of boldi-vigna. this approach allows algorithms to fully leverage the network's structure and usually permits a more precise analysis of running times. however, the theoretical frameworks of views and graph fibrations were developed for networks with unchanging topologies, and their successful application has been limited to such static networks.history trees are a newer data structure that inherently includes a temporal dimension and was specifically designed for networks with dynamic topologies. the introduction of history trees has recently led to the development of optimal linear-time algorithms for anonymous dynamic networksand state-of-the-art general algorithms for congested anonymous dynamic networks.in section 2, we outline the basic architecture of history trees, drawing comparisons with yamashita-kameda's views and boldi-vigna's minimum bases. additionally, we showcase a straightforward linear-time algorithm for dynamic networks that illustrates the practicality of history trees. in section 3, we discuss more advanced applications of history trees in challenging network situations, while also pointing out a number of areas that remain open for investigation."
    },
    {
      "header": "Basic Structure and Algorithms",
      "content": "in this section we focus on anonymous networks operating in synchronous steps, modeled as undirected dynamic multigraphs with no port awareness. other network models will be discussed in section 3.throughout this section, the reader may find it beneficial to examine the software available at https://github.com/viglietta/dynamic-networks. the repository includes a simulator that supports the creation and visualization of history trees of user-defined dynamic networks and the testing of fundamental algorithms.consider a dynamic network of six anonymous agents whose first four communications steps are as in figure. before the first step (i.e., at time t = 0), each agent only knows its own input, which in our example is represented by a color: either cyan or yellow. in the first communication step, both cyan agents (which are indistinguishable) receive three messages from yellow agents (also indistinguishable). thus, the cyan agents remain indistinguishable at time t = 1.however, two yellow agents receive two messages from cyan agents, but the other two receive only one message. thus, at time t = 1, the two yellow agentsstep 1step 2step 3step 4 in general, since the network is synchronous, at step t > 0 (i.e., between time t -1 and time t) all agents simultaneously send messages and simultaneously receive them (as unordered multisets). two messages are assumed to be identical if and only if they are sent by indistinguishable agents (possibly by the same agent). by definition, at time t = -1 no two agents are distinguishable; at time t = 0 they are distinguishable if and only if they have different inputs. at time t > 0, two agents are distinguishable if and only if they are distinguishable at time t -1 or receive different multisets of messages at step t.history trees were introduced into study how and when anonymous agents in a (dynamic) network become distinguishable. the history tree h g of a network g is an infinite tree subdivided into levels, as in figure, where the nodes in level l t represent the equivalence classes of agents that are indistinguishable at time t. the number of agents in the class represented by a node v is called the anonymity of v and is denoted as a(v). in our example, a(a 1 ) = 2 and a(a 2 ) = 4.the root r represents all agents in the network. in general, the children of a node v \u2208 l t-1 , i.e., the nodes v 1 , v 2 , . . . , v k \u2208 l t that are connected to v by a black edge, represent a partition of the set of agents represented by v. thus,on the other hand, the red edges in r t represent messages sent and received at step t. that is, a directed red edge (v, u) with multiplicity m, where v \u2208 l t-1updating the view of an agent represented by node v after it receives the view of an agent represented by u as a message. the two views are matched and merged starting from the roots, v gets a child v \u2032 , and a new red edge from u to v \u2032 is added.and u \u2208 l t , indicates that, at step t, each agent represented by node u receives exactly m (identical) messages from agents represented by v.assuming that their internal memory and message sizes are unbounded, the agents in a network g can locally construct portions of the history tree called views. more precisely, if an agent p at time t is represented by a node v \u2208 l t , then the view v t g (p) is defined as the portion of h g spanned by all directed paths from the root r to v, using black and red edges indifferently (black edges are assumed to be directed away from the root r). the node v is called the bottom of the view. figureshows an example of a view within a history tree.the distributed construction of views can be achieved via an iterative process, assuming that all agents send their current view to all their neighbors at every step. upon receiving a multiset m of messages, an agent p integrates its current view v t g (p) with all views in m . this is done by a straightforward match-and-merge algorithm, starting from the root and proceeding level by level, as exemplified in figure. the result is the smallest tree containing v t g (p) and all views in m as induced subtrees. to obtain v t+1 g (p), the agent p creates a child v \u2032 for the bottom node v of v t g (p), and connects the bottom nodes of all views in m to v \u2032 by red edges with the appropriate multiplicities. the node v \u2032 is now the bottom of v t+1 g (p) and represents p (and possibly other agents) at time t + 1.it is a simple observation that the view v t g (p) contains all the information that p can possibly extract from the network g after t communication steps.we will now focus on static anonymous networks, which are well understood thanks to the works of yamashita-kameda, boldi-vigna, and other authors.if g is a static network of n agents, once the classes of indistinguishable agents remain unchanged for a single communication step, they must remain unchanged forever. thus, the number of nodes in the levels of h g strictly increases at every level until it stabilizes, say, at level l s . therefore, if |l s | = n, we have 0 \u2264 s < n \u2264 n, because |l 0 | \u2265 1 and each node represents at least one agent.we come to the conclusion that in any network of size n, if two agents are indistinguishable at time t = n -1, they will remain indistinguishable thereafter. this observation was first made by norris (though formulated differently) in, where she also raised the question of whether the same applies to agents in two distinct networks of the same size n. 2 we restate norris' question below.open problem 1. let g and g \u2032 be two disjoint static networks of n agents each. if an agent in g and an agent in g \u2032 have isomorphic views at time t = n -1, do they have isomorphic views at all times?let us consider the subgraph of h g induced by the nodes in levels l s and l s+1 , as highlighted in figurewith a green background. contracting the black edges in this subgraph, we obtain a directed multigraph named g.this is an important structure that has been given many names and equivalent definitions in the literature. essentially, g could be defined as the smallest directed multigraph that gives rise to a history tree isomorphic to h g . yamashita and kameda call g the quotient graph of g and define it in graph-theoretical terms using their own notion of view of a static network, whereas boldi and vigna call g the minimum base of g and give it a topological definition in terms of graph fibrations. 3  notably, since the results concerning static networks from these authors are presented with reference to g, they can be directly rephrased in the language of history trees. the advantage of using history trees lies in their ability to readily offer timing information on when agents become distinguishable. this feature makes history trees particularly suitable for dynamic networks, where g is not well defined and the lack of topological regularity prevents the straightforward deduction of temporal data.before delving into applications of history trees to dynamic networks in section 2.3, let us draw a closer comparison between views of history trees and views in the sense of yamashita-kameda. while it is important not to confuse these two concepts, they bear a deep relationship illustrated in figure.for yamashita and kameda, the view t g (p) of an agent p in a static network g is an infinite tree rooted at p, where each node of depth k represents a distinct 2 by treating the disjoint union of the two networks as a single network of size 2n, it becomes evident that agents that are indistinguishable at time t = 2n -1 are indistinguishable forever. this point was already noted by conway in [8, chapter 1, theorem 7], albeit phrased in terms of moore machines. although t = 2n -1 might not be an optimal bound if both networks have size n (hence norris' question), figureimplies that t = 2n is optimal if they have sizes n and n + 1, respectively. indeed, if the two cyan agents are colored yellow, they become distinguishable after 2n steps, matching the upper bound given by the combined number of agents, 2n + 1. 3 more specifically, g is fibered onto the fibration-prime graph g, and the fibers are precisely the classes of agents represented by the nodes of ls in the history tree hg.fig.. a static network g with a distinguished agent p and its history tree hg (truncated at level l4). at stabilization, the directed graph of the red edges between non-branching levels (highlighted in green in hg) is isomorphic to the boldi-vigna minimum base g. the view v 3 g (p) after step 3 is related to the yamashita-kameda view t 3 g (p) truncated at depth 3, as well as to its tani folded view t 3 g (p), as illustrated. the precise correspondence between these structures is described in section 2.2.walk of length k in g terminating in p. as it turns out, t g (p) truncated at depth k, denoted as t k g (p), contains precisely the information encoded in v k g (p). indeed, starting from v k g (p), we can construct t k g (p) as follows. let us consider the subgraph spanned by the directed paths in v k g (p) terminating in the bottom node using only red edges. such a subgraph is a directed acyclic graph isomorphic to the so-called folded view t k g (p). this is a structure devised by tani into compress t k g (p) from exponential size to polynomial size by conflating equivalent nodes. finally, t k g (p) can easily be unraveled to reconstruct t k g (p). conversely, starting from t k g (p), one can construct an inventory of \"fragments\" by listing all subtrees hanging from different nodes and truncating them at all possible depths. the isomorphism classes of these fragments, when ordered by their height, correspond to the levels of v k g (p), with the \"empty fragment\" being the root. then, the parent of a fragment f in v k g (p) is determined by deleting all the leaves of f . similarly, the fragments of v k g (p) that are connected to f via red edges (and the multiplicities of such red edges) match the subtrees that dangle from the root's children within f . thus, we can constructwe will now describe a general algorithmic technique that can be used to solve a wide range of fundamental problems in networks operating in synchronous steps, modeled as dynamic undirected multigraphs that are connected at every step. albeit being extremely straightforward, this technique achieves optimal running times and matches in efficiency the best algorithms for static networks. as argued in section 2.1, the agents in a network have a distributed algorithm for constructing their view of the history tree and update it at every communication step. since an agent's view encodes all the information that the agent can infer from the network, in principle we can reduce any problem about anonymous networks to a problem about views of history trees.of course, this is true assuming that all agents have enough internal memory and can send large-enough messages to store their views. after t steps, the size of a view is o(tn 2 log m ) bits, where n is the total number of agents and m is the maximum number of messages sent by any agent in a single step. indeed, such a view has t levels, each of which contains at most n nodes and n 2 incoming red edges of multiplicity at most m . in particular, if the view construction algorithm runs for a polynomial number of steps, it requires internal memory and messages of polynomial size. for the time being, we will assume that this is not an issue.the basic technique relies on the following observation. if two nodes u and v in the same level l i of the history tree are non-branching, i.e., they have a unique child u \u2032 and v \u2032 respectively, and there are red edges (u, v \u2032 ) with multiplicity m u,v \u2032 > 0 and (v, u \u2032 ) with multiplicity m v,u \u2032 > 0, then we can count the number of messages exchanged by the agents represented by u and by v asbecause communication links are bidirectional. thus, since we know the multiplicities of the red edges, we can infer the ratio of the anonymities involved. now, if l i is a level where all nodes are non-branching, and since the network is connected at every step by assumption, we can repeatedly apply equation (2) to compute the ratios of the anonymities of all nodes in l i . for example, since level l 1 in figureis non-branching, we can easily deduce that a(b 1 ) = a(b 2 ) = a(b 3 ). then, using equation (1), we can extend the computation to all previous levels, and obtain for instance that 2a(a 1 ) = a(a 2 ). the reader may apply the same method to the history tree in figureto deduce that the ratio between the number of yellow agents and the number of cyan agents is 7.once we have this information, we can solve problems such as average consensus: if the agents are given input numbers, we can compute the fraction of agents that have each input and use it as a weight to compute the mean input.if we are given additional information, such as the total number of agents or the number of agents that have a certain input, we can also compute how many agents have each input. for instance, in figure, if we know that there are two cyan agents, we deduce that there are four yellow ones, because 2a(a 1 ) = a(a 2 ).in particular, if we know that the network contains a unique distinguished agent, typically referred to as a leader, then we can solve the counting problem, which asks to compute the total number of agents, n. thus, in figure, if we know that p is the unique leader, we can deduce from the history tree that n = 8.let us discuss the efficiency of this method. since |l -1 | = 1 and the number of nodes per level is at most n, it follows that it is sufficient to inspect the history tree up to level l n-1 to find a non-branching level and the relative red edges.a subtler issue is how long it takes before the views of all agents acquire all nodes (and hence all edges) up to l n-1 , so that all agents can carry out correct computations locally. in figure, for instance, since level l 0 is non-branching in the highlighted view (because node b 3 is not in the view), at time t = 2 the cyan agents may be deceived and incorrectly deduce that 3a(a 1 ) = 2a(a 2 ).recall that the network is assumed to be connected at all steps. so, it takes fewer than n steps for information to travel from any agent to any other agent; in other words, the dynamic diameter d is at most n -1. indeed, if k < n agents have some information at time t, then at least k + 1 agents have it at time t + 1.hence, it takes at most d steps for a node in the history tree to appear in the views of all agents. in particular, at time n + d -1 \u2264 2n -2, all agents have the entirety of l n-1 in their views, and thus have enough information to do correct computations. for example, in figure, knowing all levels of h g up to l 3 is enough, but these levels entirely appear in the view of p only at step 7. in fact, the diameter of the network g is d = 4.this technique yields an algorithm for average consensus that stabilizes in 2n -2 steps. that is, if all agents attempt to compute the average of the input values after every step, they may guess it incorrectly for some time, but will be all correct after 2n -2 steps at the latest. the same upper bound holds for the counting problem, assuming the presence of a unique leader in the network.a downside of this method is that it provides no certificate of correctness, and therefore the algorithm is supposed to run indefinitely. however, if n is known to the agents, they can simply count 2n -2 steps, do all computations on the first n -1 levels, and then terminate returning the correct output. similarly, if an agent knows the dynamic diameter d, it can terminate at time t if its view contains a non-branching level l i with i < td, because all levels up to l i+1 are guaranteed to be entirely in the view. this occurs by the time t = n + d -1.finally, let us discuss lower bounds. figureshows two networks of sizes n and n + 1 whose leaders have the same view up to step 2n -2. since agents with equal views must return equal outputs (assuming they execute the same algorithm), it easily follows that there is no counting algorithm that terminates in 2n -2 steps or stabilizes in 2n -4 steps in both networks. for if there were such an algorithm, then both leaders would return the same output, and at least one of them would be incorrect. note that this almost matches the running time of the stabilizing counting algorithm given above, which is 2n -2 steps. this leaves only a small gap: namely, whether 2n -3 steps are actually sufficient.open problem 2. can a counting algorithm stabilize in 2n -3 steps in all connected undirected dynamic networks with a unique leader?as for average consensus, if the two cyan agents in figureare colored yellow, then they have the same view up to step 2n -1. this implies that no average consensus algorithm can stabilize in 2n -3 steps in all networks, and therefore the one described above, which stabilizes in 2n -2 steps, is optimal.3 variations and extensions"
    },
    {
      "header": "Leader Election",
      "content": "another application of the technique in section 2.3 is leader election, where all agents have to agree on a unique representative to be identified as the \"leader\". of course, this problem has a solution only if the history tree contains a node of anonymity 1; as it turns out, this condition is also sufficient.a simple leader election algorithm, at step t, computes the ratios of all anonymities in the first non-branching level occurring after l \u230at/2\u230b and deterministically picks a node of smallest anonymity as representing the leader. this strategy eventually elects a unique leader if and only if it is possible to do so, but no certificate of correctness is provided, and the algorithm has to run indefinitely.however, if n is known, then anonymities in non-branching levels can be computed exactly with a known delay of n -1 steps. in this case, any agent that becomes distinguishable from all others at time t can be identified with certainty by time t + 2n -2, allowing all agents to terminate.in section 2.3 we gave a counting algorithm for connected undirected dynamic networks with a unique leader that stabilizes in 2n -2 steps. at the cost of n additional communication steps, we can implement a correctness certificate and make all agents return n and terminate. the algorithm's details are somewhat intricate and can be found in; here we will merely sketch the main ideas.if we know the anonymities of a node u and of all its children, then u is called a guesser. if there is a red edge directed from u to a node v of unknown anonymity, we can write an equation similar to equation (2) to count messages exchanged by the corresponding agents. solving this equation yields a guess g(v) on a(v) in terms of known anonymities and multiplicities of red edges. as it turns out, g(v) \u2265 a(v) always holds; moreover, if v has no siblings, g(v) = a(v).clearly, the nodes representing the leader are always guessers, because their anonymity is 1. using these nodes, we can make initial guesses on at least one node per level. the question is how we can determine which guesses are correct without knowing the whole history tree, but only a view of it.let us define the weight w(v) of a node v as the number of guesses that have been made on nodes in the subtree hanging from v (including on v itself). then, v is said to be heavy if w(v) \u2265 g(v). the key observation is that, if guesses are well spread, i.e., no two sibling nodes are assigned a guess, then the deepest heavy node necessarily has a correct guess.hence, in figure, the nodes in (a)-(d) with a blue number have a correct guess, but the one in (e) may not. for (a), this is obvious: since g(v) = 1 and g(v) \u2265 a(v), we must conclude that a(v) = 1 and the guess is correct. as for (b), if the lower node u has a correct guess, then the upper node v has a correct guess too, because 2 = g(v) \u2265 a(v) \u2265 a(u) = g(u) = 2, hence g(v) = a(v). otherwise, the guess on u is incorrect, and so u must have a sibling (perhaps not in the view). hence, 2 = g(v) \u2265 a(v) \u2265 2, and the guess on v is correct. the reader may verify that a similar line of reasoning applies to (c) and (d) but not to (e). it is not difficult to see that, if there are at least n well-spread nodes with guesses, then some of them must be heavy, and thus the deepest of them is necessarily correct. in this way, we can steadily determine the anonymities of new nodes. eventually, some of these nodes become guessers themselves and can be used to make new guesses, and so on. since the network is connected at all steps, it can be shown that only 2n -2 levels of the history tree are required for this algorithm to eventually identify nodes with correct guesses on all branches.adding up the anonymities of nodes on all branches produces an estimate n \u2032 on the actual size of the network, n. in general we have n \u2032 \u2264 n, because the current view may not include all branches of the history tree. to confirm this estimate, it is sufficient to wait an additional n \u2032 steps, which is the longest time it may take for at least one missing branch to appear in the view, if one exists.overall, this counting algorithm terminates in 3n -2 steps in the worst case, leaving a small gap with the lower bound of 2n -2 steps given in section 2.3.steps in all connected undirected dynamic networks with a unique leader?the previous counting algorithm was generalized into networks where the leader may not be unique, but there is a known number \u2113 \u2265 1 of indistinguishable leaders, or supervisors. note that the history tree may contain several branches corresponding to leaders; the challenge posed by this scenario is that the individual anonymities of such branches are unknown (although their sum is \u2113).the state-of-the-art solution given ininvolves subdividing the history tree into \u2113 intervals, each of at most (\u2113 + 1)n levels. the total running time is roughly (\u2113 2 + \u2113 + 1)n steps, making this algorithm impractical unless \u2113 is small.in fact, it is a major open question whether a larger \u2113 may actually be helpful.open problem 4. in connected undirected dynamic networks with a known number \u2113 of leaders, how does the optimal running time of terminating counting algorithms scale with \u2113? fig.. two directed static networks with a unique leader and no outdegree awareness that have a different number of agents but the same history tree.generalizing the scenario of section 2, we may consider directed networks, i.e., networks with unidirectional links. it is important to recognize that, in these networks, even solving basic problems such as average consensus or counting with a unique leader requires some additional assumptions, as figuredemonstrates. a reasonable approach is to assume that, in each step, agents are aware of their outdegree either before (early outdegree awareness) or after (late outdegree awareness) they transmit their messages. the key distinction is that in the early awareness model, an agent can incorporate its current outdegree into the messages it sends. here we will focus on the late outdegree awareness model, which is less advantageous especially in dynamic networks.the basic history tree architecture can be extended by attaching outdegrees to black edges, as in figure. we can then identify a non-branching level l i in the history tree, as in section 2.3, and use outdegrees and multiplicities of red edges to write linear equations generalizing equation (2), as shown in figure.the resulting homogeneous system is represented by an irreducible matrix a, assuming the network is strongly connected at every step. note that a = \u03bbi -p , where \u03bb > 0 and p \u2265 0 is also an irreducible matrix. in our example,we have ax = 0, where x > 0 is the vector of anonymities of the nodes in l i . hence, p x = \u03bbx. by the perron-frobenius theorem, \u03bb is a simple eigenvalue of p , and thus 0 is a simple eigenvalue of a. in other words, the nullity of a is 1, which means we can solve the linear system in terms of a single free variable.thus, we can find the ratios between the anonymities of all nodes in l i , or compute them exactly if there is a known number \u2113 \u2265 1 of leaders in the network.this technique yields stabilizing average consensus and counting algorithms for strongly connected directed dynamic networks with late outdegree awareness, generalizing the ones in section 2.3. the stabilization time of these algorithms is again 2n -2 steps, which is optimal. we now present a terminating counting algorithm for directed networks with late outdegree awareness and a known number \u2113 \u2265 1 of leaders. every agent waits until its view contains a long-enough interval i of non-branching levels. the goal is to find an upper bound u i on the anonymity of a node v i in each branch b i within i. to start, we take u 1 = \u2113, where b 1 is any leader branch.the algorithm repeatedly uses branches with a known upper bound to determine new upper bounds. namely, let b i have a known upper bound u i \u2265 a(v i ) and consider all red edges (v, v \u2032 ), where v is a descendant of v i within i. each of these yields an estimate \u03b4u i on a(v \u2032 ), where \u03b4 is the outdegree corresponding to the child of v in b i . note that, if v has a unique child in the history tree, at most \u03b4u i messages are sent from agents represented by v, and so \u03b4u i \u2265 a(v \u2032 ). nonetheless, even if v is not branching in a view, it may still branch in the history tree, and in this case \u03b4u i may not be a correct upper bound. however, this undesirable event may occur at most u i -1 times. thus, as soon as a branch b j receives estimates from b i on u i nodes, we take the maximum estimate as a correct upper bound u j on the anonymity of the deepest such node v j in b j .when we finally have an upper bound for all branches in i, we wait i u i additional steps to confirm that there are no branches missing from the view. then we run the previous stabilizing counting algorithm and output the result.assuming that the network is simple and strongly connected at all steps, this algorithm terminates in 2 o(n log n) steps, which is likely far from optimal.open problem 5. can a counting algorithm terminate in a polynomial number of steps in all strongly connected directed dynamic simple networks with (early or late) outdegree awareness and a unique leader?for networks that are not necessarily connected at all steps, we define a communication round as a minimal sequence of consecutive steps whose communication multigraphs have a (strongly) connected sum (constructed by adding together their adjacency matrices). a network is \u03c4 -union-connected if every block of \u03c4 consecutive steps contains a communication round. it was observed inthat \u03c4 and the dynamic diameter d are related by the tight inequalities \u03c4 \u2264 d \u2264 \u03c4 (n -1).\u2032 b \u2032 a fig.. two agents in a semi-synchronous network share their views a and b, which are updated as a \u2032 and b \u2032 . note that red edges may go upward or skip multiple levels. the highlighted nodes are the \"bottom nodes\" of their respective views, which can be identified as the only sinks (assuming black edges are directed away from the root).clearly, any non-trivial terminating computation is impossible if the agents know nothing about \u03c4 . on the other hand, with knowledge of \u03c4 , all of the previous algorithms can be straightforwardly adapted to \u03c4 -union-connected networks. it is sufficient for each agent to accumulate incoming messages at every step, updating its view only once every \u03c4 steps. this adaptation slows down all running times by a factor of \u03c4 . however, this is worst-case optimal, since a \u03c4 -union-connected network may be devoid of links except at steps that are multiples of \u03c4 .as for stabilizing computations, they can be done even with no knowledge of \u03c4 , again with a worst-case optimal slowdown by a factor of \u03c4 , as detailed in.in a network operating semi-synchronously, any agent may unpredictably be inactive at any step. an inactive agent does not communicate with other agents and does not even update its state. this model is called \"asynchronous\" by boldi-vignaand generalizes the asynchronous starts of charron-bost-moran, but we will give the term \"asynchronous\" a more extensive meaning in section 3.6.the concept of a round and the parameter \u03c4 are defined as in section 3.4. a notable distinction from the synchronous models discussed so far is that agents in a semi-synchronous network cannot reliably count communication steps, because they do not know for how many steps they have been inactive. hence, two views shared by two agents may not have the same height, as the ones in figure.consequently, a red edge no longer has to connect a level to the next, but can span any number of levels. however, it is always possible to restore this property by adding dummy nodes to represent inactive agents, resulting in an equalized view (figure). thus, we can reduce any semi-synchronous network to an equivalent synchronous one with the same parameter \u03c4 and apply the methods outlined in section 3.4 to obtain algorithms with the same running times. fig.. equalizing the view of an agent in a semi-synchronous network by adding dummy nodes. in the resulting view, every red edge connects a level to the next.a network is asynchronous if messages can take an arbitrary, independent, and unpredictable amount of time to reach their destinations. such a network is necessarily directed, and therefore some form of outdegree awareness is needed, as argued in section 3.3. a round is now any minimal interval of time such that the messages that are sent and received form a strongly connected multigraph.observe that, even in asynchronous networks, time can always be discretized, assuming that no agent can send an infinite number of messages in a finite time.also, doing non-trivial computations with termination in asynchronous networks with no knowledge about the duration of a round is impossible.however, there is a simple stabilization algorithm, as follows. when an agent sends some messages, it expands its view by adding a child to the bottom node and attaches its outdegree to the corresponding black edge, as in section 3.3. when it receives a multiset of messages, it updates its view as in section 3.5.then, the agent seeks the first interval of levels constituting a round where all nodes are non-branching. the outdegrees and red edges in this interval yield a system of equations that is solved as in the stabilizing algorithm of section 3.3.such a non-branching interval occurs in the history tree after at most n -1 rounds and appears in the agent's view in at most n -1 additional rounds. the total stabilization time is therefore 2n -2 rounds, which is worst-case optimal.a widely studied scenario, especially within static networks, is when each agent has a local numbering for its incoming links (input port awareness) or outgoing links (output port awareness). it is evident that, although input port awareness enables each agent in a static network to identify all messages sent by the same neighbor, this feature has no clear meaning or effect in dynamic networks.in contrast, output port awareness has a significant impact on both static and dynamic networks, as it not only implies outdegree awareness, but allows agents to assign a different tag to each message they send within a communication step. this is helpful in breaking network symmetry, thus facilitating certain computations. the history tree architecture for outdegree awareness of section 3.3 can also be adapted to this model by simply attaching a port number to each red edge.as an example, output port awareness combined with a unique leader makes the counting problem particularly simple even in strongly connected directed dynamic networks. indeed, all messages sent by the leader in a communication step have different tags, and so all agents that receive them become distinguishable. generalizing, every node on a red path starting at a leader node must have an anonymity of 1. when a whole level l i in a view consists of such nodes, we can check if the outdegree of each node in l i matches the number of its outgoing red edges. if so, all agents have been accounted for, and we can return n = |l i |.this counting algorithm terminates in 2n -1 steps, greatly improving upon the one in section 3.2. observe that the lower bound in figuredoes not hold for networks with output port awareness, which may allow for even faster solutions.open problem 6. can a counting algorithm terminate in fewer than 2n -2 steps in all strongly connected directed dynamic networks with output port awareness and a unique leader?a less obvious fact is that, in any non-branching level of the history tree of a strongly connected directed dynamic network with output port awareness, all nodes must have the same anonymity.indeed, if a and b are two classes of indistinguishable agents represented by nodes in a non-branching level, and an agent in a receives a message tagged k from an agent in b, then so do all agents in a (or else their node would branch). since no agent in b can send more than one message tagged k, we have |a| \u2264 |b|. repeating this reasoning for all pairs of communicating classes, and recalling that the network is strongly connected, we conclude that all classes must have the same size.a remarkable consequence is that, with output port awareness, a unique leader can be elected if and only if it is possible to assign unique identifiers to all agents (also known as the naming problem). a terminating algorithm for both problems, if n is known, is easily obtained by combining the leader election algorithm in section 3.1 (which was designed for undirected networks only) with the stabilizing technique for directed networks in section 3.3.suppose that agents have inputs that may change at every step. note that the history tree architecture already supports attaching inputs to nodes, and so the basic stabilizing algorithms previously discussed can become streaming algorithms that adaptively return the correct output with an amortized delay of n -1 steps. 2 fig.. a routine in the universal self-stabilizing protocol: delete level l0 in the view, and then repeatedly merge nodes whose corresponding sub-views are isomorphic.a network algorithm is self-stabilizing if it returns the correct output regardless of the initial state of the agents. this implies tolerance to memory corruption, transient faults, and agents dynamically joining and leaving the network.let us assume the network to be synchronous, directed, and dynamic. we remark that most existing self-stabilizing protocols, such as boldi-vigna's, are specifically designed for static networks, and cause agents to perpetually and incorrectly reset their states when executed in highly dynamic networks.we will give a universal self-stabilizing protocol that constructs coherent views, allowing to convert any stabilizing algorithm into a self-stabilizing one (note that non-trivial terminating computations are impossible in this scenario).the core idea is that an agent can deliberately \"forget\" old information by deleting level l 0 of its current view, connect level l 1 to the root, and merge equivalent nodes from top to bottom to restore a well-formed view, as in figure.if the number of agents n is known, they can simply update their views as usual (resetting their state if it does not encode a well-formed view) and delete old levels when their number exceeds some fixed threshold, e.g., 2n -2. eventually, this protocol produces views that correctly describe the last 2n-2 communication steps, which are enough for the stabilizing algorithms of sections 2.3 and 3.3.on the other hand, if n is unknown, every agent updates its view as usual, but deletes level l 0 every two steps. this is controlled by a local binary flag that is toggled at every step. however, before merging its view with a neighbor's view of different height, it deletes the top levels of the taller view to match the other. also, if the taller view was its own, the agent does not toggle its flag for a step.in o(n) steps, all agents have views of equal height, as well as equal flags. moreover, their views eventually describe an increasingly large number of previous communication steps, enabling any stabilizing algorithm to work correctly. open problem 7. is there a universal self-stabilizing protocol for semisynchronous strongly connected directed dynamic networks?the stabilizing algorithms described so far assume that all agents constantly update their views at every step, which requires an unlimited amount of internal memory. to mitigate this, we will now give a universal finite-state protocol that enables the conversion of any stabilizing algorithm into one that uses a finite amount of memory (as a function of n), albeit with an extra delay.let us assume the network to be synchronous, undirected, connected, and dynamic. a level l i in a view is said to be suitable if every node in l i-1 has a unique child in l i and the red edges between these two levels are compatible with a connected network. recall that the basic stabilizing algorithms of section 2.3 do all computations using only the shallowest suitable level of a view. now, when two neighboring agents share views whose shallowest suitable levels are isomorphic, they do not merge their views. essentially, this removes a link from the communication network for that step. also, when an agent receives no views that it can merge, it skips updating its view altogether, i.e., it remains inactive for that step. note that this makes the network semi-synchronous, so views must be equalized prior to being used by the protocol (see section 3.5).according to this protocol, if all agents remain inactive forever, they all share the same suitable level, which is enough to perform correct computations. otherwise, some inactive agent acquires relevant information within n -1 steps and reactivates. moreover, since there are at most n -1 branching nodes in the history tree, the agents can incorrectly guess a suitable level at most n -1 times. thus, the protocol is finite-state, but introduces an overhead of o(n 2 ) steps.open problem 8. is there a universal finite-state stabilizing protocol for connected undirected dynamic networks with an overhead of o(n) steps?another open problem is to design a protocol that is both self-stabilizing and finite-state. in section 3.9 we already gave one, but it assumes n to be known.open problem 9. is there a universal finite-state self-stabilizing protocol for connected undirected dynamic networks of unknown size?an agent is memoryless if its state is reset at every communication step, meaning its entire memory is erased after it sends messages and before receiving messages from neighbors. the goal is to design a universal protocol that enables memoryless agents to construct coherent views of some history tree related to the network. this would allow basic algorithms to run correctly within the memoryless model.. under what assumptions is there a universal memoryless protocol for anonymous networks?in a congested network of n agents, communication links have a logarithmic bandwidth, and therefore the size of each message is limited to o(log n) bits.it is evident that the basic technique of encoding a view as a single message is not applicable in a congested network, because the size of a view grows polynomially at every step (see section 2.3). furthermore, any naive approach that simply subdivides a view into smaller pieces to be transmitted over multiple steps is clearly ineffective in anonymous dynamic networks.correct protocols for constructing views in congested dynamic networks are found in. if the dynamic diameter d is known, then o(log n) bits of information can be reliably broadcast in phases of d steps. this makes it possible for agents to share enough information to construct a history tree that is compatible with their network, one level at a time. every node in this history tree has a unique label of logarithmic size, which also identifies all agents represented by that node. this protocol can be used to solve the counting problem in o(dn 2 ) steps.if d is unknown but there is a unique leader, there is a more complex protocol that attempts to estimate d by implementing a reset module that repeatedly doubles the estimate every time a broadcasting error is detected. the leader coordinates the process, ensuring that all agents agree on the same version of the history tree. this yields a counting algorithm that terminates in o(n 3 ) steps.open problem 11. is there a terminating counting algorithm for congested dynamic networks with more than one leader ? it was proved inthat solving the counting problem in congested networks by broadcasting \"tokens\" requires at least \u03c9(n 2 / log n) steps. on the other hand, there is a solution in o(n 2 ) steps if messages have size o(n log n) bits.open problem 12. can a counting algorithm terminate in o(n 2 ) steps in all congested dynamic networks with a unique leader?we find it fitting to conclude this note with an open problem that is unlikely to have a solution using history trees.open problem 13. is there a terminating counting algorithm for congested dynamic networks where agents have logarithmic-sized memory?"
    }
  ]
}
