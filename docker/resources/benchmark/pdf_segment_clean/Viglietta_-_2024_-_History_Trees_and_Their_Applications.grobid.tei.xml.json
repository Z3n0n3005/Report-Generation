{
  "id": "Vigliett",
  "name": "Viglietta_-_2024_-_History_Trees_and_Their_Applications.grobid.tei.xml",
  "segments": [
    {
      "header": "Introduction",
      "content": "A distributed communication network consists of a finite number of independent computational units known as agents, which can send each other messages and modify their internal states based on the messages they receive. These networks generally operate in synchronous or asynchronous communication steps, where agents send messages through the links of a (multi)graph, which may be static or dynamic, directed or undirected, connected or disconnected, etc. A common algorithmic approach in this setting involves assigning a \"weight\" to each agent, which is then distributed among neighbors at each step according to specific rules. This process is analyzed using standard stochastic methods to understand how these weights eventually converge to a common value Although this \"averaging technique\" enabled the development of general algorithms for anonymous networks, one of its major limitations is its disregard for the network's structural and topological characteristics, providing minimal insight into these aspects. Furthermore, analyzing these algorithms tends to be technically cumbersome, yielding only asymptotic estimates for how quickly the network reaches convergence or stability.Another line of research, initiated by Angluin History trees are a newer data structure that inherently includes a temporal dimension and was specifically designed for networks with dynamic topologies. The introduction of history trees has recently led to the development of optimal linear-time algorithms for anonymous dynamic networks In Section 2, we outline the basic architecture of history trees, drawing comparisons with Yamashita-Kameda's views and Boldi-Vigna's minimum bases. Additionally, we showcase a straightforward linear-time algorithm for dynamic networks that illustrates the practicality of history trees. In Section 3, we discuss more advanced applications of history trees in challenging network situations, while also pointing out a number of areas that remain open for investigation."
    },
    {
      "header": "Basic Structure and Algorithms",
      "content": "In this section we focus on anonymous networks operating in synchronous steps, modeled as undirected dynamic multigraphs with no port awareness. Other network models will be discussed in Section 3.Throughout this section, the reader may find it beneficial to examine the software available at https://github.com/viglietta/Dynamic-Networks. The repository includes a simulator that supports the creation and visualization of history trees of user-defined dynamic networks and the testing of fundamental algorithms.Consider a dynamic network of six anonymous agents whose first four communications steps are as in Figure However, two yellow agents receive two messages from cyan agents, but the other two receive only one message. Thus, at time t = 1, the two yellow agentsStep 1Step 2Step 3Step 4 In general, since the network is synchronous, at step t > 0 (i.e., between time t -1 and time t) all agents simultaneously send messages and simultaneously receive them (as unordered multisets). Two messages are assumed to be identical if and only if they are sent by indistinguishable agents (possibly by the same agent). By definition, at time t = -1 no two agents are distinguishable; at time t = 0 they are distinguishable if and only if they have different inputs. At time t > 0, two agents are distinguishable if and only if they are distinguishable at time t -1 or receive different multisets of messages at step t.History trees were introduced in The root r represents all agents in the network. In general, the children of a node v \u2208 L t-1 , i.e., the nodes v 1 , v 2 , . . . , v k \u2208 L t that are connected to v by a black edge, represent a partition of the set of agents represented by v. Thus,On the other hand, the red edges in R t represent messages sent and received at step t. That is, a directed red edge (v, u) with multiplicity m, where v \u2208 L t-1Updating the view of an agent represented by node v after it receives the view of an agent represented by u as a message. The two views are matched and merged starting from the roots, v gets a child v \u2032 , and a new red edge from u to v \u2032 is added.and u \u2208 L t , indicates that, at step t, each agent represented by node u receives exactly m (identical) messages from agents represented by v.Assuming that their internal memory and message sizes are unbounded, the agents in a network G can locally construct portions of the history tree called views. More precisely, if an agent p at time t is represented by a node v \u2208 L t , then the view V t G (p) is defined as the portion of H G spanned by all directed paths from the root r to v, using black and red edges indifferently (black edges are assumed to be directed away from the root r). The node v is called the bottom of the view. Figure The distributed construction of views can be achieved via an iterative process, assuming that all agents send their current view to all their neighbors at every step. Upon receiving a multiset M of messages, an agent p integrates its current view V t G (p) with all views in M . This is done by a straightforward match-and-merge algorithm, starting from the root and proceeding level by level, as exemplified in Figure It is a simple observation that the view V t G (p) contains all the information that p can possibly extract from the network G after t communication steps We will now focus on static anonymous networks, which are well understood thanks to the works of Yamashita-Kameda, Boldi-Vigna, and other authors.If G is a static network of n agents, once the classes of indistinguishable agents remain unchanged for a single communication step, they must remain unchanged forever. Thus, the number of nodes in the levels of H G strictly increases at every level until it stabilizes, say, at level L s . Therefore, if |L s | = n, we have 0 \u2264 s < n \u2264 n, because |L 0 | \u2265 1 and each node represents at least one agent.We come to the conclusion that in any network of size n, if two agents are indistinguishable at time t = n -1, they will remain indistinguishable thereafter. This observation was first made by Norris (though formulated differently) in Open Problem 1. Let G and G \u2032 be two disjoint static networks of n agents each. If an agent in G and an agent in G \u2032 have isomorphic views at time t = n -1, do they have isomorphic views at all times?Let us consider the subgraph of H G induced by the nodes in levels L s and L s+1 , as highlighted in Figure This is an important structure that has been given many names and equivalent definitions in the literature. Essentially, G could be defined as the smallest directed multigraph that gives rise to a history tree isomorphic to H G . Yamashita and Kameda call G the quotient graph of G and define it in graph-theoretical terms using their own notion of view of a static network Before delving into applications of history trees to dynamic networks in Section 2.3, let us draw a closer comparison between views of history trees and views in the sense of Yamashita-Kameda For Yamashita and Kameda, the view T G (p) of an agent p in a static network G is an infinite tree rooted at p, where each node of depth k represents a distinct 2 By treating the disjoint union of the two networks as a single network of size 2n, it becomes evident that agents that are indistinguishable at time t = 2n -1 are indistinguishable forever. This point was already noted by Conway in [8, Chapter 1, Theorem 7], albeit phrased in terms of Moore machines. Although t = 2n -1 might not be an optimal bound if both networks have size n (hence Norris' question), Figure Fig. walk of length k in G terminating in p. As it turns out, T G (p) truncated at depth k, denoted as T k G (p), contains precisely the information encoded in V k G (p). Indeed, starting from V k G (p), we can construct T k G (p) as follows. Let us consider the subgraph spanned by the directed paths in V k G (p) terminating in the bottom node using only red edges. Such a subgraph is a directed acyclic graph isomorphic to the so-called folded view T k G (p). This is a structure devised by Tani in We will now describe a general algorithmic technique that can be used to solve a wide range of fundamental problems in networks operating in synchronous steps, modeled as dynamic undirected multigraphs that are connected at every step. Albeit being extremely straightforward, this technique achieves optimal running times and matches in efficiency the best algorithms for static networks. As argued in Section 2.1, the agents in a network have a distributed algorithm for constructing their view of the history tree and update it at every communication step. Since an agent's view encodes all the information that the agent can infer from the network, in principle we can reduce any problem about anonymous networks to a problem about views of history trees.Of course, this is true assuming that all agents have enough internal memory and can send large-enough messages to store their views. After t steps, the size of a view is O(tn 2 log M ) bits, where n is the total number of agents and M is the maximum number of messages sent by any agent in a single step. Indeed, such a view has t levels, each of which contains at most n nodes and n 2 incoming red edges of multiplicity at most M . In particular, if the view construction algorithm runs for a polynomial number of steps, it requires internal memory and messages of polynomial size. For the time being, we will assume that this is not an issue.The basic technique relies on the following observation. If two nodes u and v in the same level L i of the history tree are non-branching, i.e., they have a unique child u \u2032 and v \u2032 respectively, and there are red edges (u, v \u2032 ) with multiplicity m u,v \u2032 > 0 and (v, u \u2032 ) with multiplicity m v,u \u2032 > 0, then we can count the number of messages exchanged by the agents represented by u and by v asbecause communication links are bidirectional. Thus, since we know the multiplicities of the red edges, we can infer the ratio of the anonymities involved. Now, if L i is a level where all nodes are non-branching, and since the network is connected at every step by assumption, we can repeatedly apply Equation (2) to compute the ratios of the anonymities of all nodes in L i . For example, since level L 1 in Figure Once we have this information, we can solve problems such as Average Consensus: if the agents are given input numbers, we can compute the fraction of agents that have each input and use it as a weight to compute the mean input.If we are given additional information, such as the total number of agents or the number of agents that have a certain input, we can also compute how many agents have each input. For instance, in Figure In particular, if we know that the network contains a unique distinguished agent, typically referred to as a leader, then we can solve the Counting problem, which asks to compute the total number of agents, n. Thus, in Figure Let us discuss the efficiency of this method. Since |L -1 | = 1 and the number of nodes per level is at most n, it follows that it is sufficient to inspect the history tree up to level L n-1 to find a non-branching level and the relative red edges.A subtler issue is how long it takes before the views of all agents acquire all nodes (and hence all edges) up to L n-1 , so that all agents can carry out correct computations locally. In Figure Recall that the network is assumed to be connected at all steps. So, it takes fewer than n steps for information to travel from any agent to any other agent; in other words, the dynamic diameter d is at most n -1. Indeed, if k < n agents have some information at time t, then at least k + 1 agents have it at time t + 1.Hence, it takes at most d steps for a node in the history tree to appear in the views of all agents. In particular, at time n + d -1 \u2264 2n -2, all agents have the entirety of L n-1 in their views, and thus have enough information to do correct computations. For example, in Figure This technique yields an algorithm for Average Consensus that stabilizes in 2n -2 steps. That is, if all agents attempt to compute the average of the input values after every step, they may guess it incorrectly for some time, but will be all correct after 2n -2 steps at the latest. The same upper bound holds for the Counting problem, assuming the presence of a unique leader in the network.A downside of this method is that it provides no certificate of correctness, and therefore the algorithm is supposed to run indefinitely. However, if n is known to the agents, they can simply count 2n -2 steps, do all computations on the first n -1 levels, and then terminate returning the correct output. Similarly, if an agent knows the dynamic diameter d, it can terminate at time t if its view contains a non-branching level L i with i < td, because all levels up to L i+1 are guaranteed to be entirely in the view. This occurs by the time t = n + d -1.Finally, let us discuss lower bounds. Figure Open Problem 2. Can a Counting algorithm stabilize in 2n -3 steps in all connected undirected dynamic networks with a unique leader?As for Average Consensus, if the two cyan agents in Figure 3 Variations and Extensions"
    },
    {
      "header": "Leader Election",
      "content": "Another application of the technique in Section 2.3 is Leader Election, where all agents have to agree on a unique representative to be identified as the \"leader\". Of course, this problem has a solution only if the history tree contains a node of anonymity 1; as it turns out, this condition is also sufficient.A simple Leader Election algorithm, at step t, computes the ratios of all anonymities in the first non-branching level occurring after L \u230at/2\u230b and deterministically picks a node of smallest anonymity as representing the leader. This strategy eventually elects a unique leader if and only if it is possible to do so, but no certificate of correctness is provided, and the algorithm has to run indefinitely.However, if n is known, then anonymities in non-branching levels can be computed exactly with a known delay of n -1 steps. In this case, any agent that becomes distinguishable from all others at time t can be identified with certainty by time t + 2n -2, allowing all agents to terminate.In Section 2.3 we gave a Counting algorithm for connected undirected dynamic networks with a unique leader that stabilizes in 2n -2 steps. At the cost of n additional communication steps, we can implement a correctness certificate and make all agents return n and terminate. The algorithm's details are somewhat intricate and can be found in If we know the anonymities of a node u and of all its children, then u is called a guesser. If there is a red edge directed from u to a node v of unknown anonymity, we can write an equation similar to Equation (2) to count messages exchanged by the corresponding agents. Solving this equation yields a guess g(v) on a(v) in terms of known anonymities and multiplicities of red edges. As it turns out, g(v) \u2265 a(v) always holds; moreover, if v has no siblings, g(v) = a(v).Clearly, the nodes representing the leader are always guessers, because their anonymity is 1. Using these nodes, we can make initial guesses on at least one node per level. The question is how we can determine which guesses are correct without knowing the whole history tree, but only a view of it.Let us define the weight w(v) of a node v as the number of guesses that have been made on nodes in the subtree hanging from v (including on v itself). Then, v is said to be heavy if w(v) \u2265 g(v). The key observation is that, if guesses are well spread, i.e., no two sibling nodes are assigned a guess, then the deepest heavy node necessarily has a correct guess.Hence, in Figure Adding up the anonymities of nodes on all branches produces an estimate n \u2032 on the actual size of the network, n. In general we have n \u2032 \u2264 n, because the current view may not include all branches of the history tree. To confirm this estimate, it is sufficient to wait an additional n \u2032 steps, which is the longest time it may take for at least one missing branch to appear in the view, if one exists.Overall, this Counting algorithm terminates in 3n -2 steps in the worst case, leaving a small gap with the lower bound of 2n -2 steps given in Section 2.3.steps in all connected undirected dynamic networks with a unique leader?The previous Counting algorithm was generalized in The state-of-the-art solution given in In fact, it is a major open question whether a larger \u2113 may actually be helpful.Open Problem 4. In connected undirected dynamic networks with a known number \u2113 of leaders, how does the optimal running time of terminating Counting algorithms scale with \u2113? Fig. Generalizing the scenario of Section 2, we may consider directed networks, i.e., networks with unidirectional links. It is important to recognize that, in these networks, even solving basic problems such as Average Consensus or Counting with a unique leader requires some additional assumptions, as Figure The basic history tree architecture can be extended by attaching outdegrees to black edges, as in Figure The resulting homogeneous system is represented by an irreducible matrix A, assuming the network is strongly connected at every step. Note that A = \u03bbI -P , where \u03bb > 0 and P \u2265 0 is also an irreducible matrix. In our example,We have Ax = 0, where x > 0 is the vector of anonymities of the nodes in L i . Hence, P x = \u03bbx. By the Perron-Frobenius theorem, \u03bb is a simple eigenvalue of P , and thus 0 is a simple eigenvalue of A. In other words, the nullity of A is 1, which means we can solve the linear system in terms of a single free variable.Thus, we can find the ratios between the anonymities of all nodes in L i , or compute them exactly if there is a known number \u2113 \u2265 1 of leaders in the network.This technique yields stabilizing Average Consensus and Counting algorithms for strongly connected directed dynamic networks with late outdegree awareness, generalizing the ones in Section 2.3. The stabilization time of these algorithms is again 2n -2 steps, which is optimal. We now present a terminating Counting algorithm for directed networks with late outdegree awareness and a known number \u2113 \u2265 1 of leaders. Every agent waits until its view contains a long-enough interval I of non-branching levels. The goal is to find an upper bound U i on the anonymity of a node v i in each branch B i within I. To start, we take U 1 = \u2113, where B 1 is any leader branch.The algorithm repeatedly uses branches with a known upper bound to determine new upper bounds. Namely, let B i have a known upper bound U i \u2265 a(v i ) and consider all red edges (v, v \u2032 ), where v is a descendant of v i within I. Each of these yields an estimate \u03b4U i on a(v \u2032 ), where \u03b4 is the outdegree corresponding to the child of v in B i . Note that, if v has a unique child in the history tree, at most \u03b4U i messages are sent from agents represented by v, and so \u03b4U i \u2265 a(v \u2032 ). Nonetheless, even if v is not branching in a view, it may still branch in the history tree, and in this case \u03b4U i may not be a correct upper bound. However, this undesirable event may occur at most U i -1 times. Thus, as soon as a branch B j receives estimates from B i on U i nodes, we take the maximum estimate as a correct upper bound U j on the anonymity of the deepest such node v j in B j .When we finally have an upper bound for all branches in I, we wait i U i additional steps to confirm that there are no branches missing from the view. Then we run the previous stabilizing Counting algorithm and output the result.Assuming that the network is simple and strongly connected at all steps, this algorithm terminates in 2 O(n log n) steps, which is likely far from optimal.Open Problem 5. Can a Counting algorithm terminate in a polynomial number of steps in all strongly connected directed dynamic simple networks with (early or late) outdegree awareness and a unique leader?For networks that are not necessarily connected at all steps, we define a communication round as a minimal sequence of consecutive steps whose communication multigraphs have a (strongly) connected sum (constructed by adding together their adjacency matrices). A network is \u03c4 -union-connected if every block of \u03c4 consecutive steps contains a communication round. It was observed in \u2032 B \u2032 A Fig. Clearly, any non-trivial terminating computation is impossible if the agents know nothing about \u03c4 . On the other hand, with knowledge of \u03c4 , all of the previous algorithms can be straightforwardly adapted to \u03c4 -union-connected networks. It is sufficient for each agent to accumulate incoming messages at every step, updating its view only once every \u03c4 steps. This adaptation slows down all running times by a factor of \u03c4 . However, this is worst-case optimal, since a \u03c4 -union-connected network may be devoid of links except at steps that are multiples of \u03c4 .As for stabilizing computations, they can be done even with no knowledge of \u03c4 , again with a worst-case optimal slowdown by a factor of \u03c4 , as detailed in In a network operating semi-synchronously, any agent may unpredictably be inactive at any step. An inactive agent does not communicate with other agents and does not even update its state. This model is called \"asynchronous\" by Boldi-Vigna The concept of a round and the parameter \u03c4 are defined as in Section 3.4. A notable distinction from the synchronous models discussed so far is that agents in a semi-synchronous network cannot reliably count communication steps, because they do not know for how many steps they have been inactive. Hence, two views shared by two agents may not have the same height, as the ones in Figure Consequently, a red edge no longer has to connect a level to the next, but can span any number of levels. However, it is always possible to restore this property by adding dummy nodes to represent inactive agents, resulting in an equalized view (Figure A network is asynchronous if messages can take an arbitrary, independent, and unpredictable amount of time to reach their destinations. Such a network is necessarily directed, and therefore some form of outdegree awareness is needed, as argued in Section 3.3. A round is now any minimal interval of time such that the messages that are sent and received form a strongly connected multigraph.Observe that, even in asynchronous networks, time can always be discretized, assuming that no agent can send an infinite number of messages in a finite time.Also, doing non-trivial computations with termination in asynchronous networks with no knowledge about the duration of a round is impossible.However, there is a simple stabilization algorithm, as follows. When an agent sends some messages, it expands its view by adding a child to the bottom node and attaches its outdegree to the corresponding black edge, as in Section 3.3. When it receives a multiset of messages, it updates its view as in Section 3.5.Then, the agent seeks the first interval of levels constituting a round where all nodes are non-branching. The outdegrees and red edges in this interval yield a system of equations that is solved as in the stabilizing algorithm of Section 3.3.Such a non-branching interval occurs in the history tree after at most n -1 rounds and appears in the agent's view in at most n -1 additional rounds. The total stabilization time is therefore 2n -2 rounds, which is worst-case optimal.A widely studied scenario, especially within static networks, is when each agent has a local numbering for its incoming links (input port awareness) or outgoing links (output port awareness). It is evident that, although input port awareness enables each agent in a static network to identify all messages sent by the same neighbor, this feature has no clear meaning or effect in dynamic networks.In contrast, output port awareness has a significant impact on both static and dynamic networks, as it not only implies outdegree awareness, but allows agents to assign a different tag to each message they send within a communication step. This is helpful in breaking network symmetry, thus facilitating certain computations. The history tree architecture for outdegree awareness of Section 3.3 can also be adapted to this model by simply attaching a port number to each red edge.As an example, output port awareness combined with a unique leader makes the Counting problem particularly simple even in strongly connected directed dynamic networks. Indeed, all messages sent by the leader in a communication step have different tags, and so all agents that receive them become distinguishable. Generalizing, every node on a red path starting at a leader node must have an anonymity of 1. When a whole level L i in a view consists of such nodes, we can check if the outdegree of each node in L i matches the number of its outgoing red edges. If so, all agents have been accounted for, and we can return n = |L i |.This Counting algorithm terminates in 2n -1 steps, greatly improving upon the one in Section 3.2. Observe that the lower bound in Figure Open Problem 6. Can a Counting algorithm terminate in fewer than 2n -2 steps in all strongly connected directed dynamic networks with output port awareness and a unique leader?A less obvious fact is that, in any non-branching level of the history tree of a strongly connected directed dynamic network with output port awareness, all nodes must have the same anonymity. A remarkable consequence is that, with output port awareness, a unique leader can be elected if and only if it is possible to assign unique identifiers to all agents (also known as the Naming problem). A terminating algorithm for both problems, if n is known, is easily obtained by combining the Leader Election algorithm in Section 3.1 (which was designed for undirected networks only) with the stabilizing technique for directed networks in Section 3.3.Suppose that agents have inputs that may change at every step. Note that the history tree architecture already supports attaching inputs to nodes, and so the basic stabilizing algorithms previously discussed can become streaming algorithms that adaptively return the correct output with an amortized delay of n -1 steps. 2 Fig. A network algorithm is self-stabilizing if it returns the correct output regardless of the initial state of the agents. This implies tolerance to memory corruption, transient faults, and agents dynamically joining and leaving the network.Let us assume the network to be synchronous, directed, and dynamic. We remark that most existing self-stabilizing protocols, such as Boldi-Vigna's We will give a universal self-stabilizing protocol that constructs coherent views, allowing to convert any stabilizing algorithm into a self-stabilizing one (note that non-trivial terminating computations are impossible in this scenario).The core idea is that an agent can deliberately \"forget\" old information by deleting level L 0 of its current view, connect level L 1 to the root, and merge equivalent nodes from top to bottom to restore a well-formed view, as in Figure If the number of agents n is known, they can simply update their views as usual (resetting their state if it does not encode a well-formed view) and delete old levels when their number exceeds some fixed threshold, e.g., 2n -2. Eventually, this protocol produces views that correctly describe the last 2n-2 communication steps, which are enough for the stabilizing algorithms of Sections 2.3 and 3.3.On the other hand, if n is unknown, every agent updates its view as usual, but deletes level L 0 every two steps. This is controlled by a local binary flag that is toggled at every step. However, before merging its view with a neighbor's view of different height, it deletes the top levels of the taller view to match the other. Also, if the taller view was its own, the agent does not toggle its flag for a step.In O(n) steps, all agents have views of equal height, as well as equal flags. Moreover, their views eventually describe an increasingly large number of previous communication steps, enabling any stabilizing algorithm to work correctly. Open Problem 7. Is there a universal self-stabilizing protocol for semisynchronous strongly connected directed dynamic networks?The stabilizing algorithms described so far assume that all agents constantly update their views at every step, which requires an unlimited amount of internal memory. To mitigate this, we will now give a universal finite-state protocol that enables the conversion of any stabilizing algorithm into one that uses a finite amount of memory (as a function of n), albeit with an extra delay.Let us assume the network to be synchronous, undirected, connected, and dynamic. A level L i in a view is said to be suitable if every node in L i-1 has a unique child in L i and the red edges between these two levels are compatible with a connected network. Recall that the basic stabilizing algorithms of Section 2.3 do all computations using only the shallowest suitable level of a view. Now, when two neighboring agents share views whose shallowest suitable levels are isomorphic, they do not merge their views. Essentially, this removes a link from the communication network for that step. Also, when an agent receives no views that it can merge, it skips updating its view altogether, i.e., it remains inactive for that step. Note that this makes the network semi-synchronous, so views must be equalized prior to being used by the protocol (see Section 3.5).According to this protocol, if all agents remain inactive forever, they all share the same suitable level, which is enough to perform correct computations. Otherwise, some inactive agent acquires relevant information within n -1 steps and reactivates. Moreover, since there are at most n -1 branching nodes in the history tree, the agents can incorrectly guess a suitable level at most n -1 times. Thus, the protocol is finite-state, but introduces an overhead of O(n 2 ) steps.Open Problem 8. Is there a universal finite-state stabilizing protocol for connected undirected dynamic networks with an overhead of O(n) steps?Another open problem is to design a protocol that is both self-stabilizing and finite-state. In Section 3.9 we already gave one, but it assumes n to be known.Open Problem 9. Is there a universal finite-state self-stabilizing protocol for connected undirected dynamic networks of unknown size?An agent is memoryless if its state is reset at every communication step, meaning its entire memory is erased after it sends messages and before receiving messages from neighbors. The goal is to design a universal protocol that enables memoryless agents to construct coherent views of some history tree related to the network. This would allow basic algorithms to run correctly within the memoryless model.. Under what assumptions is there a universal memoryless protocol for anonymous networks?In a congested network of n agents, communication links have a logarithmic bandwidth, and therefore the size of each message is limited to O(log n) bits. Correct protocols for constructing views in congested dynamic networks are found in If d is unknown but there is a unique leader, there is a more complex protocol that attempts to estimate d by implementing a reset module that repeatedly doubles the estimate every time a broadcasting error is detected. The leader coordinates the process, ensuring that all agents agree on the same version of the history tree. This yields a Counting algorithm that terminates in O(n 3 ) steps.Open Problem 11. Is there a terminating Counting algorithm for congested dynamic networks with more than one leader ? It was proved in Open Problem 12. Can a Counting algorithm terminate in O(n 2 ) steps in all congested dynamic networks with a unique leader?We find it fitting to conclude this note with an open problem that is unlikely to have a solution using history trees.Open Problem 13. Is there a terminating Counting algorithm for congested dynamic networks where agents have logarithmic-sized memory?"
    }
  ]
}
