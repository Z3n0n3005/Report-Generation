{
  "id": "Onah_et_",
  "name": "Onah_et_al._-_2023_-_A_Data-driven_Latent_Semantic_Analysis_for_Automat.grobid.tei.xml",
  "segments": [
    {
      "header": "I. INTRODUCTION",
      "content": "Topic modelling has been performed on several types of documents in the past. However, this study presents a novel approach to topic modelling by performing extracDve summarizaDon on over 100 arDcles related to genes and associated diseases and feeding the summary as an input argument a Latent Dirichlet AllocaDon (LDA) model in order to perform the topic modelling. The idea here is to idenDfy the commonaliDes between arDcles of the same genre describing a specific topic of interest in the research. The study is addressing journal arDcles retrieved from PubMed Central 1 h+ps://www.ncbi.nlm.nih.gov/pmc/ (PMC 1 ) database discussing about genes and their associated diseases. What would you do if you were handed a pile of papersreceipts, emails, travel iDneraries, meeDng minutes-and asked to summarize their contents? One strategy might be to read through each of the documents, highlighDng the terms or phrases most relevant to each, and then sort them all into piles. If one pile started geTng too big, you might split it into two smaller piles. Once you had gone through all the documents and grouped them, you could examine each pile more closely. Perhaps you would use the main phrases or words from each pile to write up the summaries and give each a unique name-the topic of the pile. This is, in fact, a task pracDced in many disciplines, from medicine to law, from computer science to engineering and so on. At its core, this sorDng task relies on our ability to compare two documents and determine their similarity. Documents that are similar to each other are grouped together and the resulDng groups broadly describe the overall themes, topics, and paVerns inside the corpus. With so many documents being extracted from social media, review comments from online plaWorms and microblogs as TwiVer, a huge amount of natural language data is being mined and are available to be analysed AutomaDc text summarizaDon is the process of performing specific NLP task by producing a concise summary of documents (single or mulDple) without any manual support while preserving the meaning or important points of the original document \u2022 How automated text summarizaDon techniques were used in an extracDve summary of arDcles?\u2022 How topic modelling models were used in producing emerging terms that are related to mulDple and different journal arDcles? \u2022 Are the search terms used for the text mining of arDcles from the database predominant in the emerging terms that were extracted from the processed text? The experimental results show that the proposed model achieves good performance in terms of the document summary and the topic modelling informaDon retrieved from the full document. This paper is presented as follows. SecDon 2, covers related study on summarizaDon. SecDon 3, conceptualise the methods and describes the techniques applied in the study. SecDon 4 describes topic modelling, SecDon 5, presents a descripDon of the model pipeline. SecDon 6, presents the results and findings. The limitaDon of the study is presented in secDon 7 and finally, the discussion and conclusion of the study are presented in secDons 8 and 9."
    },
    {
      "header": "II. RELATED WORK",
      "content": "The amount of text data being produced worldwide is enormous and growing rapidly. Unless these text data are extracted and make meaning, then the most important and relevant informaDon would be lost. Text summarizaDon is a well-known task in natural language understanding and processing. SummarizaDon is described as the process of presenDng huge data informaDon in a concise manner while focusing on the most useful secDons of the data whilst preserving the original meaning "
    },
    {
      "header": "A. Summariza-on",
      "content": "SummarizaDon is a technique in NLP that is used for condensing or summarising huge texts into smaller versions taking care not to omit the main relevant informaDon contained in the document 1) Extrac-ve approach: ExtracDve summarizaDon approach considers the top N sentences based on their score rankings for the summary generaDon 2) Abstrac-ve approach:In abstracDve text summarizaDon technique, this follows the convenDon of unsupervised approach where machine learning paradigms such as deep learning plays a big role in generaDng the document summary In this study, we decided to use extracDve approach for arDcle summarizaDon, because we wanted all parts of the sentences that will be summarised to be from the original document."
    },
    {
      "header": "B. Topic Modelling",
      "content": "Topic modelling is the process of labelling and describing documents into topics. This is an unsupervised machine learning technique for abstracDng topics from collecDons of documents "
    },
    {
      "header": "C. Latent Dirichlet Alloca-on",
      "content": "Latent Dirichlet AllocaDon (LDA) is a technique applied in topic modelling introduced by "
    },
    {
      "header": "III. METHODS",
      "content": "The summarizaDon model was designed to scrap text data from PubMed journal database using genes and diseases keywords search The study was designed to apply a generalised concept of LDA topic modelling technique to create a dicDonary of terms that was fed from the summarised arDcles. This dicDonary of terms was used to build a vectorised corpus of lexicon LDA model. One of the key approaches that was used in the experiment was the 'pyLDAvis.gensim.prepare' method which takes as an argument our LDA model, the corpus and the derived lexicon which contains the dicDonary terms for the study "
    },
    {
      "header": "A. Model Descrip-on",
      "content": "Most of the processing of the text was performed with the python Natural Language Toolkit (NLTK) "
    },
    {
      "header": "1)",
      "content": "Sentence scoring method: : In this study, a scoring funcDon is introduced to generate the sentence score dicDonary which hold the value assigned to each sentence "
    },
    {
      "header": "Sentscores[S] = Wordfreq[W]",
      "content": "(1)During the sentence model processing interval, the length of the sentence is either increased or reduced by certain values within the sentence scores dicDonary. Therefore, new sentences are added into the sentence dicDonary scores. The sentence model would check whether the new sentences are in the sentence dicDonary. If the sentence exists in the sentence dicDonary, then the model will proceed accordingly. But if the process sentence is not in the sentence scores dicDonary keys, then the word in the word frequencies dicDonary is added to the sentence in the sentence scores dicDonary (see equaDon 2)."
    },
    {
      "header": "Sentscores[S]+ = Wordfreq[W]",
      "content": "(2)2) Word frequency:: DicDonary of word frequency corpus was generated within the model. The word frequencies were selected automaDcally based on the prevalence or occurrence of the words in the corpus dicDonary created in the model (see Figure The next equaDon allows us to calculate the maximum word in the word frequencies (see equaDon 4)."
    },
    { "header": "Word", "content": "(4) " },
    {
      "header": "B. Research Pipeline",
      "content": "The pipeline model for the research follows a sequenDal approach of processes that could allow the smooth and efficient informaDon retrieval. The pipeline in Figure 1) Data Collec-on: The dataset was scraped from the web. About 100 papers were extracted from PubMed Central (PMC) database (\"https : //www.ncbi.nlm.nih.gov/pmc/ 00 ) using a search key combinaDon of 'gene' and 'disease'. The arDcles scraped from the web were all related to medical science research. Papers related to diseases and the mutated genes causaDon were extracted for this study "
    },
    {
      "header": "2)",
      "content": "Pre-processing & Feature Extrac-on: The web-based dataset scraped from PubMed journal was in raw state and unstructured which consist of HTML tags, special characters, symbols and numbers that had to be processed and cleaned. The preprocessing involved converDng the dataset into text documents using NLP packages such as BeauDfulSoup, regular expression, lxml, tokenisaDon and using NLTK library. In the feature extracDon process, we parse the web arDcles source code in order to extract the textual material needed for the final summary. As the arDcles were parsed through the source code, the text for extracDon are between the paragraphs' tags < p > text < /p >. During the process of formaTng the clean arDcles, we performed extra filtering of special characters from the processed text in order to find and replace these symbols automaDcally. Finally, these extracted paragraphs text are combined to form a single string to store the clean web content for further topic model processing (see Figure "
    },
    {
      "header": "3)",
      "content": "Stopwords: We further removed a list of stop-words from the propocessed arDcles. Words such as pronounce that are not necessary or essenDal for the final summary (see Figure "
    },
    {
      "header": "4) Topic Modelling & Visualiza-on:",
      "content": "This study was able to reveal prevalence of terms that emerged within the documents and show their relevance by how the projecDon of the topic modelling circle and the size of a word in the result visualisaDon. The result was visualised using PyLDAvis which is a web-based interacDve visualizaDon package that allows the display of the topics that were idenDfied using the LDA approach "
    },
    {
      "header": "IV. MODEL",
      "content": "A. Defining seman-c significance we define the semanDc significance of term t to the topic n given the parameter weight of the (\u03bb) where(0 \u2264 \u03bb \u2264 1) "
    },
    {
      "header": "B. Defining Saliency Term",
      "content": "In this study we define saliency term as given a word 'w 0 , we compute its minimal probability P(TM/w). where TM is the topic model. The possibility that the emerge word w was generated from the LDA topic model (TM).We also compute the marginal probability P(TM): -with the possibility that any word w 0 randomly selected was generated by TM. We define the uniqueness of each idenDfied word 0 w 0 as the divergence occurrence between P(TM/w) and P(TM) "
    },
    { "header": "U(6)", "content": "" },
    {
      "header": "=5",
      "content": "The uniqueness of each term is described as how significance and semanDcally associated they are to the topics. For example, a term could be semanDcally associated to more than one topic. The frequency and populaDon of terms are denoted by the size of the topic circles and also the inter-topic distance denote how closely related the topics are. We noDce a few words that are expressed in several topics, but observing this word w reveals liVle informaDon about the mixture or semanDc associaDon of the topics. In some cases, this word might be scored very low in the computaDon of it's uniqueness. In order to compute the saliency, we used the following model equaDon 7:As illustrated in Figure "
    },
    {
      "header": "V. LATENT SEMANTIC ANALYSIS",
      "content": "Latent SemanDc Analysis (LSA) is a robust Algebraic and StaDsDcal method which extracts hidden semanDc structures of words and sentences. LSA is used to extract features that cannot be directly menDoned within the dataset "
    },
    {
      "header": "A. Sample Extracted Summary",
      "content": "The sentences with the most prevalence sentence score was used for the summary together. We used the heap queue (heapq) library to select the most or very useful sentences. The heapq is used in implemenDng the priority queues for word frequencies in sentences with higher weight is given more priority in processing the summary. The threshold indicates the number of sentences to summarize (see Table "
    },
    {
      "header": "B. Findings",
      "content": "The summary result has revealed very interesDng findings of genes that are associated to some Cancerous and type 2 diabetes diseases (see Table "
    },
    {
      "header": "VI. ROUGE: RELIABILITY & VALIDITY OF MODEL",
      "content": "ROUGE is a metric evaluaDon model which stands for Recall Oriented Understudy for Gisting Evaluation. It is an intrinsic metric for automaDcally evaluaDng document summaries "
    },
    {
      "header": "TABLE III ROUGE METRICS MEASUREMENT SUMMARIES",
      "content": "System and Human Annotated Summaries Type Summary SSummary 'Some of the genes in the BCAA metabolic pathway such as MLYCD (rank 164)HADHB (rank 354)IVD (rank 713)MUT (rank 921)and PCCB (rank 684) are also ranked highly by Hridaya. The SVMs are based on 181 features broadly grouped into (1) gene8c( "
    },
    {
      "header": "Comparing the system generated summary with a new human",
      "content": ""
    },
    {
      "header": "A. Procedure: Recall & Precision",
      "content": "We have mulDple processed arDcles or documents extracted from the web based on key search terms. The documents are stored in a given name CleanHTML.txt file and an automaDc summary was generated and stored in a file called summary.txt. We then produced a set of human annotated reference summaries of the CleanHTML.txt document. The Recall in the context of the ROUGE metric simply means we are calculaDng how much of reference summary (the human summary) is the system summary (automated machine summary) recovering or capturing from our text. In considering the individual words in a sentence we simply represent this with the formula in equaDon 8.The metric will produce a perfect result of 1 which usually will be the case if indeed the sentence matches. This metric simply means all the words in the reference summary has been captured by the system summary.In the system generated summary, which someDmes might be very large based on the threshold selected, capturing all the words in the reference or model summary. However, most of the worlds in the system summary might be unnecessary verbose. But, this where precision becomes very important. In conducDng precision on the summary, we are essenDally measuring how much of the system or machine summary is required? We can measure precision using the equaDon 9.This means we will evaluate and calculate words in the sentence summary of the Recall overlapping with the total words in the system summary. This will predict the words that are relevant which appears in the reference and over the total words in the system summary.The system's summary mostly contains unnecessary words in the summary. Therefore, our precision becomes crucial as we are trying to predict generated summaries that should be concise in nature. In this study, we combined and computerised both the Precision and Recall and further report the F1 -score measure.In order to ascertain the validity of the study, we measured ROUGE-N, ROUGE -S and ROUGE -L which are the granularity of texts that was compared between the system summaries and the reference or human annotated model summaries. ROUGE -1 refers to the overlap of unigrams between the system summary and reference summary. ROUGE -2 refers to the overlap of bigrams between the system reference and the model or reference summaries. We computed precision and recall scores of the ROUGE -2. The main reason why ROUGE-1 could be considered over others or in conjuncDon with ROUGE -2 or even other fine granularity measures is because it reveals the fluency of the summaries or if used in a translaDon task. The intuiDon is that following the word ordering of the reference m=summary indicate that the summary is more fluent.The precision result tells us about the percentage (%) of the overlap between the system summary bigrams and the reference summary. We noDced in the case of the abstracDve summarizaDon as both the summaries of system and reference summaries get larger. There are few overlapping bigrams outcome as we are not always or directly re-using the whole sentences for the summarizaDon."
    },
    {
      "header": "VII. RESULTS & FINDINGS",
      "content": "The terms in the topic modelling show text which are mostly frequent in the document these were depicted by the size of the circle (as seen in Figures The distance between two or more topics is an approximaDon of their semanDc relaDonship. Note that close topics such as topics 1, 2 and 3 are semanDcally related which describes the terms in the topics. As observed in Figures "
    },
    {
      "header": "IX. DISCUSSION",
      "content": "In this study, we presented a fully data-driven approach for automaDc text summarizaDon. We proposed and evaluated the model on unstructured datasets which show some results comparable to the current state-of-the-art topic modelling techniques without depending on modificaDons using any linguisDc informaDon models "
    },
    {
      "header": "X. CONCLUSION",
      "content": "AutomaDc summarizaDon is the process of reducing a text document with a computer program in order to create a summary that retains the most important points of the original document "
    }
  ]
}
