{
  "id": 1723809965798419990,
  "name": "source_tracing_of_audio_deepfakes_systems.grobid.tei.xml",
  "segments": [
    {
      "header": "Introduction",
      "content": "in recent years, deepfake generation and detection have attracted significant attention.\nthus, explainability in deepfake detection systems is crucial.\nwithin this research area, the task of deepfake audio source attribution has recently been gaining interest.\nfor example, the study inaims to predict the specific attack systems used to produce utterances in asvspoof 2019.\nthis approach of directly identifying the name of the system misses the opportunity to categorize the spoofing systems based on their attributes.\nsuch attribute-based categorization allows for better generalization to spoofing algorithms that are unseen in training but are composed of building blocks, such as acoustic models or vocoders, that are seen.\nalong these lines, authors inpropose a more generalizable approach by classifying the vocoder used in the spoofing system.\nauthors inexplore classifying both the acoustic model and vocoder, finding that the acoustic model is more challenging to predict.\nthe work intakes this further by proposing to classify several attributes of spoofing systems in asvspoof 2019 la: conversionfigure: illustration of proposed frameworks for spoofing attribute-classification.\nbottom: two-stage learning that includes a traditional countermeasure (cm) and an auxiliary classifier trained on embeddings.model 1 , speaker representation, and vocoder.\nanother drawback of their evaluation protocol is that the asvspoof 2019 dataset is relatively outdated as there have been many advancements in voice cloning techniques in the last five years.\nfinally, their choice of categories for acoustic model and vocoder are very broad (e.g.\"rnn related\" for acoustic model and \"neural network\" for vocoder) and may not be that useful in narrowing down the identity of the spoofing system.in this work, we investigate two attribute classification strategies as illustrated in fig.: an end-to-end learning method which trains standalone systems for each attribute and a twostage learning method which leverages the learned representations of existing countermeasure systems.\nto this end, we leverage three state-of-the-art systems, namely resnet, self-supervised learning (ssl), and whisper.\nin addition to identifying the acoustic model and vocoder, we propose classifying the input type (i.e. speech, text, or bonafide) rather than speaker representation.\nas an anchor to previous work, we evaluate our methods on the asvspoof 2019 protocol designed by.\nto address the limitations of the outdated asvspoof-based protocol, we design a new protocol based on the recent mlaad dataset which consists of multilingual utter-"
    },
    {
      "header": "Attribute classification of spoof systems",
      "content": "in this section, we describe our approaches for classifying the input type, acoustic model, and vocoder of the spoofing system used to generate a given audio.we present two strategies for leveraging existing state-of-theart (sota) spoofing countermeasure (cm) systems for the task of component classification:\u2022 our end-to-end (e2e) approach takes an existing cm architecture and trains the whole model for each of the multi-class component classification tasks separately, as depicted in the top part of fig..\n\u2022 the two-stage approach, shown in the bottom of fig., splits training into two steps: first an existing cm is trained for the standard binary spoof detection task; next, the cm backbone is frozen and a lightweight classification head is trained on the cm's embeddings for each separate component classification task.\nfor the classification head, we use the simple feed forward architecture from the back-end model of the resnet spoof detection system described in.\nwhile the second approach is limited to the information that the binary-trained cm learns, it is very attractive in practice: in addition to the reduction in computational costs, existing binary systems can be trained on significantly more data than we have component labels for and enhancing them with an auxiliary head rather than replacing them with a modified e2e system is much safer for models that run in production.we used three different cms to validate our hypothesis.\nthis system consists of a front-end spoof embedding extractor and a back-end classifier.\nthe front-end model is known as the resnet18-l-fm model, as detailed in.\nthe back-end model is trained using the spoof embedding vectors for the classification tasks described in section 2.\nthe back-end classifier is a feed forward neural network with one fc layer described in.\nssl-based front-ends have attracted significant attention in the speech community, including spoofing and deepfake detection.\nthe ssl-based cm architectureis a combination of ssl-based front-end feature extraction and an advanced graph neural network based backend, named aasist.\nthe ssl feature extractor is a pre-trained wav2vec 2.0 model, the weights of which are fine-tuned during cm training.whisper.\nthe whisper-based cm architectureis a combination of whisper-based front-end feature extraction and light convolution neural network (lcnn)as a back-end.\nfor the front-end feature extraction, the whisper embedding is concatenated with 128-dimensional linear frequency cepstral coefficients (lfccs)along with their delta and double-delta features."
    },
    {
      "header": "Datasets and protocols",
      "content": "two publicly available spoofing detection benchmarks are used in our study: the asvspoof 2019 laand the most recent mlaad dataset.the asvspoof 2019 la dataset has three independent partitions: train, development, and evaluation.\ntablesummarises the statistics for each partition used for the different attribute classification tasks on the asvspoof 2019 dataset.mlaad consists of tts attacks only, however it includes 52 different state-of-the-art spoofing algorithms.\nwe manually label the acoustic models and vocoders based on the available metadata.since mlaad includes only tts systems, we focus on acoustic model and vocoder classification without any input-type prediction.\nfor end-to-end systems such as vits and bark, we use the name of the full system as the acoustic model and vocoder labels.\nadditionally, while the mlaad dataset labels 19 different architectures, our protocol groups several systems that are identical aside from their training data.\nfor example, the systems \"jenny\", \"vits\", \"vits-neon\", and \"vits-mms\" are all labeled with the same acoustic model and vocoder category \"vits\".\nthe resulting acoustic model and vocoder labels along with their number of examples in each partition are presented in tableand table, respectively."
    },
    {
      "header": "Experimental Results",
      "content": "since fine-tuning large ssl models requires high gpu computation, experiments with ssl are performed with a smaller batch-size of 16 and a lower learning rate of 10 -6 .\nssl and whisper based models are fine-tuned on asvspoof and mlaad datasets in their respective experiments, whereas the resnet model is trained from scratch.\nthe best model is chosen based on dev set accuracy and average f1-score for asvspoof and mlaad experiments, respectively.our results are compared with the previous studyon asvspoof 2019 in terms of unweighted accuracy in table.this study introduces a novel task, predicting input types, which the previous study did not explore.\nwe train classification heads using fixed resnet, ssl, and whisper based binary spoof detection models named as, resnet (two-stage), ssl (two-stage), and whisper (two-stage).\nour ssl model fine-tuned end-to-end, ssl (e2e), further improves accuracy to 99.9%.acoustic model classification: several of our models surpass the previous study's highest accuracy of 88.4%, achieved table: results in terms of accuracy (%) on the asvspoof 2019 la dataset.\nspecifically, ssl (two-stage), resnet (two-stage), and ssl (e2e) achieve accuracies of 91.4%, 92.6%, and 99.4% (a 12.4% relative improvement over the previous study), respectively.\nthe substantial increase in accuracy may be due to the fact that our models are specifically trained for these tasks, unlike the previous study's multi-task approach that jointly trained on acoustic, vocoder, and speaker representation tasks.vocoder classification: our ssl (e2e) model slightly outperforms the previous study with an accuracy of 84.6% (a 0.1% relative improvement).\naside from this one kind of error, our ssl (e2e) model's accuracy is 99.7%.we report results in terms of macro-averaged f1 and accuracy scores in table."
    },
    {
      "header": "Conclusions and Discussions",
      "content": "in this paper, we propose three multi-class classification tasks to give more explanatory predictions in the place of traditional binary spoof detection: input-type, acoustic model, and vocoder classification.\nwe experiment with two methods of leveraging open source spoof detection systems to accomplish this task and evaluate them on a recently introduced asvspoof 2019 protocol as well as a new protocol that we design using the more modern mlaad dataset.\non our mlaad protocol which includes a greater number of vocoder and acoustic categories from more modern tts systems, our resnet (e2e) model yields an average f1 score of 82.3% for the acoustic model and 93.3% for the vocoder classification task.\nthus, a potential area of future study is to more explicitly ignore voice-specific information.our experiments with two-stage classification methods that leverage embeddings from binary spoof detection systems show promise, though they underperform on mlaad compared to the full model fine-tuning methods.\nfuture research in this area is crucial as models that augment rather than replace existing binary spoof detection systems are attractive, especially in industry where changes in the behavior of the binary detection system require thorough evaluation.\nthus, one possible future experiment is to assess where in the binary model contains the most useful information for discriminating the different spoof system components."
    }
  ]
}
