{
  "id": 3564379243090159618,
  "name": "Peterson_-_2024_-_AI_and_the_Problem_of_Knowledge_Collapse.grobid.tei.xml",
  "segments": [
    {
      "header": "Introduction",
      "content": "the capability of large language models (llms) to generate text with near-zero human effort, however, along with models to generate images, audio, and video, suggest that the data to which humans are exposed may come to be dominated by ai-generated or ai-aided processes.researchers have noted that the recursive training of ai models on synthetic text may lead to degeneration, known as \"model collapse\".\nwe ask under what conditions the rise of ai-generated content and ai-mediated access to information might harm the future of human thought, information-seeking, and knowledge.the initial effect of ai-generated information is presumably limited, and existing work on the harms of ai rightly focuses on the immediate effects of false information spread by \"deepfakes\", bias in ai algorithms, and political misinformation.\nour focus has a somewhat longer time horizon, and probes the impact of widespread, rather than marginal adoption.researchers and engineers are currently building a variety of systems whereby ai would mediate our experience with other humans and with information sources.\nthese range from learning from llms, ranking or summarizing search results with llms, suggesting search terms or words to write as with traditional autocomplete, designing systems to pair collaborators, llm-based completion of knowledge bases sourced from wikipedia, interpreting government dataand aiding journalists, to cite only a few from an ever-growing list.over time, dependence on these systems, and the existence of multifaceted interactions among them, may create a \"curse of recursion\", in which our access to the original diversity of human knowledge is increasingly mediated by a partial and increasingly narrow subset of views.\nwith increasing integration of llm-based systems, certain popular sources or beliefs which were common in the training data may come to be reinforced in the public mindset (and within the training data), while other \"long-tail\" ideas are neglected and eventually forgotten.such a process might be reinforced by an 'echo chamber' or information cascade effect, in which repeated exposure to this restricted set of information leads individuals to believe that the neglected, unobserved tails of knowledge are of little value.\nto the extent ai can radically discount the cost of access to certain kinds of information, it may further generate harm through the \"streetlight effect\", in which a disproportionate amount of search is done under the lighted area not because it is more likely to contain one's keys but because it's easier to look there.\nwe argue that the resulting curtailment of the tails of human knowledge would have significant effects on a range of concerns, including fairness, inclusion of diversity, lost-gains in innovation, and the preservation of the heritage of human culture.in our simulation model, however, we also consider the possibility that humans are strategic in actively curating their information sources.\nif, as we argue, there is significant value in the tai' areas of knowledge that come to be neglected by ai-generated content, some individuals may put in additional effort to realize the gains, assuming they are sufficiently informed about the potential value."
    },
    {
      "header": "Summary of Main Contributions",
      "content": "we identify a dynamic whereby ai, despite only reducing the cost of access to certain kinds of information, may lead to \"knowledge collapse,\" neglecting the long-tails of knowledge and creating an degenerately narrow perspective over generations.\nwe provide a positive knowledge spillovers model with in which individuals decide whether to rely on cheaper ai technology or invest in samples from the full distribution of true knowledge.\nwe examine through simulations the conditions under which individuals are sufficiently informed to prevent knowledge collapse within society.\nfinally, we conclude with an overview of possible solutions to prevent knowledge collapse in the ai-era."
    },
    {
      "header": "Related Work",
      "content": "technology has long affected how we access knowledge, raising concerns about its impact on the transmission and creation of knowledge.\nyeh meng-te, for example, argued in the twelfth century that the rise of books led to a decline in the practice of memorizing and collating texts that contributed to a decline of scholarship and the repetition of errors.\neven earlier, a discussion in plato's phaedrus considers whether the transition from oral tradition to reading texts was harmful to memory, reflection and wisdom.we focus on recent work on the role of digital platforms and social interactions, and mention only in passing the literature on historical innovations and knowledge (e.g., and the vast literature on the printing press (e.g..\nlike other media transitions before it, the rise of internet search algorithms and of social media raised concerns about the nature and distribution of information people are exposed to, and the downstream effects on attitudes and political polarization.the following section considers research on the impact of recommendation algorithms and self-selection on social media, and how this might generate distorted and polarizing opinions, as an analogy for understanding the transformation brought about by reliance on ai.\nwe consider game theoretic models of information cascades as an alternative model for failure in social learning, in which the public to fails to update rationally on individuals' private signals.\nnext, we review the main findings of network analysis on the flow of information in social media, which also identify mechanisms which distort knowledge formation.\nwe then examine the specific nature of generative ai algorithms, focusing on the problem of model collapse and known biases in ai outputs."
    },
    {
      "header": "The media, filter bubbles and echo chambers",
      "content": "a common critique of social media is that they allow users to select in to \"echo chambers\" (specific communities or communication practices) in which they are exposed to only a narrow range of topics or perspectives.\nfor example, instead of consulting the \"mainstream\" news where a centrist and relatively balanced perspective is provided, users are exposed to selective content that echoes pre-existing beliefs.\nin the ideological version of the echo-chamber hypothesis, individuals within a latent ideological space (for example a one-dimensional left-right spectrum), are exposed to peers and content with ideologically-similar views.\nif so, their beliefs are reinforced socially and by a generalization from their bounded observations, leading to political polarization.a simple model for this assumes homophily within in a network growth model, in which similar individuals chose to interact.\nimplicitly the approach presumes that this is common on social media but not common within traditional media, which for technological reasons were constrained to provide the same content across a broad population with possibly heterogeneous preferences.\n1 this general dynamic may hold even if traditional media and newspapers were themselves dynamic systems interacting with their consumers, markets and advertisers, and themselves adapting their message to specific communities and preferences (e.g..the second main line of analysis focuses on \"filter bubbles,\" whereby the content to which users are exposed is selected based on a recommendation system.model this as a dynamic process between a user's evolving interests and behavior (such as clicking a link, video, or text) and a recommender system which aims to maximize expected utility for the user.\nthe 'payola' scandals, however, led to regulations that shifted content decisions from diverse djs to centralized music directors.ommendations their relation to polarization.\nin a more recent twist,find that llm-powered search may generate more selective exposure bias and polarization by reinforcing pre-existing opinions based on finer-grained clues in the user's queries.particularly relevant for our context is the issue of \"popularity bias\" in recommender systems, in which a small subset of content receives wide exposure while users (distributed based on some long-tailed distribution, like the topics) from smaller groups or with rare preferences are marginalized.\non the one hand, users may desire to be exposed to popular content, for example to understand trending ideas or fashions.\nbut overly favoring popular items can lead to user disengagement because it neglects their unique interests, lacks variety, etc.\nrecommendation systems are often biased in the sense that even when a subset of users wants to get access to non-popular items, they receive few or no such recommendations.\na number of approaches have been suggested to counteract this tendency (e.g..the problem of popularity bias is ironic given that one of the unique contributions of the internet was its ability to provide access to long-tailed products and services that were previously ignored or inaccessible."
    },
    {
      "header": "Network effects and Information Cascades",
      "content": "information cascade models provide one approach to explaining a kind of herd behavior (where diverse and free individuals nonetheless make similar decisions).\nthis can occur where individuals sequentially make decisions from a discrete set after observing the behaviors but not the private signals of others.\nthis can generate a \"herd externality\"in which an individual ignores her private signal in deciding, and as a result the public is in turn unable to update on her private information.\nin some variants of the model, individuals must pay to receive a signal, which encourages the tendency to want to free-ride on the information received by others, and thus the greater the cost, the more likely it is that a cascade develops.a related literature on the spread of information on social networks analyzes information cascades in terms of network structure, as a kind of contagion.\nhere, the focus is not on private information but how information flows within the network.\nfor example, independent cascade models consider how an individual may change their beliefs based on some diffusion probability as a result of contact with a neighbor with that belief.more generally, such models determine the probability of diffusion within a network as some function of the connected nodes, and may also incorporate additional characteristics such as each nodes' social influence, ideological or other preferences, or topics.\nalternatively, epidemic models allow that individuals may be in one of three states -susceptible, infected (capable of transmitting the information), and recovered (in which case they have the information but do not consider it worth sharing with others) (e.g.andsocial (and even physical) proximity can lead individuals to share similar attitudes, such as when individuals randomly assigned housing together come to have attitudes similar to their apartment block and differing from nearby blocks, as modeled by.\nby extension, we could consider the generalization of these networks to the case where llms play a key role as (possibly influential) nodes, or as determining how an individual navigates a knowledge graph.\nby extension, in the ai era, llms interact with users, authors, programmers and technology to structure that knowledge, and understanding the flow of information requires understanding the emergent behavior of these elements."
    },
    {
      "header": "Model collapse",
      "content": "the idea of model collapse is rooted in the earlier phenomenon of \"mode collapse\" in generative adversarial networks (gans).\ngans are based on a generator neural network that proposes, e.g. an image, and a discriminator attempts to predict whether a given image is created by the generator or is a real image from the dataset.\nwhile ideally the generator attempts to produce images across the full range of input data, in practice they may settle into producing a narrow range of images for which it is good at fooling the discriminator, known as mode collapse.\nthe case of \"posterior collapse\" was also identified in modeling language data with variational autoencoders.introduced the term \"model collapse\" to describe a related process when models such as variational autoencoders, gaussian mixture models, and llms are trained on data produced by an earlier version of the model.\nincorporating ai-generated content in the training data causes loss of information which they categorize into two types.\nfirst, in \"early model collapse,\" the tails of the distribution are lost due to statistical error (finite sampling bias) or functional approximation error, which leads to reversion to the mean.\nsecond, \"late model collapse\" may occur when a model converges with narrow variance on a distribution unlike the original data.\nthey provide evidence of such model collapse in llms and other models, see for example figure.demonstrate conditions under which the injection of true (non ai-generated) data can preserve representation of the true distribution, thoughshow that even small amounts of synthetic data can poison an image model, and once distorted, it is difficult for such models to recover even after being trained on true data.demonstrate that training llms on synthetic data can lead to diminishing lexical, semantic and syntactic diversity."
    },
    {
      "header": "Known biases in LLMs",
      "content": "newer ai models such as llms are not immune to the problems of bias identified and measured in machine learning algorithmsand which have plagued predictive algorithms in real-world uses cases gen 9: architecture.\nin addition to being home to some of the world's largest populations of black @-@ tailed jackrabbits, white @-@ tailed jackrabbits, blue @-@ tailed jackrabbits, red @-@ tailed jackrabbits, yellow @- going back to at least the 1930s.\nunsurprisingly, llms are better at recalling facts that occur frequently within the training data and struggle with long-tail knowledge.identify a range of shortcomings of llms in attempting to generate human-like texts, such as underrepresenting minority viewpoints and reducing the broad concept of \"positive\" text to that simply of expressing \"joy\".recent work attempts to address these issues through a variety of methods, for example by upsampling underrepresented features on which prediction is otherwise sub-optimal, or evaluating the importance of input data using shapely values.\nhowever, the mechanistic interpretability work on llms to date suggest that our understanding, while improving, is still very limited (e.g..\nas such, direct methods for overcoming such biases are, at a minimum, not close at hand.\nfinally, while much of the focus is naturally on overt racial and gender biases, there may also be pervasive but less observable biases in the content and form of the output., for example, provide evidence that that current llms trained on large amounts of english text 'rely on' english in their latent representations, as if a kind of reference language.one particular area in which the diversity of llm outputs has been analyzed is on a token-by-token level in the context of decoding strategies.\nin some situations, using beam search to choose the most likely next token can create degenerate repetitive phrases.\nfurthermore, a bit like thelonious monk's melodic lines, humans do not string together sequences of the most likely words but occasionally try to surprise the listener by sampling from low-probability words, defying conventions, etc.(referring to."
    },
    {
      "header": "A Model of Knowledge Collapse Defining Knowledge Collapse",
      "content": "a commonly held, optimistic view is that knowledge has improved monotonically over time, and will continue to do so.\nthis indeed appears to be the case for certain scientific fields like physics, chemistry, or molecular biology, where we can measure the quality of predictions made over time.\nfor example, accuracy in the computation of digits of \u03c0 has increased from 1 digit in 200 bce to 16 in 1424 (jamashid al-kashi) to 10 14 digits recently.in other domains, however, it is less clear, especially within regions.\nhistorically, knowledge has not progressed monotonically, as evidenced by the fall of the western roman empire, the destruction of the house of wisdom in baghdad and subsequent decline of the abbasid empire after 1258, or the collapse of the mayan civilization in the 8th or 9th century.\nor, to cite specific examples, the ancient romans had a recipe for concrete that was subsequently lost, and despite progress we have not yet re-discovered the secrets of its durability, and similarly for damascus steel.\nculturally, there are many languages, cultural and artistic practices, and religious beliefs that were once held by communities of humans which are now lost in that they do not exist among any known sources.the distribution of knowledge across individuals also varies over time.\nfor example, traditional huntergatherers could identify thousands of different plants and knew their medicinal usages, whereas most humans today only know a few dozen plants and whether they can be purchased in a grocery store.\nthis could be seen as a more efficient form of specialization of information across individuals, but it might also impact our beliefs about the value of those species or of a walk through a forest, or influence scientific or policy-relevant judgements.informally,we define knowledge collapse as the progressive narrowing over time (or over technological representations) of the set of information available to humans, along with a concomitant narrowing in the perceived availability and utility of different sets of information.\nthe latter is important because for many purposes it is not sufficient for their to exist a capability to, for example, go to an archive to look up some information.\nif all members deem it too costly or not worthwhile to seek out some information, that theoretically available information is neglected and useless."
    },
    {
      "header": "Model Overview",
      "content": "this is a modeling assumption in order to work with a process with well-known properties, where there is both a large central mass and long-tails, which we take to be in some general way reflective of the nature of knowledge (and of the distribution of training data for llms.)the set of individuals who decide to invest in information receive a sample from the true distribution, while those that invest in the ai-generated sample receive a sample from a version of the true distribution which is truncated at \u03c3 tr standard deviations above and below the mean.\nthe results are similar for a standard normal distribution, and as expected the problem of knowledge collapse is more pronounced for wider tails (c.f. appendix figure).while individuals choose whether or not to invest in innovation according to their personal payoff, when they do so invest they also contribute their knowledge to the public.\nthat is, the innovation (individual payoff) i generated by an individuals additional (n + 1)th sample is calculated with respect to the true pdf p true (x) and the current public pdf p public (x), based on the hellinger distance h(p(x), q(x)) 5 , as follows:in figure, we illustrate the innovation calculation for a hypothetical example where the distance between the existing public pdf and the true pdf is 0.5, while the n + 1th sample reduces the distance to 0.4, thereby generating an innovation of 0.1.\nfor the previous estimate vt-1 , the new estimate vt for each of the full-and truncated-samples is calculated from the observed value in the previous round (i t-1 ) as:by varying the learning rate, we can evaluate the impact of having more or less up-to-date information on the value of different information sources, where we expect that if individuals are sufficiently informed, they will avoid knowledge collapse by seeing and acting on the potential to exploit knowledge from the tail regions, even if relatively more expensive.while the individual payoff is based on the true movement of the public pdf towards the true pdf, the public pdf is updated based on all samples.\nunlike the individual innovator who has a narrow focus and observes whether her patent ultimately generates value, the public sphere has limited attention and is forced to accept the aggregate contributions of the marketplace of ideas.as a result, individuals' investments in innovation have positive spillovers to the extent they can move public knowledge towards the truth.\nhowever, if too many people invest in 'popular' or 'central' knowledge by sampling from the truncated distribution, this can have a negative externality, by distorting public knowledge towards the center and thinning the tails.we also introduce the possibility of generational turnover in some models to explore the impact on knowledge collapse.\nthis could either be taken to be literal generations of humans, as in economic 'overlapping generation' models (e.g., or alternatively as reflecting the recursive nature of reliance on interleaved ai-systems, which could generate the same result within a rapid timeframe.in the version of the model with generational change, the new generation takes the existing public pdf to be representative and thus begins sampling from a distribution with the same (possibly smaller) variance (and correspondingly the truncation limits are updated)."
    },
    {
      "header": "Results",
      "content": "as a baseline, when there is no discount from using ai (discount rate is 1), then as expected public knowledge converges to the true distribution, 9 as ai reduces the cost of truncated knowledge, however, the distribution of public knowledge collapses towards the center, with tail knowledge being under-represented.\nunder these conditions, excessive reliance on ai-generated content over time leads 7 zamora-bonilla (2010, p.328) suggests a scientific process of 'verisimiltude', where we judge evidence not with reference to objective truth by by \"perceived closeness to what we empirically know about the truth, weighted by the perceived amount of information this empirical knowledge contains\".\nfor example, for our default model,after nine generations, when there is no ai discount the public distribution has a hellinger distance of just 0.09 from the true distribution.\nwhen ai-generated content is 20% cheaper (discount rate is 0.8), the distance increases to 0.22, while a 50% discount increases the distance to 0.40.\nthus, while the availability of cheap ai-approximations might be thought to only increase public knowledge, under these conditions public knowledge is 2.3 or 3.2 times further away from the truth due to reliance on ai.for subsequent results illustrating the tradeoff of different parameters, we plot the hellinger distance between public knowledge at the end of the 100 rounds and the true distribution.\nas above, the more ai-generated content is cheaper (discount rate indicated by colors), the more public knowledge collapses towards the center.\nand conversely, if the discount rate is not too extreme, even slower updating on the relative values is not too harmful.in figure, we consider the impact of variations in how extreme the truncation of ai-generated content is on the collapse of knowledge.\nif ai truncates knowledge outside of 0.25 standard deviations from the mean, the impact is large, though once again this is at least someone moderated when the discount is smaller (especially if there is no generational effect).we compare the effect of the generational compounding of errors in figure."
    },
    {
      "header": "Discussion",
      "content": "we provide a theoretical framework for defining \"knowledge collapse\", whereby dependence on generative ai such as large language models may lead to a reduction in the long-tails of knowledge.\nour simulation study suggests that such harm can be mitigated to the extent that (a) we are aware of the of the possible value of niche, specialized and eccentric perspectives that may be neglected by ai-generated data and continue to seek them out, (b) ai-systems are not recursively interdependent, as occurs if they use other ai-generated content as inputs or suffer from other generational effects, and (c) ai-generated content is as representative as possible of the full distribution of knowledge.\nfor every hundred people who read a one-paragraph summary of a book, there should be a human somewhere who takes the time to sit down and read it, in hopes that she can then provide feedback one extension to the model would be to allow for generational change but endogenize the choice of public subsidies to protect 'tail' knowledge.\nprotecting the diversity of information means also paying attention to the effect of ai adoption on the revenue streams of journalists that produce and not merely transmit information (e.g..\nsecondly, there is an obvious need to avoid building recursively dependent ai systems (e.g. where one llm or agent provides answers based on another ai-generated summary, etc.) and thereby playing an llm-mediated game of 'telephone'.\npreserving access to 'unmediated' texts, such as through a well-conceived retrieval augmented generation approach, can preserve the long-tails of knowledge, as may generating multiple results and re-ranking.finally, while much recent attention has been on the problem of llms misleadingly presenting fiction as fact (hallucination), this may be less of an issue than the problem of representativeness across a distribution of possible responses.\nif a user asks, for example, \"what causes inflation?\" and a llm answers \"monetary policy\", the problem isn't one of hallucination, but of the failure to reflect the full-distribution of possible answers to the question, or at least provide an overview of the main schools of economic thought.this could be considered in the setup of frameworks for reinforcement learning from human feedback and related approaches to shaping model outputs, since humans may by default prefer simple, monolithic answers over those that represent the diversity of perspectives.\nparticular care should also be given in the context of the use of ai in education, to ensure students consider not only the veracity of ai-generated answers but also their variance, representativeness, and biases, that is, to what extent they represent the full distribution of possible answers to a question.the scaling lawsdemonstrate the advantage of training llms on the maximum amount of (quality) data."
    },
    {
      "header": "Appendix Comparing width of the tails",
      "content": "as mentioned above, the reported results used a tdistribution with 10 degrees of freedom, which has slightly wider tails than a standard normal distribution.\nwe can compare the results with a standard normal distribution (i.e.a t-distribution as the degrees of freedom becomes large) or with wider tails.\nin figure, we plot a comparison of the results from the main section (with 10 degrees of freedom with wider or narrower tails (3 and 9999 degrees of freedom respectively).\nthe main difference is for more extreme discounts provided by ai (< 0.7), for which the wider tails contribute to knowledge collapse (i.e.generate a public knowledge distribution further from the true distribution).\nnarrower tails, such as from a standard normal distribution, generate results broadly similar to the main model.\nthus, as expected more information in the tails makes the effect of knowledge collapse more pronounced, but is plays less of a role than the other parameters discussed above in determining the dynamic of collapse."
    },
    {
      "header": "Defining knowledge collapse",
      "content": "12 first, we con- 12 the broadest definition of 'human knowledge' might encompass all the beliefs, information, values, and representations of the world ever held by humans anywhere on earth, whether recorded or not.\nwe are unable to access almost all of this, and we tend to assume that the sider the broad set of historical human knowledge that was at one point held in common within communities of humans, shared and reproduced in a regular way, which we might call 'broad historical knowledge'.second, we consider the set of knowledge that is held or accessible to us, (humans who are living in a given epoch), which we call 'available current knowledge.' in the example cited in the main section, the ancient roman recipe for concrete is part of broad historical knowledge but not part of available current knowledge.technological innovations from the printing press to the internet to ai mediate human interactions and human's exposure to historical and current sources of knowledge.\nfor example, the digitization of archives might make obscure sources available to a wider audience and thus increase the amount of 'broad historical knowledge' that is part of the 'available current knowledge.'we also distinguish a third, narrower set of knowledge, which reflects not what is theoretically accessible to humans but which is readily part of human patterns of thinking or habits of thought.\nthis we call 'human memory knowledge' or 'human working knowledge' by reference to human working memory.for example, consider the problem of listing all the animals that have ever existed on earth.\nmore narrowly, the set of \"available current knowledge\" corresponds to the set of all animals that a team of all biologists could compile with access to the internet and other records.\nfinally, however, if we were able to conduct a survey of all humans on earth and ask them to name as many animals as possible in, say, one day, we would come up with a more limited list (that would include many repetitions).in many practical applications, 'human working knowledge' is the most relevant because it is the knowledge that shapes human action and reflection.\na doctor considering possible sources of a crossover pathogen might rely on their knowledge of common species in useful parts of this have been passed on to others, but theoretically we might want to allow for the fact that, for example some human somewhere once had an important, original, and useful belief just before they, say, got hit by a car and could not tell anyone.\nsecondly, in using the term 'knowledge', we do not restrict our focus based on the truth of the beliefs held, such that in referring to 'human knowledge' we refer to a variety of beliefs and statements, some of which contract others.asking a patient if they had recently been in the presence of certain animals (even if a researcher who specializes in this area might consult know more and sources to find a longer possible list).\nedison and his team famously tried thousands of different filament materials, but if it bamboo had not been among the materials that came to mind as they searched alternatives, a practical electric bulb may have been invented only later.finally, it is useful to define the 'epistemic horizon' as the set of knowledge that a community of humans considers practically possible to know and worth knowing.\none way to think about this relationship is as a generalization of 'availability bias', in which we take the set of readily recalled information to be more likely, important, or relevant.in these terms, we define 'knowledge collapse' as the progressive narrowing over time (or over technological representations) of the set of human working knowledge and the current human epistemic horizon relative to the set of broad historical knowledge.on a theoretical level, the idea of epistemic horizon has an intellectual heritage in immanuel kant's argument about the forms and categories of understanding that underly the possibility of knowledge."
    }
  ]
}
